"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[16078],{3905:(e,n,t)=>{t.d(n,{Zo:()=>g,kt:()=>m});var s=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);n&&(s=s.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,s)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function r(e,n){if(null==e)return{};var t,s,a=function(e,n){if(null==e)return{};var t,s,a={},o=Object.keys(e);for(s=0;s<o.length;s++)t=o[s],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(s=0;s<o.length;s++)t=o[s],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var c=s.createContext({}),i=function(e){var n=s.useContext(c),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},g=function(e){var n=i(e.components);return s.createElement(c.Provider,{value:n},e.children)},p={inlineCode:"code",wrapper:function(e){var n=e.children;return s.createElement(s.Fragment,{},n)}},h=s.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,c=e.parentName,g=r(e,["components","mdxType","originalType","parentName"]),h=i(t),m=a,u=h["".concat(c,".").concat(m)]||h[m]||p[m]||o;return t?s.createElement(u,l(l({ref:n},g),{},{components:t})):s.createElement(u,l({ref:n},g))}));function m(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,l=new Array(o);l[0]=h;var r={};for(var c in n)hasOwnProperty.call(n,c)&&(r[c]=n[c]);r.originalType=e,r.mdxType="string"==typeof e?e:a,l[1]=r;for(var i=2;i<o;i++)l[i]=t[i];return s.createElement.apply(null,l)}return s.createElement.apply(null,t)}h.displayName="MDXCreateElement"},92046:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>p,frontMatter:()=>o,metadata:()=>r,toc:()=>i});var s=t(87462),a=(t(67294),t(3905));const o={sidebar_position:8080,slug:"2021-03-24",title:"Logstash 7 and Common Log Pattern",authors:"mpolinowski",tags:["LINUX","Elasticsearch"]},l=void 0,r={unversionedId:"DevOps/Elasticsearch/2021-03-24-logstash-common-grok-pattern/index",id:"DevOps/Elasticsearch/2021-03-24-logstash-common-grok-pattern/index",title:"Logstash 7 and Common Log Pattern",description:"Cheung Chau, Hongkon",source:"@site/docs/DevOps/Elasticsearch/2021-03-24-logstash-common-grok-pattern/index.md",sourceDirName:"DevOps/Elasticsearch/2021-03-24-logstash-common-grok-pattern",slug:"/DevOps/Elasticsearch/2021-03-24-logstash-common-grok-pattern/2021-03-24",permalink:"/docs/DevOps/Elasticsearch/2021-03-24-logstash-common-grok-pattern/2021-03-24",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/DevOps/Elasticsearch/2021-03-24-logstash-common-grok-pattern/index.md",tags:[{label:"LINUX",permalink:"/docs/tags/linux"},{label:"Elasticsearch",permalink:"/docs/tags/elasticsearch"}],version:"current",sidebarPosition:8080,frontMatter:{sidebar_position:8080,slug:"2021-03-24",title:"Logstash 7 and Common Log Pattern",authors:"mpolinowski",tags:["LINUX","Elasticsearch"]},sidebar:"tutorialSidebar",previous:{title:"Elasticsearch Cheat Sheet",permalink:"/docs/DevOps/Elasticsearch/2021-03-25-elasticsearch7-activate-logging-of-search-queries/elasticsearch-cheat-sheet"},next:{title:"Logstash 7 Working with Unstructured Data",permalink:"/docs/DevOps/Elasticsearch/2021-03-23-logstash-working-with-unstructured-data/2021-03-23"}},c={},i=[{value:"Working with common Log Formats",id:"working-with-common-log-formats",level:2},{value:"NGINX Access Logs",id:"nginx-access-logs",level:3},{value:"Apache Access Logs",id:"apache-access-logs",level:3},{value:"User Agent Mapping and Geo Location Mapping",id:"user-agent-mapping-and-geo-location-mapping",level:4},{value:"Elasticsearch Logs",id:"elasticsearch-logs",level:3},{value:"Elasticsearch Slow Logs",id:"elasticsearch-slow-logs",level:3},{value:"MySQL Slow Logs",id:"mysql-slow-logs",level:3}],g={toc:i};function p(e){let{components:n,...o}=e;return(0,a.kt)("wrapper",(0,s.Z)({},g,o,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Cheung Chau, Hongkon",src:t(62736).Z,width:"1500",height:"693"})),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#working-with-common-log-formats"},"Working with common Log Formats"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#nginx-access-logs"},"NGINX Access Logs")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#apache-access-logs"},"Apache Access Logs"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#user-agent-mapping-and-geo-location-mapping"},"User Agent Mapping and Geo Location Mapping")))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#elasticsearch-logs"},"Elasticsearch Logs")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#elasticsearch-slow-logs"},"Elasticsearch Slow Logs")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#mysql-slow-logs"},"MySQL Slow Logs"))))),(0,a.kt)("h2",{id:"working-with-common-log-formats"},"Working with common Log Formats"),(0,a.kt)("p",null,"You can find a variety of of typical server logs in an repository by ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/coralogix-resources/logstash"},"Coralogix : Logstash Resources"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yml"},"\u251c\u2500\u2500 logs\n\u2502  \u251c\u2500\u2500 apache\n\u2502  \u2502  \u251c\u2500\u2500 access_log\n\u2502  \u2502  \u251c\u2500\u2500 apache-access-enriched.conf\n\u2502  \u2502  \u251c\u2500\u2500 apache-access-final-modified.conf\n\u2502  \u2502  \u251c\u2500\u2500 apache-access-final.conf\n\u2502  \u2502  \u251c\u2500\u2500 apache.log\n\u2502  \u2502  \u2514\u2500\u2500 log guide\n\u2502  \u251c\u2500\u2500 aws_alb\n\u2502  \u2502  \u251c\u2500\u2500 alb_logs.log\n\u2502  \u2502  \u2514\u2500\u2500 aws-alb.conf\n\u2502  \u251c\u2500\u2500 aws_cloudfront\n\u2502  \u2502  \u251c\u2500\u2500 aws-cloudfront.conf\n\u2502  \u2502  \u2514\u2500\u2500 cloudfront_logs.log\n\u2502  \u251c\u2500\u2500 aws_elb\n\u2502  \u2502  \u251c\u2500\u2500 aws-elb.conf\n\u2502  \u2502  \u2514\u2500\u2500 elb_logs.log\n\u2502  \u251c\u2500\u2500 commands help.txt\n\u2502  \u251c\u2500\u2500 elasticsearch_logs\n\u2502  \u2502  \u251c\u2500\u2500 elasticsearch.log\n\u2502  \u2502  \u2514\u2500\u2500 es-logs-final.conf\n\u2502  \u251c\u2500\u2500 elasticsearch_slowlogs\n\u2502  \u2502  \u251c\u2500\u2500 es-slowlog-final.conf\n\u2502  \u2502  \u2514\u2500\u2500 es_slowlog.log\n\u2502  \u251c\u2500\u2500 git_push.sh\n\u2502  \u251c\u2500\u2500 iis\n\u2502  \u2502  \u251c\u2500\u2500 iis-final-working.conf\n\u2502  \u2502  \u2514\u2500\u2500 u_ex171118-sample.log\n\u2502  \u251c\u2500\u2500 mongodb\n\u2502  \u2502  \u251c\u2500\u2500 mongodb-final.conf\n\u2502  \u2502  \u2514\u2500\u2500 mongodb.log\n\u2502  \u251c\u2500\u2500 mysql_slowlogs\n\u2502  \u2502  \u251c\u2500\u2500 mysql-slow.log\n\u2502  \u2502  \u2514\u2500\u2500 mysql-slowlogs.conf\n\u2502  \u251c\u2500\u2500 nginx\n\u2502  \u2502  \u251c\u2500\u2500 access.log\n\u2502  \u2502  \u2514\u2500\u2500 nginx-access-final.conf\n\u2502  \u2514\u2500\u2500 syslog\n\u2502     \u251c\u2500\u2500 syslog-direct-final-02.conf\n\u2502     \u251c\u2500\u2500 syslog-direct-final.conf\n\u2502     \u251c\u2500\u2500 syslog-forward-tcp - rsyslog settings\n\u2502     \u2514\u2500\u2500 syslog-forward-tcp.conf\n")),(0,a.kt)("h3",{id:"nginx-access-logs"},"NGINX Access Logs"),(0,a.kt)("p",null,"Let's first take a look at the NGINX ",(0,a.kt)("inlineCode",{parentName:"p"},"access.log"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-cfg"},'114.119.167.35 - - [01/Jun/2020:08:34:45 +0000] "GET /blog/tag/mongodb/amp HTTP/1.1" 301 0 "-" "Mozilla/5.0 (Linux; Android 7.0;) AppleWebKit/537.36 (KHTML, like Gecko) Mobile Safari/537.36"\n\n...\n')),(0,a.kt)("p",null,"The corresponding Logstash config is also part of the repository ",(0,a.kt)("inlineCode",{parentName:"p"},"nginx-access-final.conf"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-json"},'input {\nfile {\n   path => ["/usr/share/logstash/access.log"]\n   start_position => "beginning"\n   sincedb_path => "/dev/null"\n }\n}\nfilter {\n      grok {\n        match => { "message" => ["%{IPORHOST:remote_ip} - %{DATA:user_name} \\[%{HTTPDATE:access_time}\\] \\"%{WORD:http_method} %{DATA:url} HTTP/%{NUMBER:http_version}\\" %{NUMBER:response_code} %{NUMBER:body_sent_bytes} \\"%{DATA:referrer}\\" \\"%{DATA:agent}\\""] }\n        remove_field => "message"\n      }\n      mutate {\n        add_field => { "read_timestamp" => "%{@timestamp}" }\n      }\n      date {\n        match => [ "timestamp", "dd/MMM/YYYY:H:m:s Z" ]\n        remove_field => "timestamp"\n      }\n}\noutput{\n  elasticsearch{\n    hosts => ["localhost:9200"]\n    index => "nginx-access-log"\n  }\n  stdout {\n    codec => "rubydebug"\n   }\n}\n')),(0,a.kt)("p",null,"We can test the Grok Pattern in the ",(0,a.kt)("a",{parentName:"p",href:"http://grokdebug.herokuapp.com"},"Grok Debugger"),":"),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Grok Filter",src:t(21895).Z,width:"970",height:"289"})),(0,a.kt)("p",null,"This will give us the following result:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "remote_ip": [["114.119.167.35"]],\n  "user_name": [["-"]],\n  "access_time": [["01/Jun/2020:08:34:45 +0000"]],\n  "http_method": [["GET"]],\n  "url": [["/blog/tag/mongodb/amp"]],\n  "http_version": [["1.1"]],\n  "response_code": [["301"]],\n  "body_sent_bytes": [["0"]],\n  "referrer": [["-"]],\n  "agent": [\n    [\n      "Mozilla/5.0 (Linux; Android 7.0;) AppleWebKit/537.36 (KHTML, like Gecko) Mobile Safari/537.36"\n    ]\n  ]\n}\n')),(0,a.kt)("p",null,"I will now try to ingest the entire log into Elasticsearch using my Logstash container:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'docker run \\\n   --name logstash \\\n   --net=host \\\n   --rm -it \\\n   -v /opt/logstash/logs/nginx/nginx-access-final.conf:/usr/share/logstash/pipeline/nginx-access-final.conf \\\n   -v /opt/logstash/logs/nginx/access.log:/usr/share/logstash/access.log \\\n   -e "ELASTIC_HOST=localhost:9200" \\\n   -e "XPACK_SECURITY_ENABLED=false" \\\n   -e "XPACK_REPORTING_ENABLED=false" \\\n   -e "XPACK_MONITORING_ENABLED=false" \\\n   -e "XPACK_MONITORING_ELASTICSEARCH_USERNAME=elastic" \\\n   -e "XPACK_MONITORING_ELASTICSEARCH_PASSWORD=changeme" \\\n   logstash:7.13.4\n')),(0,a.kt)("p",null,"You can query the indexed data with:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'curl -XGET "http://localhost:9200/nginx-access-log/_search?pretty" -H \'Content-Type: application/json\' -d\'{\n  "size": 1,\n  "track_total_hits": true,\n  "query": {\n    "bool": {\n      "must_not": [\n        {\n          "term": {\n            "tags.keyword": "_grokparsefailure"\n          }\n        }\n      ]\n    }\n  }\n}\'\n')),(0,a.kt)("p",null,"This will return the first hit that wasn't not a parsing error:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-json"},'"hits" : [\n      {\n        "_index" : "nginx-access-log",\n        "_type" : "_doc",\n        "_id" : "LBROC3sBhWUvimFeTT46",\n        "_score" : 0.0,\n        "_source" : {\n          "user_name" : "-",\n          "@version" : "1",\n          "path" : "/usr/share/logstash/access.log",\n          "read_timestamp" : "2021-08-03T09:18:04.356Z",\n          "access_time" : "01/Jun/2020:15:49:10 +0000",\n          "body_sent_bytes" : "131",\n          "agent" : "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36",\n          "http_version" : "1.1",\n          "referrer" : "https://www.techstuds.com/blog/join-in-mongodb/",\n          "response_code" : "200",\n          "url" : "/blog/join-in-mongodb/?relatedposts=1",\n          "host" : "debian11",\n          "remote_ip" : "73.44.199.53",\n          "http_method" : "GET",\n          "@timestamp" : "2021-08-03T09:18:04.356Z"\n        }\n      }\n    ]\n')),(0,a.kt)("p",null,"We can now create an index pattern in Kibana and e.g. check how often a certain IP address accessed an URL:"),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Grok Filter",src:t(750).Z,width:"1513",height:"689"})),(0,a.kt)("p",null,"To delete the indexed data run:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"curl -XDELETE -u elastic:changeme http://localhost:9200/nginx-access-log\n")),(0,a.kt)("h3",{id:"apache-access-logs"},"Apache Access Logs"),(0,a.kt)("h4",{id:"user-agent-mapping-and-geo-location-mapping"},"User Agent Mapping and Geo Location Mapping"),(0,a.kt)("p",null,"Let's first take a look at the Apache ",(0,a.kt)("inlineCode",{parentName:"p"},"access_log"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-cfg"},'66.249.84.199 - - [30/Apr/2017:06:49:05 +0000] "GET /wp-content/plugins/revslider/public/assets/css/settings.css?ver=5.4.1 HTTP/1.1" 200 7067 "http://sundog-soft.com/2017/04/skymaxx-pro-4-5-coming/" "Mozilla/5.0 (Linux; Android 5.1.1; C6903 Build/14.6.A.1.236) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.25 Mobile Safari/537.36"\n\n...\n')),(0,a.kt)("p",null,"The corresponding Logstash config is also part of the repository ",(0,a.kt)("inlineCode",{parentName:"p"},"apache-access-enriched.conf"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-json"},'input {\nfile {\n   path => ["/usr/share/logstash/access_log"]\n   start_position => "beginning"\n   sincedb_path => "/dev/null"\n }\n}\nfilter {\n      grok {\n         match => { "message" => ["%{COMBINEDAPACHELOG}"] }\n        remove_field => "message"\n      }\n      mutate {\n        add_field => { "read_timestamp" => "%{@timestamp}" }\n      }\n      date {\n        match => [ "timestamp", "dd/MMM/YYYY:H:m:s Z" ]\n        remove_field => "timestamp"\n      }\n     useragent {\n       source => "agent"\n       target => "agent"\n     }\n     geoip {\n       source => "clientip"\n       target => "geoip"\n     }\n}\noutput {\n  elasticsearch {\n            hosts => [ "localhost:9200"]\n            index => "apache-access-log"\n        }\n  stdout { codec => rubydebug }\n}\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'docker run \\\n   --name logstash \\\n   --net=host \\\n   --rm -it \\\n   -v /opt/logstash/logs/apache/apache-access-enriched.conf:/usr/share/logstash/pipeline/apache-access-enriched.conf \\\n   -v /opt/logstash/logs/apache/access_log:/usr/share/logstash/access_log \\\n   -e "ELASTIC_HOST=localhost:9200" \\\n   -e "XPACK_SECURITY_ENABLED=false" \\\n   -e "XPACK_REPORTING_ENABLED=false" \\\n   -e "XPACK_MONITORING_ENABLED=false" \\\n   -e "XPACK_MONITORING_ELASTICSEARCH_USERNAME=elastic" \\\n   -e "XPACK_MONITORING_ELASTICSEARCH_PASSWORD=changeme" \\\n   logstash:7.13.4\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'curl -XGET "http://localhost:9200/apache-access-log/_search?pretty" -d\'{\n  "size": 1,\n  "track_total_hits": true,\n  "query": {\n  "bool": {\n    "must_not": [\n      {\n        "term": {\n          "tags.keyword": "_grokparsefailure"\n        }\n      }\n    ]\n  }\n  }\n}\'\n')),(0,a.kt)("p",null,"We can now create an index pattern in Kibana and e.g. check how often a users from a specific city accessed an URL:"),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Grok Filter",src:t(56544).Z,width:"1485",height:"697"})),(0,a.kt)("p",null,"To delete the indexed data run:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"curl -XDELETE -u elastic:changeme http://localhost:9200/apache-access-log\n")),(0,a.kt)("h3",{id:"elasticsearch-logs"},"Elasticsearch Logs"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/coralogix-resources/logstash/blob/master/elasticsearch_logs/es-logs-final.conf"},"https://github.com/coralogix-resources/logstash/blob/master/elasticsearch_logs/es-logs-final.conf")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-json"},'input {\n  file {\n    path => "/etc/logstash/conf.d/logstash/elasticsearch_logs/elasticsearch.log"\n    type => "elasticsearch"\n    start_position => "beginning"\n    sincedb_path => "/dev/null"\n    codec => multiline {\n      pattern => "^\\["\n      negate => true\n      what => "previous"\n    }\n  }\n}\n\nfilter {\n  if [type] == "elasticsearch" {\n    grok {\n      match => [ "message", "\\[%{TIMESTAMP_ISO8601:timestamp}\\]\\[%{DATA:severity}%{SPACE}\\]\\[%{DATA:source}%{SPACE}\\]%{SPACE}(?<message>(.|\\r|\\n)*)" ]\n      overwrite => [ "message" ]\n    }\n\n    if "_grokparsefailure" not in [tags] {\n      grok {\n        match => [\n          "message", "^\\[%{DATA:node}\\] %{SPACE}\\[%{DATA:index}\\]%{SPACE}(?<short_message>(.|\\r|\\n)*)",\n          "message", "^\\[%{DATA:node}\\]%{SPACE}(?<short_message>(.|\\r|\\n)*)" ]\n        tag_on_failure => []\n      }\n    }\n  }\n}\n\noutput {\n  elasticsearch {\n            hosts => [ "localhost:9200"]\n            index => "es-test-logs"\n        }\n  stdout { codec => rubydebug }\n}\n')),(0,a.kt)("h3",{id:"elasticsearch-slow-logs"},"Elasticsearch Slow Logs"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/coralogix-resources/logstash/blob/master/elasticsearch_slowlogs/es_slowlog.log"},"https://github.com/coralogix-resources/logstash/blob/master/elasticsearch_slowlogs/es_slowlog.log")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-json"},'input{\n    file{\n        path => ["/etc/logstash/conf.d/logstash/elasticsearch_slowlogs/es_slowlog.log"]\n                start_position => "beginning"\n                sincedb_path => "/dev/null"\n        codec => plain {\n                    charset => "ISO-8859-15" #Reads plaintext with no delimiting between events\n            }\n    }\n}\nfilter {\n    grok {\n        match => { "message" => [\'\\[%{TIMESTAMP_ISO8601:timestamp}\\]\\[%{LOGLEVEL:level}\\]\\[%{HOSTNAME:type}\\]%{SPACE}\\[%{HOSTNAME:[node_name]}\\]%{SPACE}\\[%{WORD:[index_name]}\\]%{NOTSPACE}%{SPACE}took\\[%{NUMBER:took_micro}%{NOTSPACE}\\]%{NOTSPACE}%{SPACE}%{NOTSPACE}%{NOTSPACE}%{SPACE}%{NOTSPACE}%{NOTSPACE}%{SPACE}%{NOTSPACE}%{NOTSPACE}%{SPACE}search_type\\[%{WORD:search_type}\\]%{NOTSPACE}%{SPACE}total_shards\\[%{NUMBER:total_shards}\\]%{NOTSPACE}%{SPACE}source%{GREEDYDATA:query}\\Z\']}\n    }\n\n    mutate{\n        remove_field => ["@version","@timestamp","host","path","logTook"]\n    }\n}\noutput{\n    elasticsearch{\n        hosts => ["localhost:9200"]\n        index => "es-slow-logs"\n    }\n    stdout {\n        codec => "rubydebug"\n     }\n}\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'curl -XGET "http://localhost:9200/es-slow-logs/_search?pretty" -d\'{  "size": 1}\'\n')),(0,a.kt)("h3",{id:"mysql-slow-logs"},"MySQL Slow Logs"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://raw.githubusercontent.com/coralogix-resources/logstash/master/mysql_slowlogs/mysql-slow.log"},"https://raw.githubusercontent.com/coralogix-resources/logstash/master/mysql_slowlogs/mysql-slow.log")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-json"},'input {\nfile {\n   path => ["/etc/logstash/conf.d/logstash/mysql_slowlogs/mysql-slow.log"]\n   start_position => "beginning"\n   sincedb_path => "/dev/null"\n   codec => multiline {\n          pattern => "^# Time: %{TIMESTAMP_ISO8601}"\n          negate => true\n          what => "previous"\n        }\n }\n}\nfilter {\n      mutate {\n        gsub => [\n          "message", "#", "",\n          "message", "\\n", " "\n        ]\n        remove_field => "host"\n      }\n      grok {\n        match => { "message" => [\n              "Time\\:%{SPACE}%{TIMESTAMP_ISO8601:timestamp}%{SPACE}User\\@Host\\:%{SPACE}%{WORD:user}\\[%{NOTSPACE}\\] \\@ %{NOTSPACE:host} \\[\\]%{SPACE}Id\\:%{SPACE}%{NUMBER:sql_id}%{SPACE}Query_time\\:%{SPACE}%{NUMBER:query_time}%{SPACE}Lock_time\\:%{SPACE}%{NUMBER:lock_time}%{SPACE}Rows_sent\\:%{SPACE}%{NUMBER:rows_sent}%{SPACE}Rows_examined\\:%{SPACE}%{NUMBER:rows_examined}%{SPACE}%{GREEDYDATA}; %{GREEDYDATA:command}\\;%{GREEDYDATA}"\n       ] }\n      }\n\n      mutate {\n        add_field => { "read_timestamp" => "%{@timestamp}" }\n        #remove_field => "message"\n      }\n}\noutput {\n  elasticsearch {\n            hosts => [ "localhost:9200"]\n            index => "mysql-slowlogs-01"\n        }\n  stdout { codec => rubydebug }\n}\n')))}p.isMDXComponent=!0},21895:(e,n,t)=>{t.d(n,{Z:()=>s});const s=t.p+"assets/images/Logstash_Grok_Filter_01-c4f16752e42bdfea2b8212564d302694.png"},750:(e,n,t)=>{t.d(n,{Z:()=>s});const s=t.p+"assets/images/Logstash_Grok_Filter_02-60ef78764f572ce7091754a87b254c68.png"},56544:(e,n,t)=>{t.d(n,{Z:()=>s});const s=t.p+"assets/images/Logstash_Grok_Filter_03-8f6aa8a7e3e49edbb63fdcc20775e658.png"},62736:(e,n,t)=>{t.d(n,{Z:()=>s});const s=t.p+"assets/images/photo-456tdsfggd_67gfh6dgdf4_d-e0663a8ee734d70171add9efd27aa0c8.jpg"}}]);