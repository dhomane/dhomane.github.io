"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[56686],{3905:(e,a,t)=>{t.d(a,{Zo:()=>p,kt:()=>d});var n=t(67294);function l(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function r(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function o(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?r(Object(t),!0).forEach((function(a){l(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function i(e,a){if(null==e)return{};var t,n,l=function(e,a){if(null==e)return{};var t,n,l={},r=Object.keys(e);for(n=0;n<r.length;n++)t=r[n],a.indexOf(t)>=0||(l[t]=e[t]);return l}(e,a);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)t=r[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(l[t]=e[t])}return l}var s=n.createContext({}),m=function(e){var a=n.useContext(s),t=a;return e&&(t="function"==typeof e?e(a):o(o({},a),e)),t},p=function(e){var a=m(e.components);return n.createElement(s.Provider,{value:a},e.children)},c={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},g=n.forwardRef((function(e,a){var t=e.components,l=e.mdxType,r=e.originalType,s=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),g=m(t),d=l,u=g["".concat(s,".").concat(d)]||g[d]||c[d]||r;return t?n.createElement(u,o(o({ref:a},p),{},{components:t})):n.createElement(u,o({ref:a},p))}));function d(e,a){var t=arguments,l=a&&a.mdxType;if("string"==typeof e||l){var r=t.length,o=new Array(r);o[0]=g;var i={};for(var s in a)hasOwnProperty.call(a,s)&&(i[s]=a[s]);i.originalType=e,i.mdxType="string"==typeof e?e:l,o[1]=i;for(var m=2;m<r;m++)o[m]=t[m];return n.createElement.apply(null,o)}return n.createElement.apply(null,t)}g.displayName="MDXCreateElement"},60153:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>s,contentTitle:()=>o,default:()=>c,frontMatter:()=>r,metadata:()=>i,toc:()=>m});var n=t(87462),l=(t(67294),t(3905));const r={sidebar_position:7050,slug:"2021-11-13",title:"Tensorflow2 Model Zoo",authors:"mpolinowski",tags:["Machine Learning","Python","Tensorflow"]},o=void 0,i={unversionedId:"IoT-and-Machine-Learning/ML/2021-11-13--tensorflow-model-zoo/index",id:"IoT-and-Machine-Learning/ML/2021-11-13--tensorflow-model-zoo/index",title:"Tensorflow2 Model Zoo",description:"Mong Kok, Hongkong",source:"@site/docs/IoT-and-Machine-Learning/ML/2021-11-13--tensorflow-model-zoo/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2021-11-13--tensorflow-model-zoo",slug:"/IoT-and-Machine-Learning/ML/2021-11-13--tensorflow-model-zoo/2021-11-13",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-11-13--tensorflow-model-zoo/2021-11-13",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2021-11-13--tensorflow-model-zoo/index.md",tags:[{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Python",permalink:"/docs/tags/python"},{label:"Tensorflow",permalink:"/docs/tags/tensorflow"}],version:"current",sidebarPosition:7050,frontMatter:{sidebar_position:7050,slug:"2021-11-13",title:"Tensorflow2 Model Zoo",authors:"mpolinowski",tags:["Machine Learning","Python","Tensorflow"]},sidebar:"tutorialSidebar",previous:{title:"Tensorflow.js React App",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-11-14--tensorflow-model-for-tfjs/2021-11-14"},next:{title:"Tensorflow2 Crash Course - Part V",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-11-12--tensorflow-crash-course-part-v/2021-11-12"}},s={},m=[{value:"What I am trying to do",id:"what-i-am-trying-to-do",level:2},{value:"Project Setup",id:"project-setup",level:2},{value:"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8",id:"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8",level:3},{value:"Expanding the ROI",id:"expanding-the-roi",level:4},{value:"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8",id:"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8",level:3},{value:"Labeling Done Right!",id:"labeling-done-right",level:2}],p={toc:m};function c(e){let{components:a,...r}=e;return(0,l.kt)("wrapper",(0,n.Z)({},p,r,{components:a,mdxType:"MDXLayout"}),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Mong Kok, Hongkong",src:t(34610).Z,width:"1500",height:"544"})),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#what-i-am-trying-to-do"},"What I am trying to do")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#project-setup"},"Project Setup"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8"},"ssd","_","mobilenet","_","v2","_","fpnlite","_","320x320","_","coco17","_","tpu-8"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#expanding-the-roi"},"Expanding the ROI")))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8"},"ssd","_","mobilenet","_","v2","_","fpnlite","_","640x640","_","coco17","_","tpu-8")))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#labeling-done-right"},"Labeling Done Right!"))),(0,l.kt)("h2",{id:"what-i-am-trying-to-do"},"What I am trying to do"),(0,l.kt)("p",null,"I need to gain an understanding how different models and training steps affect the accuracy of the resulting model. Also gathering data in form of screen caps and labeling has a huge effect on the outcome of the training. Let' s see how this can be optimized."),(0,l.kt)("h2",{id:"project-setup"},"Project Setup"),(0,l.kt)("p",null,"I am using this ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/mpolinowski/tensorflow2-starter"},"Tensorflow Boilerplate"),". But instead of using an IP camera to film my hand and labeling hand gestures I now want to use screen caps from popular TV shows and label the characters depicted in that scene. With the exception of this change I am following the ",(0,l.kt)("a",{parentName:"p",href:"/docs/IoT-and-Machine-Learning/ML/2021-11-08--tensorflow-crash-course-part-i/2021-11-08"},"Tensorflow Tutorial")," and try to end up with a model that can tell me the character names when I show it a TV show."),(0,l.kt)("p",null,(0,l.kt)("a",{parentName:"p",href:"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md"},"Detection Models"),": Tensorflow provides a collection of detection models pre-trained on the COCO 2017 dataset. So far I have been using the ",(0,l.kt)("a",{parentName:"p",href:"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"},"SSD MobileNet V2 FPNLite 320x320"),". I will now replace it with the slightly slower but more accurate ",(0,l.kt)("a",{parentName:"p",href:"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz"},"SSD MobileNet V2 FPNLite 640x640"),":"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Model name"),(0,l.kt)("th",{parentName:"tr",align:null},"Speed (ms)"),(0,l.kt)("th",{parentName:"tr",align:null},"COCO mAP"),(0,l.kt)("th",{parentName:"tr",align:null},"Outputs"),(0,l.kt)("th",{parentName:"tr",align:null}),(0,l.kt)("th",{parentName:"tr",align:null}))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"SSD MobileNet V2 FPNLite 320x320"),(0,l.kt)("td",{parentName:"tr",align:null},"22"),(0,l.kt)("td",{parentName:"tr",align:null},"22.2"),(0,l.kt)("td",{parentName:"tr",align:null},"Boxes"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null})),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"SSD MobileNet V2 FPNLite 640x640"),(0,l.kt)("td",{parentName:"tr",align:null},"39"),(0,l.kt)("td",{parentName:"tr",align:null},"28.2"),(0,l.kt)("td",{parentName:"tr",align:null},"Boxes"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null})))),(0,l.kt)("h3",{id:"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8"},"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},(0,l.kt)("inlineCode",{parentName:"p"},"INFO:tensorflow:Step 2000 per-step time 0.117s"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"Accumulating evaluation results...\nDONE (t=0.03s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.449\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.401\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.318\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.629\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.679\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.679\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679\n")),(0,l.kt)("p",null," After 2000 steps I only got a few positive recognitions. All of them were from one label. In general the result was pretty bad... So another 3000 steps on top:"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},(0,l.kt)("inlineCode",{parentName:"p"},"INFO:tensorflow:Step 3000 per-step time 0.123s"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"Accumulating evaluation results...\nDONE (t=0.03s).\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.486\nAverage Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.669\nAverage Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.604\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.707\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.721\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.721\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.721\n")),(0,l.kt)("p",null,"This greatly increased the metrics above. But I still ran into the issue that only one of my labels was being recognized - ",(0,l.kt)("strong",{parentName:"p"},"Captain Jean-Luc Picard"),". The model also seemed to be obsessed with hair styles. Evaluating them higher than facial features..."),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Tensorflow Model Zoo",src:t(10682).Z,width:"999",height:"474"})),(0,l.kt)("h4",{id:"expanding-the-roi"},"Expanding the ROI"),(0,l.kt)("p",null,"Which is interesting because during labeling he was the only character where I choose to make the entire head ROI. For the others I used a region of interest centered on their face to prevent the model from over-emphasizing their hair cut... so now I went back to labeling and corrected this - potential - mistake:"),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Tensorflow Model Zoo",src:t(2859).Z,width:"1034",height:"375"})),(0,l.kt)("p",null,"Now I re-ran the 3000 steps and already here I am getting a much better result:"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},(0,l.kt)("inlineCode",{parentName:"p"},"INFO:tensorflow:Step 3000 per-step time 0.117s"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"Accumulating evaluation results...\nDONE (t=0.03s).\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.436\nAverage Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.576\nAverage Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.478\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.436\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.650\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.793\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.793\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.793\n")),(0,l.kt)("p",null," I now also found an image that tested - correctly - positive for another label. But I also lost a couple of detection that worked before:"),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Tensorflow Model Zoo",src:t(37901).Z,width:"1025",height:"386"})),(0,l.kt)("p",null,"So let's re-run the training and add another 10.000 steps to see if this makes a difference:"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},(0,l.kt)("inlineCode",{parentName:"p"},"INFO:tensorflow:Step 10000 per-step time 0.125s"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"Accumulating evaluation results...\nDONE (t=0.03s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.558\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.558\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.473\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.831\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.831\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.831\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.831\n")),(0,l.kt)("p",null," What I am noticing here is that the ",(0,l.kt)("strong",{parentName:"p"},"Recall")," value greatly benefits from the training. But there is almost no increase in ",(0,l.kt)("strong",{parentName:"p"},"Precision"),":"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Precision"),": True Positive / (True Positive + False Positive)"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Recall"),": True Positive / (True PMost are still undetected.")),(0,l.kt)("p",null,"This must be because the recognition in general is terrible - I am getting almost no recognitions false or positive. But if there is a hit it is almost always good. So why doesn't this work? It might be that the 320x320 image resolution is not sufficient for the training. So let's try using the higher one and see how this changes the evaluation:"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Model name"),(0,l.kt)("th",{parentName:"tr",align:null},"Speed (ms)"),(0,l.kt)("th",{parentName:"tr",align:null},"COCO mAP"),(0,l.kt)("th",{parentName:"tr",align:null},"Outputs"),(0,l.kt)("th",{parentName:"tr",align:null}),(0,l.kt)("th",{parentName:"tr",align:null}))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"SSD MobileNet V2 FPNLite 320x320"),(0,l.kt)("td",{parentName:"tr",align:null},"22"),(0,l.kt)("td",{parentName:"tr",align:null},"22.2"),(0,l.kt)("td",{parentName:"tr",align:null},"Boxes"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null})),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"SSD MobileNet V2 FPNLite 640x640"),(0,l.kt)("td",{parentName:"tr",align:null},"39"),(0,l.kt)("td",{parentName:"tr",align:null},"28.2"),(0,l.kt)("td",{parentName:"tr",align:null},"Boxes"),(0,l.kt)("td",{parentName:"tr",align:null}),(0,l.kt)("td",{parentName:"tr",align:null})))),(0,l.kt)("h3",{id:"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8"},"ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"INFO:tensorflow:Step 2000 per-step time 0.439s")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"Accumulating evaluation results...\nDONE (t=0.03s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.234\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.372\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.283\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.512\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.595\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.595\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.595\n")),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"INFO:tensorflow:Step 11000 per-step time 0.468s")),(0,l.kt)("p",null,(0,l.kt)("em",{parentName:"p"},"Oh, I noticed a mistake here. I thought the steps for a new run will be added to the already run steps. But by rerunning the command with ",(0,l.kt)("inlineCode",{parentName:"em"},"11.000")," steps I ended up at ",(0,l.kt)("inlineCode",{parentName:"em"},"11.000")," and not ",(0,l.kt)("inlineCode",{parentName:"em"},"13.000")," as I expected. So I am now comparing ",(0,l.kt)("strong",{parentName:"em"},"10.000 steps")," for the ",(0,l.kt)("strong",{parentName:"em"},"320")," model with ",(0,l.kt)("strong",{parentName:"em"},"11.000 steps")," for the ",(0,l.kt)("strong",{parentName:"em"},"640")," model")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"Accumulating evaluation results...\nDONE (t=0.03s).\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.474\nAverage Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.559\nAverage Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.548\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\nAverage Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.484\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.729\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.786\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.786\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\nAverage Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.786\n")),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Model name"),(0,l.kt)("th",{parentName:"tr",align:null},"AP (2000 steps)"),(0,l.kt)("th",{parentName:"tr",align:null},"AR (2000 steps)"),(0,l.kt)("th",{parentName:"tr",align:null},"AP (10000 steps)"),(0,l.kt)("th",{parentName:"tr",align:null},"AR (10000 steps)"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"SSD MobileNet V2 FPNLite 320x320"),(0,l.kt)("td",{parentName:"tr",align:null},"0.302"),(0,l.kt)("td",{parentName:"tr",align:null},"0.679"),(0,l.kt)("td",{parentName:"tr",align:null},"0.558"),(0,l.kt)("td",{parentName:"tr",align:null},"0.831")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"SSD MobileNet V2 FPNLite 640x640"),(0,l.kt)("td",{parentName:"tr",align:null},"0.234"),(0,l.kt)("td",{parentName:"tr",align:null},"0.595"),(0,l.kt)("td",{parentName:"tr",align:null},"0.548"),(0,l.kt)("td",{parentName:"tr",align:null},"0.786")))),(0,l.kt)("p",null,"So the ",(0,l.kt)("strong",{parentName:"p"},"640")," performed a worse at 2000 steps but almost got the the same level as the ",(0,l.kt)("strong",{parentName:"p"},"320")," model at 11.000 steps. But given the long training time this is a bit underwhelming. Going through the images - the detection rate did not even get that much better."),(0,l.kt)("p",null,"Letting the training running over night to get up to ",(0,l.kt)("strong",{parentName:"p"},"90.000")," steps"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},(0,l.kt)("inlineCode",{parentName:"p"},"INFO:tensorflow:Step 90000 per-step time 0.432s"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"Accumulating evaluation results...\nDONE (t=0.03s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.243\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.328\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.263\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.244\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.560\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.683\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.683\n")),(0,l.kt)("p",null,"And taking a look at the results from a ",(0,l.kt)("strong",{parentName:"p"},"20.000")," (",(0,l.kt)("inlineCode",{parentName:"p"},"left"),") steps training and the end result at ",(0,l.kt)("strong",{parentName:"p"},"90.000")," (",(0,l.kt)("inlineCode",{parentName:"p"},"right"),"). For all labels that already performed (at least a little bit) I can see an improvement in confidence. There have also been a few new hits (correct and false). But overall the training did lead to a more accurate model:"),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Tensorflow Model Zoo",src:t(92791).Z,width:"1589",height:"511"})),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Tensorflow Model Zoo",src:t(47186).Z,width:"1765",height:"533"})),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Tensorflow Model Zoo",src:t(3263).Z,width:"1812",height:"570"})),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Tensorflow Model Zoo",src:t(38093).Z,width:"1813",height:"586"})),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Tensorflow Model Zoo",src:t(82657).Z,width:"1743",height:"553"})),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Tensorflow Model Zoo",src:t(37329).Z,width:"1810",height:"483"})),(0,l.kt)("h2",{id:"labeling-done-right"},"Labeling Done Right!"),(0,l.kt)("p",null,"Ok, I think I figured it out. And it is pretty obvious now... Since I collected separate images for each label (character) I ended up only labeling on person per image - even if there was a group of them in there. This must have caused my model a lot of frustration due to ",(0,l.kt)("strong",{parentName:"p"},"false false-positive")," every time it recognized something correctly that wasn't labeled ... So now I went through my stash of images and re-did the labeling part - this time adding multiple labels to each image (where appropriated):"),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Tensorflow Model Zoo",src:t(50487).Z,width:"1106",height:"418"})),(0,l.kt)("p",null,"I deleted the trained model and re-run the training. I am getting a much better result - already, after only 10.000 steps:"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"INFO:tensorflow:Step 10000 per-step time 0.431s")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"Accumulating evaluation results...\nDONE (t=0.03s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.804\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.976\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.808\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.819\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.824\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.824\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.828\n")),(0,l.kt)("p",null,"And the detections follow suit - so I added another ",(0,l.kt)("strong",{parentName:"p"},"10.000")," steps and saw a slight decrease in numbers:"),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"INFO:tensorflow:Step 20000 per-step time 0.454s")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-bash"},"Accumulating evaluation results...\nDONE (t=0.03s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.798\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.820\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.820\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.820\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.600\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.824\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Tensorflow Model Zoo",src:t(53550).Z,width:"245",height:"170"})),(0,l.kt)("p",null,"And again I am surprised - while the detection rate for some labels stayed the same, it rose to the high nineties for others. While dropping blow 50% confidence where the detection rate was high before: "),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"Tensorflow Model Zoo",src:t(89503).Z,width:"1878",height:"695"})),(0,l.kt)("p",null,"The next steps would be to replace the trainings images of badly performing labels with higher quality ones. And in general add more, diverse trainings images for all labels and keep running trainings until the improvements start to level out."))}c.isMDXComponent=!0},53550:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/fascinating-4800c0ec46c5f6db588613ed9789d8c0.gif"},2859:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/Tensorflow_Model_Zoo_01-ef9e72aff44ba4ad3abcc4113db1647e.png"},10682:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/Tensorflow_Model_Zoo_02-b17c450b76fd099b70e388484fed1acd.png"},37901:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/Tensorflow_Model_Zoo_03-f384b42187cff8c10b6a58718ab568b3.png"},50487:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/Tensorflow_Model_Zoo_04-c2d027cc76db8d5d305626a100675b68.png"},89503:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/Tensorflow_Model_Zoo_05-8d60982f0870eb5c7117ce31dba91443.png"},92791:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/data_01-117e8948185adf35038ffb64d15eefe0.png"},47186:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/geordi_01-a2236b8129eeec2b6272108e3b6fcf42.png"},34610:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-8629210580d5b66cf728356357923b9f.jpg"},3263:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/picard_01-25883b411ebbe46e5d6913995c635031.png"},38093:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/riker_01-62342b48798c4701cee8c1e01e1c00b1.png"},82657:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/troi_02-98b4b85537965a1b93fde139d48dbbf7.png"},37329:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/worf_01-163ea6c85c9c506615511b77bee6f76f.png"}}]);