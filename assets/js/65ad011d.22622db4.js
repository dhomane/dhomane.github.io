"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[28850],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>m});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},d=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},g=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),g=c(a),m=r,f=g["".concat(l,".").concat(m)]||g[m]||p[m]||o;return a?n.createElement(f,i(i({ref:t},d),{},{components:a})):n.createElement(f,i({ref:t},d))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=g;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var c=2;c<o;c++)i[c]=a[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}g.displayName="MDXCreateElement"},39872:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var n=a(87462),r=(a(67294),a(3905));const o={sidebar_position:4810,slug:"2023-01-03",title:"Tensorflow Tensorboard",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Tensorflow dashboard that allows you to track the network performance by accuracy and loss statistics."},i=void 0,s={unversionedId:"IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard/index",id:"IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard/index",title:"Tensorflow Tensorboard",description:"Tensorflow dashboard that allows you to track the network performance by accuracy and loss statistics.",source:"@site/docs/IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard/index.md",sourceDirName:"IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard",slug:"/IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard/2023-01-03",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard/2023-01-03",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"}],version:"current",sidebarPosition:4810,frontMatter:{sidebar_position:4810,slug:"2023-01-03",title:"Tensorflow Tensorboard",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Tensorflow dashboard that allows you to track the network performance by accuracy and loss statistics."},sidebar:"tutorialSidebar",previous:{title:"Distributed training with TensorFlow",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-04-tf-distributed-strategy/2023-01-04"},next:{title:"Tensorflow Serving REST API",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-02-tf-serve-own-models/2023-01-02"}},l={},c=[{value:"Adding Tensorboard",id:"adding-tensorboard",level:2},{value:"Starting Tensorboard",id:"starting-tensorboard",level:2},{value:"Tracking Progress",id:"tracking-progress",level:2},{value:"Displaying Image Datasets",id:"displaying-image-datasets",level:2},{value:"Logging arbitrary Image Data",id:"logging-arbitrary-image-data",level:3},{value:"Confusion Matrix",id:"confusion-matrix",level:3}],d={toc:c};function p(e){let{components:t,...o}=e;return(0,r.kt)("wrapper",(0,n.Z)({},d,o,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Guangzhou, China",src:a(84027).Z,width:"1500",height:"662"})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#adding-tensorboard"},"Adding Tensorboard")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#starting-tensorboard"},"Starting Tensorboard")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#tracking-progress"},"Tracking Progress")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#displaying-image-datasets"},"Displaying Image Datasets"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#logging-arbitrary-image-data"},"Logging arbitrary Image Data")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#confusion-matrix"},"Confusion Matrix"))))),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/mpolinowski/tf-serving"},"Github Repository")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://www.tensorflow.org/tensorboard"},"Tensorboard")," is - since Tensorflow 2.0 - a build-in model learning dashboard that we can use to track the network performance by accuracy and loss statistics. I want to take my previous project ",(0,r.kt)("a",{parentName:"p",href:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-02-tf-serve-own-models/2023-01-02"},"Feature Detection based on the MNIST Fashion Dataset")," and add Tensorboard to optimize my neural network."),(0,r.kt)("h2",{id:"adding-tensorboard"},"Adding Tensorboard"),(0,r.kt)("p",null,"I will start with the simple network layout that is used by the ",(0,r.kt)("a",{parentName:"p",href:"https://www.tensorflow.org/tfx/tutorials/serving/rest_simple"},"official Tensorflow tutorial"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"classifier = tf.keras.Sequential([\n  tf.keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3, strides=2, activation='relu', name='Conv1'),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(10, name='Dense')\n])\n\nclassifier.compile(optimizer='adam', \n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n")),(0,r.kt)("p",null,"Now before starting the training we have to add two lines to initialize Tensorboard and insert this callback into our training:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},'# configuring tensorboard\nlog_dir="tensorboard/logs/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\n# model training\nclassifier.fit(X_train, y_train, epochs=EPOCHS, callbacks=[tensorboard_callback])\n')),(0,r.kt)("h2",{id:"starting-tensorboard"},"Starting Tensorboard"),(0,r.kt)("p",null,"To execute Tensorboard run the following command in your terminal or add the following line to the end of your training code:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},'# execute tensorboard\nos.system("tensorboard --logdir tensorboard/logs")\n')),(0,r.kt)("p",null,"This will serve Tensorboard on port ",(0,r.kt)("inlineCode",{parentName:"p"},"6006"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\nTensorBoard 2.11.0 at http://localhost:6006/ (Press CTRL+C to quit)\n")),(0,r.kt)("p",null,"A brief overview of the dashboards shown (tabs in top navigation bar):"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"The Scalars dashboard")," shows how the loss and metrics change with every epoch. You can use it to also track training speed, learning rate, and other scalar values."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"The Graphs dashboard")," helps you visualize your model. In this case, the Keras graph of layers is shown which can help you ensure it is built correctly."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"The Distributions and Histograms dashboards")," show the distribution of a Tensor over time. This can be useful to visualize weights and biases and verify that they are changing in an expected way.")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow Tensorboard",src:a(31040).Z,width:"1222",height:"790"})),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow Tensorboard",src:a(54897).Z,width:"930",height:"840"})),(0,r.kt)("h2",{id:"tracking-progress"},"Tracking Progress"),(0,r.kt)("p",null,"Changing to a slightly more complicated network:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"## second attempt\nclassifier = tf.keras.Sequential([\n  tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (28,28,1)),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(64, activation = 'relu'),\n  tf.keras.layers.Dense(10, activation = 'softmax')\n])\n")),(0,r.kt)("p",null,"The first attempt in green and the second in orange it is already very obvious that the latter performs a lot better:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow Tensorboard",src:a(97605).Z,width:"1099",height:"894"})),(0,r.kt)("p",null,"So add even more complexity and see what happens:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"## third attempt\nclassifier = tf.keras.Sequential([\n  tf.keras.layers.Conv2D(6, (5,5), activation = 'relu', input_shape = (28,28,1)),\n  tf.keras.layers.AveragePooling2D(),\n  tf.keras.layers.Conv2D(16, (5,5), activation = 'relu'),\n  tf.keras.layers.AveragePooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(120, activation = 'relu'),\n  tf.keras.layers.Dense(84, activation = 'relu'),\n  tf.keras.layers.Dense(10, activation = 'softmax')\n])\n")),(0,r.kt)("p",null,"We can see that this network (blue) roughly performs as well as the first attempt network (green) - in this case I would continue working with the second network (orange) as it performs significantly better:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow Tensorboard",src:a(31180).Z,width:"1099",height:"897"})),(0,r.kt)("h2",{id:"displaying-image-datasets"},"Displaying Image Datasets"),(0,r.kt)("p",null,"To be able to inspect images from our dataset in Tensorboard we need to add an ",(0,r.kt)("inlineCode",{parentName:"p"},"file_writer"),". The following will take the first image of the training dataset and make it available to Tensorboard:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},'# configuring tensorboard\n## set log data location\nlog_dir="tensorboard/logs/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")\n## create a file writer for the log directory\nfile_writer = tf.summary.create_file_writer(log_dir)\n## reshape the first training image\nimg = np.reshape(X_train[0], (-1, 28, 28, 1))\n## using the file writer to log the reshaped image\nwith file_writer.as_default():\n  tf.summary.image("Training data", img, step=0)\n## create Tensorboard callback\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n')),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow Tensorboard",src:a(58562).Z,width:"1095",height:"682"})),(0,r.kt)("h3",{id:"logging-arbitrary-image-data"},"Logging arbitrary Image Data"),(0,r.kt)("p",null,"In the code below, you'll log the first 25 images as a nice grid using matplotlib's ",(0,r.kt)("inlineCode",{parentName:"p"},"subplot()")," function:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},'# configuring tensorboard\n## set log data location\nlog_dir="tensorboard/logs/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")\n## create a file writer for the log directory\nfile_writer = tf.summary.create_file_writer(log_dir)\n\ndef plot_to_image(figure):\n  # Converts the matplotlib plot specified by \'figure\' to a PNG image and\n  # returns it. The supplied figure is closed and inaccessible after this call.\n  # Save the plot to a PNG in memory.\n  buf = io.BytesIO()\n  plt.savefig(buf, format=\'png\')\n  # Closing the figure prevents it from being displayed directly inside\n  # the notebook.\n  plt.close(figure)\n  buf.seek(0)\n  # Convert PNG buffer to TF image\n  image = tf.image.decode_png(buf.getvalue(), channels=4)\n  # Add the batch dimension\n  image = tf.expand_dims(image, 0)\n  return image\n\ndef image_grid():\n  # Return a 5x5 grid of the MNIST images as a matplotlib figure.\n  # Create a figure to contain the plot.\n  figure = plt.figure(figsize=(10,10))\n  for i in range(25):\n    # Start next subplot.\n    plt.subplot(5, 5, i + 1, title=class_names[y_train[i]])\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_train[i], cmap=plt.cm.binary)\n\n  return figure\n\n# Prepare the plot\nfigure = image_grid()\n# Convert to image and log\nwith file_writer.as_default():\n  tf.summary.image("Training data", plot_to_image(figure), step=0)\n')),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow Tensorboard",src:a(2086).Z,width:"1349",height:"886"})),(0,r.kt)("h3",{id:"confusion-matrix"},"Confusion Matrix"),(0,r.kt)("p",null,"When training a classifier, it's useful to see the confusion matrix. The confusion matrix gives you detailed knowledge of how your classifier is performing on test data. Define a function that calculates the confusion matrix:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},'def plot_confusion_matrix(cm, class_names):\n  """\n  Returns a matplotlib figure containing the plotted confusion matrix.\n\n  Args:\n    cm (array, shape = [n, n]): a confusion matrix of integer classes\n    class_names (array, shape = [n]): String names of the integer classes\n  """\n  figure = plt.figure(figsize=(8, 8))\n  plt.imshow(cm, interpolation=\'nearest\', cmap=plt.cm.Blues)\n  plt.title("Confusion Matrix")\n  plt.colorbar()\n  tick_marks = np.arange(len(class_names))\n  plt.xticks(tick_marks, class_names, rotation=45)\n  plt.yticks(tick_marks, class_names)\n\n  # Compute the labels from the normalized confusion matrix.\n  labels = np.around(cm.astype(\'float\') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n\n  # Use white text if squares are dark; otherwise black.\n  threshold = cm.max() / 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    color = "white" if cm[i, j] > threshold else "black"\n    plt.text(j, i, labels[i, j], horizontalalignment="center", color=color)\n\n  plt.tight_layout()\n  plt.ylabel(\'True label\')\n  plt.xlabel(\'Predicted label\')\n  return figure\n\nfile_writer_cm = tf.summary.create_file_writer(log_dir + \'/cm\')\n\n\ndef log_confusion_matrix(epoch, logs):\n  # Use the model to predict the values from the validation dataset.\n  test_pred_raw = classifier.predict(X_test)\n  test_pred = np.argmax(test_pred_raw, axis=1)\n\n  # Calculate the confusion matrix.\n  cm = confusion_matrix(y_test, test_pred)\n  # Log the confusion matrix as an image summary.\n  figure = plot_confusion_matrix(cm, class_names=class_names)\n  cm_image = plot_to_image(figure)\n\n  # Log the confusion matrix as an image summary.\n  with file_writer_cm.as_default():\n    tf.summary.image("Confusion Matrix", cm_image, step=epoch)\n\n# Define the per-epoch callback.\ncm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n')),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow Tensorboard",src:a(78653).Z,width:"1386",height:"899"})))}p.isMDXComponent=!0},31040:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Tensorflow_Tensorboard_01-f30dc70840228c4f81d5d7fdca28255c.png"},54897:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Tensorflow_Tensorboard_02-cd0a7023b00f92cec121441d89159761.png"},97605:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Tensorflow_Tensorboard_04-e707abf628dd6f6bd6cbf9f599d60f40.png"},31180:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Tensorflow_Tensorboard_05-7b14f5b930e23630363b1046bbab089c.png"},58562:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Tensorflow_Tensorboard_06-ac6231616103409b859d871a0c46569e.png"},2086:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Tensorflow_Tensorboard_07-c06122b76b3be0f47e53c8a6c0883298.png"},78653:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Tensorflow_Tensorboard_08-2c2beb896e41d5f9665a64a869f4d900.png"},84027:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-296769d73822f07b0ac5dc952f56bfa1.jpg"}}]);