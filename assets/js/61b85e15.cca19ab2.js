"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[24483],{3905:(e,a,n)=>{n.d(a,{Zo:()=>p,kt:()=>h});var t=n(67294);function r(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function i(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),n.push.apply(n,t)}return n}function o(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?i(Object(n),!0).forEach((function(a){r(e,a,n[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))}))}return e}function s(e,a){if(null==e)return{};var n,t,r=function(e,a){if(null==e)return{};var n,t,r={},i=Object.keys(e);for(t=0;t<i.length;t++)n=i[t],a.indexOf(n)>=0||(r[n]=e[n]);return r}(e,a);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)n=i[t],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var c=t.createContext({}),l=function(e){var a=t.useContext(c),n=a;return e&&(n="function"==typeof e?e(a):o(o({},a),e)),n},p=function(e){var a=l(e.components);return t.createElement(c.Provider,{value:a},e.children)},m={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},d=t.forwardRef((function(e,a){var n=e.components,r=e.mdxType,i=e.originalType,c=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),d=l(n),h=r,u=d["".concat(c,".").concat(h)]||d[h]||m[h]||i;return n?t.createElement(u,o(o({ref:a},p),{},{components:n})):t.createElement(u,o({ref:a},p))}));function h(e,a){var n=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=d;var s={};for(var c in a)hasOwnProperty.call(a,c)&&(s[c]=a[c]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var l=2;l<i;l++)o[l]=n[l];return t.createElement.apply(null,o)}return t.createElement.apply(null,n)}d.displayName="MDXCreateElement"},43573:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>c,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>s,toc:()=>l});var t=n(87462),r=(n(67294),n(3905));const i={sidebar_position:5020,slug:"2022-05-28",title:"Hashicorp Nomad to set up an Elasticsearch Cluster Part II",authors:"mpolinowski",tags:["Nomad","Consul","LINUX","Elasticsearch"]},o=void 0,s={unversionedId:"DevOps/Hashicorp/2022-05-28-hashicorp-nomad-for-elastic-part-2/index",id:"DevOps/Hashicorp/2022-05-28-hashicorp-nomad-for-elastic-part-2/index",title:"Hashicorp Nomad to set up an Elasticsearch Cluster Part II",description:"Shen Zhen, China",source:"@site/docs/DevOps/Hashicorp/2022-05-28-hashicorp-nomad-for-elastic-part-2/index.md",sourceDirName:"DevOps/Hashicorp/2022-05-28-hashicorp-nomad-for-elastic-part-2",slug:"/DevOps/Hashicorp/2022-05-28-hashicorp-nomad-for-elastic-part-2/2022-05-28",permalink:"/docs/DevOps/Hashicorp/2022-05-28-hashicorp-nomad-for-elastic-part-2/2022-05-28",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/DevOps/Hashicorp/2022-05-28-hashicorp-nomad-for-elastic-part-2/index.md",tags:[{label:"Nomad",permalink:"/docs/tags/nomad"},{label:"Consul",permalink:"/docs/tags/consul"},{label:"LINUX",permalink:"/docs/tags/linux"},{label:"Elasticsearch",permalink:"/docs/tags/elasticsearch"}],version:"current",sidebarPosition:5020,frontMatter:{sidebar_position:5020,slug:"2022-05-28",title:"Hashicorp Nomad to set up an Elasticsearch Cluster Part II",authors:"mpolinowski",tags:["Nomad","Consul","LINUX","Elasticsearch"]},sidebar:"tutorialSidebar",previous:{title:"Hashicorp Nomad with NGINX Loadbalancer",permalink:"/docs/DevOps/Hashicorp/2022-05-29-hashicorp-nomad-with-nginx-loadbalancer/2022-05-29"},next:{title:"Hashicorp Nomad to set up an Elasticsearch Cluster",permalink:"/docs/DevOps/Hashicorp/2022-05-27-hashicorp-nomad-for-elastic/2022-05-27"}},c={},l=[{value:"Nomad Job",id:"nomad-job",level:2},{value:"Docker-Compose",id:"docker-compose",level:3},{value:"Job Specification",id:"job-specification",level:3}],p={toc:l};function m(e){let{components:a,...i}=e;return(0,r.kt)("wrapper",(0,t.Z)({},p,i,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Shen Zhen, China",src:n(24909).Z,width:"2230",height:"839"})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#kibana"},"Kibana"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#nomad-job"},"Nomad Job"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#docker-compose"},"Docker-Compose")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#job-specification"},"Job Specification"))))))),(0,r.kt)("h1",{id:"kibana"},"Kibana"),(0,r.kt)("p",null,"I already setup ",(0,r.kt)("a",{parentName:"p",href:"/docs/DevOps/Hashicorp/2022-05-27-hashicorp-nomad-for-elastic/2022-05-27"},"Elasticsearch")," and now want to add the Kibana Dashboard. To get started I first have to ",(0,r.kt)("inlineCode",{parentName:"p"},"exec")," into the Elasticsearch container - in my case it is called ",(0,r.kt)("inlineCode",{parentName:"p"},"elastic_container-e6d43a0a-300b-ffa7-55f8-7883bee7a412")," - and add my Kibana user login:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker exec -ti elastic_container-e6d43a0a-300b-ffa7-55f8-7883bee7a412 /bin/bash\n/usr/share/elasticsearch/bin/elasticsearch-reset-password --interactive --username kibana_system\n")),(0,r.kt)("p",null,"I will set the password to ",(0,r.kt)("inlineCode",{parentName:"p"},"mykibanapassword")," and will have to supply this in my ",(0,r.kt)("inlineCode",{parentName:"p"},"kibana.yml")," configuration file."),(0,r.kt)("h2",{id:"nomad-job"},"Nomad Job"),(0,r.kt)("h3",{id:"docker-compose"},"Docker-Compose"),(0,r.kt)("p",null,"I have been using a ",(0,r.kt)("inlineCode",{parentName:"p"},"docker-compose.yml")," file before to set up a ELK cluster. The Kibana part of looks like:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml"},'kibana:\n    container_name: kibana\n    restart: unless-stopped\n    build:\n      context: kibana/\n      args:\n        ELK_VERSION: $ELK_VERSION\n    volumes:\n      - type: bind\n        source: ./kibana/config/kibana.yml\n        target: /usr/share/kibana/config/kibana.yml\n        read_only: true\n    # ports:\n    #   - "5601:5601"\n    networks:\n      - wikinet\n    depends_on:\n      - elasticsearch\n')),(0,r.kt)("p",null,"And the ",(0,r.kt)("inlineCode",{parentName:"p"},"kibana.yml")," that is included in the image during the build process is:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml"},"---\n## Default Kibana configuration from Kibana base image.\n## https://github.com/elastic/kibana/blob/master/src/dev/build/tasks/os_packages/docker_generator/templates/kibana_yml.template.js\n#\nserver.name: kibana\nserver.host: 0.0.0.0\nserver.publicBaseUrl: https://my.kibana.com\nelasticsearch.hosts: [ \"http://elasticsearch:9200\" ]\nmonitoring.ui.container.elasticsearch.enabled: true\n\nelasticsearch.username: kibana_system\nelasticsearch.password: 'mykibanapassword'\n")),(0,r.kt)("h3",{id:"job-specification"},"Job Specification"),(0,r.kt)("p",null,"The translation into a Nomad job file is:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js"},'job "wiki_kibana" {\n  type        = "service"\n  datacenters = ["wiki_search"]\n\n  update {\n    max_parallel     = 1\n    health_check     = "checks"\n    min_healthy_time = "180s"\n    healthy_deadline = "5m"\n    progress_deadline = "10m"\n    auto_revert = true\n    auto_promote = true\n    canary = 1\n  }\n\n  group "wiki_kibana" {\n    count = 1\n\n    network {\n        port "ki_http" {\n              static = 5601\n          }\n    }\n\n    task "kibana_container" {\n      driver = "docker"\n      kill_timeout = "600s"\n      kill_signal = "SIGTERM"\n\n      template {\n          data = <<EOH\nserver.name: kibana\nserver.host: 0.0.0.0\nserver.publicBaseUrl: https://my.kibana.com\nelasticsearch.hosts: [ "http://my.server.ip:9200" ]\nmonitoring.ui.container.elasticsearch.enabled: true\nelasticsearch.username: kibana_system\nelasticsearch.password: \'mykibanapassword\'\n          EOH\n  \n          destination = "local/kibana/kibana.yml"\n        }\n\n      config {\n        network_mode = "host"\n        image = "docker.elastic.co/kibana/kibana:8.3.2"\n        command = "kibana"\n        ports = ["ki_http"]\n        volumes = [\n          "local/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml",\n        ]\n\n        ulimit {\n            memlock = "-1"\n            nofile  = "65536"\n            nproc   = "8192"\n          }\n      }\n\n      service {\n        name = "kibana"\n        check {\n          name     = "http-tcp"\n          port     = "ki_http"\n          type     = "tcp"\n          interval = "30s"\n          timeout  = "4s"\n        }\n        \n        # check {\n        #     name     = "rest-http"\n        #     type     = "http"\n        #     port     = "ki_http"\n        #     path     = "/"\n        #     interval = "30s"\n        #     timeout  = "4s"\n        #     header {\n        #       Authorization = ["Basic myelasticpassword"]\n        #     }\n        #   }\n        }\n  \n        resources {\n          cpu    = 1024\n          memory = 2048\n        }\n    }\n  }\n}\n')))}m.isMDXComponent=!0},24909:(e,a,n)=>{n.d(a,{Z:()=>t});const t=n.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-6c1edb088dfea3a7d39f8eebb8e9dc23.jpg"}}]);