"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[11933],{3905:(e,n,t)=>{t.d(n,{Zo:()=>l,kt:()=>u});var a=t(67294);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var c=a.createContext({}),p=function(e){var n=a.useContext(c),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},l=function(e){var n=p(e.components);return a.createElement(c.Provider,{value:n},e.children)},m={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},g=a.forwardRef((function(e,n){var t=e.components,i=e.mdxType,o=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),g=p(t),u=i,d=g["".concat(c,".").concat(u)]||g[u]||m[u]||o;return t?a.createElement(d,r(r({ref:n},l),{},{components:t})):a.createElement(d,r({ref:n},l))}));function u(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var o=t.length,r=new Array(o);r[0]=g;var s={};for(var c in n)hasOwnProperty.call(n,c)&&(s[c]=n[c]);s.originalType=e,s.mdxType="string"==typeof e?e:i,r[1]=s;for(var p=2;p<o;p++)r[p]=t[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,t)}g.displayName="MDXCreateElement"},43090:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>p});var a=t(87462),i=(t(67294),t(3905));const o={sidebar_position:6090,slug:"2021-12-04",title:"OpenCV Image Objects",authors:"mpolinowski",tags:["Machine Learning","Python","OpenCV"]},r=void 0,s={unversionedId:"IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/index",id:"IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/index",title:"OpenCV Image Objects",description:"Shenzhen, China",source:"@site/docs/IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects",slug:"/IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/2021-12-04",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/2021-12-04",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/index.md",tags:[{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Python",permalink:"/docs/tags/python"},{label:"OpenCV",permalink:"/docs/tags/open-cv"}],version:"current",sidebarPosition:6090,frontMatter:{sidebar_position:6090,slug:"2021-12-04",title:"OpenCV Image Objects",authors:"mpolinowski",tags:["Machine Learning","Python","OpenCV"]},sidebar:"tutorialSidebar",previous:{title:"OpenCV Face Detection and Privacy",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-12-05--opencv-face-detection/2021-12-05"},next:{title:"OpenCV Image Operations",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-12-03--opencv-image-operations/2021-12-03"}},c={},p=[{value:"Setup OpenCV",id:"setup-opencv",level:2},{value:"Image Operations",id:"image-operations",level:2},{value:"Contour Detection",id:"contour-detection",level:3},{value:"Bitwise Operation",id:"bitwise-operation",level:3},{value:"Merging Images",id:"merging-images",level:4},{value:"Select Colour Range",id:"select-colour-range",level:4},{value:"Section Masking",id:"section-masking",level:4}],l={toc:p};function m(e){let{components:n,...o}=e;return(0,i.kt)("wrapper",(0,a.Z)({},l,o,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Shenzhen, China",src:t(49103).Z,width:"2385",height:"919"})),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#setup-opencv"},"Setup OpenCV")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#image-operations"},"Image Operations"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#contour-detection"},"Contour Detection")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#bitwise-operation"},"Bitwise Operation"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#merging-images"},"Merging Images")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#select-colour-range"},"Select Colour Range")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#section-masking"},"Section Masking"))))))),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://github.com/mpolinowski/opencv-image-objects"},"Github Repo")),(0,i.kt)("h2",{id:"setup-opencv"},"Setup OpenCV"),(0,i.kt)("p",null,"Create and activate a virtual work environment:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"python -m venv .env\nsource .env/bin/activate\npython -m pip install --upgrade pip\n")),(0,i.kt)("p",null,"Add a file ",(0,i.kt)("inlineCode",{parentName:"p"},"dependencies.txt")," with all project ",(0,i.kt)("strong",{parentName:"p"},"pip dependencies"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"opencv-python\nnumpy\nmatplotlib\n")),(0,i.kt)("p",null,"Install all dependencies with:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"pip install -r dependencies.txt\n")),(0,i.kt)("h2",{id:"image-operations"},"Image Operations"),(0,i.kt)("h3",{id:"contour-detection"},"Contour Detection"),(0,i.kt)("p",null,"Contour in image is an outline on the objects present in the image. The significance of the objects depend on the requirement and threshold you choose."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"import cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimage = cv2.imread('resources/trafiko.jpg', cv2.IMREAD_UNCHANGED)\nimg_grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n# Set binary tresholds\nret, img_threshold = cv2.threshold(img_grayscale, 127, 255, cv2.THRESH_BINARY)\ncv2.imshow(\"Object Contours\", img_threshold)\n\n# Find contours\ncontours, _ = cv2.findContours(img_threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n\n# Create an empty image for contours\ncanvas = np.zeros(image.shape)\n\ni = 0\n\nfor contour in contours:\n    if i == 0:\n        i = 1\n        continue\n\n    # For each of the contours detected, the shape of the contours is\n    # approximated using approxPolyDP() function and the\n    # contours are drawn in the image using drawContours() function\n    approx = cv2.approxPolyDP(contour, 0.01*cv2.arcLength(contour, True), True)\n    # Draw polygons on the empty image\n    cv2.drawContours(canvas, [contour], 0, (0, 255, 0), 5)\n    # Find center of found shapes\n    M = cv2.moments(contour)\n    if M['m00'] != 0.0:\n        x = int(M['m10']/M['m00'])\n        y = int(M['m01']/M['m00'])\n    # Classifying shapes\n    if len(approx) == 3:\n       cv2.putText(canvas, 'Triangle', (x, y), cv2.QT_FONT_NORMAL, 0.6, (0, 255, 255), 2)\n    elif len(approx) == 4:\n       cv2.putText(canvas, 'Rectangle', (x, y), cv2.QT_FONT_NORMAL, 0.6, (255, 255, 255), 2)\n    elif len(approx) == 6:\n       cv2.putText(canvas, 'Hexagon', (x, y), cv2.QT_FONT_NORMAL, 0.6, (255, 0, 255), 2)\n    elif 6 < len(approx) < 15:\n       cv2.putText(canvas, 'Circle?', (x, y), cv2.QT_FONT_NORMAL, 0.6, (255, 255, 0), 2)\n\n# Display results\ncv2.imshow('Detected Shapes', canvas)\ncv2.imwrite('processed/shapes.jpg', canvas)\n\ncv2.waitKey(5000)\ncv2.destroyAllWindows()\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"OpenCV Image Objects",src:t(76625).Z,width:"1411",height:"707"})),(0,i.kt)("h3",{id:"bitwise-operation"},"Bitwise Operation"),(0,i.kt)("p",null,"To manipulating a given image or extract parts of it based on the requirement use of bitwise operators in OpenCV:"),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},(0,i.kt)("inlineCode",{parentName:"p"},"bitwise_and(source1_array, source2_array, destination_array, mask)"))),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"source1_array")," is the array corresponding to the first input image on which bitwise and operation is to be performed."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"source2_array")," is the array corresponding to the second input image on which bitwise and operation is to be performed."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"destination_array")," is the resulting array by performing bitwise operation on the array corresponding to the first input image and the array corresponding to the second input image"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},"mask")," is the mask operation to be performed on the resulting image and it is optional.")),(0,i.kt)("h4",{id:"merging-images"},"Merging Images"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"import cv2\nimport numpy as np\n\nimage_left = cv2.imread('resources/left.jpg')\nimage_right = cv2.imread('resources/right.jpg')\n\n#using bitwise_and operation on the given two images\nmerged_image = cv2.bitwise_and(image_left, image_right, mask = None)\n#displaying the merged image as the output on the screen\ncv2.imshow('Left Image', image_left)\ncv2.imshow('Right Image', image_right)\ncv2.imshow('Merged Image', merged_image)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"OpenCV Image Objects",src:t(13660).Z,width:"1568",height:"337"})),(0,i.kt)("h4",{id:"select-colour-range"},"Select Colour Range"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"import cv2\nimport numpy as np\n\nimage_left = cv2.imread('resources/left.jpg')\nimage_right = cv2.imread('resources/right.jpg')\n\nimage_colour = cv2.imread('resources/on_fire.jpg')\n\n# Using bitwise_and operation on the given two images\nmerged_image = cv2.bitwise_and(image_left, image_right, mask = None)\n\n# Displaying the merged image as the output on the screen\ncv2.imshow('Left Image', image_left)\ncv2.imshow('Right Image', image_right)\ncv2.imshow('Merged Image', merged_image)\n\n# Working with colour masks\nrgb_conversion = cv2.cvtColor(image_colour, cv2.COLOR_BGR2RGB)\n\n# Define colour range in RGB\ndark_yellow = np.array([252, 170, 0])\nbright_yellow = np.array([255, 205, 114])\n\n# Select pixel within the defined colour range\nmask_yellow = cv2.inRange(rgb_conversion, dark_yellow, bright_yellow)\ncolour_range = cv2.bitwise_and(image_colour, image_colour, mask=mask_yellow)\n\ncv2.imshow('Original Image', image_colour)\ncv2.imshow('Colour Range Selection', colour_range)\n\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n")),(0,i.kt)("h4",{id:"section-masking"},"Section Masking"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"# Bitwise masking\nimage_colour_copy = image_colour.copy()\n# Create mask with 100 rows, 300 columns and 3 colour channels\nmask = np.zeros((100 , 300, 3))\n# pos = (600, 600)\n# set position of upper left corner and lower right corner of mask\nvar = image_colour_copy[200:(200+mask.shape[0]), 200:(200+mask.shape[1])] = mask\ncv2.imshow('Masked Section', image_colour_copy)\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"OpenCV Image Objects",src:t(16586).Z,width:"2146",height:"552"})))}m.isMDXComponent=!0},76625:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/OpenCV_Object_Detection_01-a45d1c10eeb7ddf7833c197e0beb63ea.png"},13660:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/OpenCV_Object_Detection_02-d8e415e3af43f6a97372c181b8433c9a.png"},16586:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/OpenCV_Object_Detection_03-8f8f3c41b87c397889a00bfc183f66dc.png"},49103:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-5a0b68587d9242bbb46a1f1aaab44216.jpg"}}]);