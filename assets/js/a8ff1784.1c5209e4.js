"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[52479],{3905:(e,t,n)=>{n.d(t,{Zo:()=>l,kt:()=>u});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function c(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?c(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):c(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},c=Object.keys(e);for(a=0;a<c.length;a++)n=c[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var c=Object.getOwnPropertySymbols(e);for(a=0;a<c.length;a++)n=c[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),d=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},l=function(e){var t=d(e.components);return a.createElement(s.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,c=e.originalType,s=e.parentName,l=i(e,["components","mdxType","originalType","parentName"]),h=d(n),u=r,m=h["".concat(s,".").concat(u)]||h[u]||p[u]||c;return n?a.createElement(m,o(o({ref:t},l),{},{components:n})):a.createElement(m,o({ref:t},l))}));function u(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var c=n.length,o=new Array(c);o[0]=h;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i.mdxType="string"==typeof e?e:r,o[1]=i;for(var d=2;d<c;d++)o[d]=n[d];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},5650:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>p,frontMatter:()=>c,metadata:()=>i,toc:()=>d});var a=n(87462),r=(n(67294),n(3905));const c={sidebar_position:6060,slug:"2021-12-07",title:"OpenCV Object Detection and Tracking",authors:"mpolinowski",tags:["Machine Learning","Python","OpenCV"]},o=void 0,i={unversionedId:"IoT-and-Machine-Learning/ML/2021-12-07--opencv-detection-and-tracking/index",id:"IoT-and-Machine-Learning/ML/2021-12-07--opencv-detection-and-tracking/index",title:"OpenCV Object Detection and Tracking",description:"Shenzhen, China",source:"@site/docs/IoT-and-Machine-Learning/ML/2021-12-07--opencv-detection-and-tracking/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2021-12-07--opencv-detection-and-tracking",slug:"/IoT-and-Machine-Learning/ML/2021-12-07--opencv-detection-and-tracking/2021-12-07",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-12-07--opencv-detection-and-tracking/2021-12-07",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2021-12-07--opencv-detection-and-tracking/index.md",tags:[{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Python",permalink:"/docs/tags/python"},{label:"OpenCV",permalink:"/docs/tags/open-cv"}],version:"current",sidebarPosition:6060,frontMatter:{sidebar_position:6060,slug:"2021-12-07",title:"OpenCV Object Detection and Tracking",authors:"mpolinowski",tags:["Machine Learning","Python","OpenCV"]},sidebar:"tutorialSidebar",previous:{title:"OpenCV Meanshift Algorithm for Object Tracking",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-12-08--opencv-meanshift-tracking/2021-12-08"},next:{title:"OpenCV Object Tracking",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking/2021-12-06"}},s={},d=[{value:"OpenCV Haarcascades",id:"opencv-haarcascades",level:2},{value:"Using Haarcascades to find Objects",id:"using-haarcascades-to-find-objects",level:3}],l={toc:d};function p(e){let{components:t,...c}=e;return(0,r.kt)("wrapper",(0,a.Z)({},l,c,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Shenzhen, China",src:n(99892).Z,width:"2385",height:"919"})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#opencv-haarcascades"},"OpenCV Haarcascades"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#using-haarcascades-to-find-objects"},"Using Haarcascades to find Objects"))))),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/mpolinowski/opencv-detection-and-tracking"},"Github Repo")),(0,r.kt)("h2",{id:"opencv-haarcascades"},"OpenCV Haarcascades"),(0,r.kt)("p",null,"To identify objects I am going to use the provided OpenCV Haarcascades from ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/opencv/opencv/tree/4.x/data/haarcascades"},"Github.com"),":"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/opencv/opencv/blob/4.x/data/haarcascades/haarcascade_fullbody.xml"},"haarcascade_fullbody.xml")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/opencv/opencv/blob/4.x/data/haarcascades/haarcascade_eye.xml"},"haarcascade_eye.xml")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/opencv/opencv/blob/4.x/data/haarcascades/haarcascade_frontalface_default.xml"},"haarcascade_frontalface_default.xml")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/opencv/opencv/blob/4.x/data/haarcascades/haarcascade_lowerbody.xml"},"haarcascade_lowerbody.xml")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/opencv/opencv/blob/4.x/data/haarcascades/haarcascade_upperbody.xml"},"haarcascade_upperbody.xml"))),(0,r.kt)("p",null,"You only need a few lines of code to perform an object detection on an image (image source ",(0,r.kt)("a",{parentName:"p",href:"https://www.pexels.com/"},"pexels.com"),"):"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import cv2\n\nimage = cv2.imread('resources/group_of_people.jpg')\n\ndetector = cv2.CascadeClassifier('cascades/haarcascade_fullbody.xml')\nimage_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\ndetections = detector.detectMultiScale(image_gray)\nprint('[INFO] People detected: ' + str(len(detections)))\n\nfor (x, y, w, h) in detections:\n    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n\ncv2.imshow('People', image)\n\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"OpenCV Object Detection and Tracking",src:n(34956).Z,width:"1880",height:"686"})),(0,r.kt)("h3",{id:"using-haarcascades-to-find-objects"},"Using Haarcascades to find Objects"),(0,r.kt)("p",null,"In the previous ",(0,r.kt)("a",{parentName:"p",href:"/docs/IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking/2021-12-06"},"Object Tracking Example")," I selected the object I wanted to track by hand. We can now use the OpenCV object detection feature to automatically find people in our video and return the coordinates for a bounding box:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import cv2\nimport sys\n\ntracker = cv2.legacy.TrackerCSRT_create()\n\nvideo = cv2.VideoCapture('resources/group_of_people_03.mp4')\nif not video.isOpened():\n    print('[ERROR] loading video')\n    sys.exit()\n\nok, frame = video.read()\nif not ok:\n    print('[ERROR] loading frame')\n    sys.exit()\n\ndetector = cv2.CascadeClassifier('cascades/haarcascade_fullbody.xml')\n\n\ndef detect():\n    while True:\n        ok, frame = video.read()\n        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n        detections = detector.detectMultiScale(frame_gray, minSize=(300, 300))\n        print('[INFO] people detected: ' + str(len(detections)))\n\n        for (x, y, w, h) in detections:\n            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n            cv2.imshow('Detections', frame)\n            cv2.waitKey(0)\n            cv2.destroyAllWindows()\n            if x > 0:\n                print('[INFO] bounding box calculated')\n                return x, y, w, h\n\n\nbbox = detect()\nprint(bbox)\n")),(0,r.kt)("p",null,"This code will search for a person inside the first frame of the image and return the bounding box coordinates once it found one (all videos are free stock from ",(0,r.kt)("a",{parentName:"p",href:"https://www.pexels.com/"},"pexels.com"),"):"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"OpenCV Object Detection and Tracking",src:n(61462).Z,width:"3840",height:"1072"})),(0,r.kt)("p",null,"Those coordinates can then be fed into the tracking algorithm that allows us to track the person recognized by OpenCV:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# initialize tracker with detected coordinates\nok = tracker.init(frame, bbox)\nif not ok:\n    print('[ERROR] loading tracker')\n# generate random colours for bounding box\ncolours = (randint(0, 255), randint(0, 255), randint(0, 255))\n\n# loop through all frames and apply tracker on detected object\nwhile True:\n    ok, frame = video.read()\n    if not ok:\n        print('[INFO] reached end of video')\n        break\n    # update bounding box in new frame using tracker\n    ok, bbox = tracker.update(frame)\n    if ok:\n        (x, y, w, h) = [int(v) for v in bbox]\n        cv2.rectangle(frame, (x, y), (x+w, y+h), colours, 5)\n        # show tracking / resize frame if necessary\n        resized = cv2.resize(frame, (1280, 720), interpolation=cv2.INTER_NEAREST)\n        cv2.imshow('Tracking', resized)\n        # press 'q' to break loop and close window\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n\n    else:\n        print('[WARNING] No Track')\n        # re-run detection if track was lost\n        bbox = detect()\n        # restart tracker if person detected\n        tracker = cv2.legacy.TrackerCSRT_create()\n        tracker.init(frame, bbox)\n")),(0,r.kt)("p",null,"With this code we are entirely dependent on the Haarcascade to select objects to track. We can adjust this by first selecting the initial object by hand and only handing the selection to the algorithm if the track fails:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# call detection function\n# if you want OpenCV to detect the initial object automatically\n# bbox = detect()\n# print(bbox)\n# or use the ROI selector to select initial object yourself\nbbox = cv2.selectROI(frame)\n")),(0,r.kt)("p",null,"Now the detection code is skipped and I am presented with the manual selector instead (all videos are free stock from ",(0,r.kt)("a",{parentName:"p",href:"https://www.pexels.com/"},"pexels.com"),"):"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"OpenCV Object Detection and Tracking",src:n(26978).Z,width:"1906",height:"774"})),(0,r.kt)("p",null,"The tracking algorithm will then take those coordinates and start tracking the region of interest. If it looses track it will trigger the object detection function to reacquire it:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"OpenCV Object Detection and Tracking",src:n(12336).Z,width:"640",height:"360"})))}p.isMDXComponent=!0},34956:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/OpenCV-Detection-and-Tracking_01-2a7bed1acc45654e5dc59f39cefbc916.jpg"},61462:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/OpenCV-Detection-and-Tracking_02-698543d09b0fc5efb2aa101164a0ad45.jpg"},26978:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/OpenCV-Detection-and-Tracking_03-6901ebc8ff4bbfc3316fbc20a44b1e0f.png"},12336:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/OpenCV-Detection-and-Tracking_04-832c4cd366315eeb32c20b80be42b3b1.gif"},99892:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-5a0b68587d9242bbb46a1f1aaab44216.jpg"}}]);