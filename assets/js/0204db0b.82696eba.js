"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[78571],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>m});var r=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var i=r.createContext({}),p=function(e){var t=r.useContext(i),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},u=function(e){var t=p(e.components);return r.createElement(i.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},d=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,i=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),d=p(n),m=a,g=d["".concat(i,".").concat(m)]||d[m]||c[m]||o;return n?r.createElement(g,s(s({ref:t},u),{},{components:n})):r.createElement(g,s({ref:t},u))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,s=new Array(o);s[0]=d;var l={};for(var i in t)hasOwnProperty.call(t,i)&&(l[i]=t[i]);l.originalType=e,l.mdxType="string"==typeof e?e:a,s[1]=l;for(var p=2;p<o;p++)s[p]=n[p];return r.createElement.apply(null,s)}return r.createElement.apply(null,n)}d.displayName="MDXCreateElement"},10582:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>i,contentTitle:()=>s,default:()=>c,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var r=n(87462),a=(n(67294),n(3905));const o={sidebar_position:9070,slug:"2022-06-27",title:"Web Scraping Essentials with Python",authors:"mpolinowski",tags:["Python"]},s=void 0,l={unversionedId:"Development/Python/2022-06-27-python-web-scraping/index",id:"Development/Python/2022-06-27-python-web-scraping/index",title:"Web Scraping Essentials with Python",description:"Sham Sui Po, Hong Kong",source:"@site/docs/Development/Python/2022-06-27-python-web-scraping/index.md",sourceDirName:"Development/Python/2022-06-27-python-web-scraping",slug:"/Development/Python/2022-06-27-python-web-scraping/2022-06-27",permalink:"/docs/Development/Python/2022-06-27-python-web-scraping/2022-06-27",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Development/Python/2022-06-27-python-web-scraping/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"}],version:"current",sidebarPosition:9070,frontMatter:{sidebar_position:9070,slug:"2022-06-27",title:"Web Scraping Essentials with Python",authors:"mpolinowski",tags:["Python"]},sidebar:"tutorialSidebar",previous:{title:"Python - Video Processing with OpenCV",permalink:"/docs/Development/Python/2022-09-17-python-video-processing/2022-09-17"},next:{title:"Introduction to PyScript",permalink:"/docs/Development/Python/2022-06-01-python-pyscript/2022-06-01"}},i={},p=[{value:"Web Scraping Tools",id:"web-scraping-tools",level:2},{value:"Using Requests to Download Web Content",id:"using-requests-to-download-web-content",level:3},{value:"Scrape Web Content with Beautiful Soup 4",id:"scrape-web-content-with-beautiful-soup-4",level:3}],u={toc:p};function c(e){let{components:t,...o}=e;return(0,a.kt)("wrapper",(0,r.Z)({},u,o,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Sham Sui Po, Hong Kong",src:n(96721).Z,width:"1500",height:"548"})),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#web-scraping-tools"},"Web Scraping Tools"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#using-requests-to-download-web-content"},"Using Requests to Download Web Content")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#scrape-web-content-with-beautiful-soup-4"},"Scrape Web Content with Beautiful Soup 4"))))),(0,a.kt)("h2",{id:"web-scraping-tools"},"Web Scraping Tools"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://requests.readthedocs.io/en/latest/"},"Requests")," is an elegant and simple HTTP library for Python, built for human beings."),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://beautiful-soup-4.readthedocs.io/en/latest/"},"Beautiful Soup")," is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree.")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pip install requests bs4\n")),(0,a.kt)("h3",{id:"using-requests-to-download-web-content"},"Using Requests to Download Web Content"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"import requests\n\nurl = 'http://www.python.org'\nresponse = requests.get(url)\n\nprint('INFO :: Retrieving Web Content Successful?', response.ok)\nprint('INFO :: HTTP Status Code:', response.status_code)\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"python main.py\nINFO :: Retrieving Web Content Successful? True\nINFO :: HTTP Status Code: 200\n")),(0,a.kt)("p",null,"The web content is send as bytes and needs to be decoded into a string before further processing:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"# Return bytes and decode to string\nprint(response.content.decode())\n# Return content directly as unicode\nprint(response.text)\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"# Get response headers\nprint(response.headers)\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"{'Connection': 'keep-alive', 'Content-Length': '50171', 'Server': 'nginx', 'Content-Type': 'text/html; charset=utf-8', 'X-Frame-Options': 'DENY', 'Via': '1.1 vegur, 1.1 varnish, 1.1 varnish', 'Accept-Ranges': 'bytes', 'Date': 'Sat, 06 Aug 2022 10:46:40 GMT', 'Age': '3190', 'X-Served-By': 'cache-iad-kiad7000112-IAD, cache-nrt-rjtf7700056-NRT', 'X-Cache': 'HIT, HIT', 'X-Cache-Hits': '390, 2623', 'X-Timer': 'S1659782801.626291,VS0,VE0', 'Vary': 'Cookie', 'Strict-Transport-Security': 'max-age=63072000; includeSubDomains'}\n")),(0,a.kt)("h3",{id:"scrape-web-content-with-beautiful-soup-4"},"Scrape Web Content with Beautiful Soup 4"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"import requests\nfrom bs4 import BeautifulSoup\n\nurl = 'https://wiki.instar.com/en/Web_User_Interface/1440p_Series/Smarthome/MQTT/'\nresponse = requests.get(url)\n\nprint('INFO :: Retrieving Web Content Successful?', response.ok)\nprint('INFO :: HTTP Status Code:', response.status_code)\n\nhtml = response.text\n\nsoup = BeautifulSoup(html, 'html.parser')\n")),(0,a.kt)("p",null,"BS allows us to select content based on HTML tags, ID or classes:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"print('INFO :: Page Title', soup.title)\nprint('INFO :: Page Header', soup.body.h1)\n")),(0,a.kt)("p",null,"This method always returns only the first hit:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'python main.py\nINFO :: Retrieving Web Content Successful? True\nINFO :: HTTP Status Code: 200\nINFO :: Page Title <title data-react-helmet="true">Smarthome Menu // INSTAR MQTT Broker</title>\nINFO :: Page Header <h1>INSTAR Wiki 2.5</h1>\n')),(0,a.kt)("p",null,"If you want to return all of a type you need to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"find_all")," method:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"import requests\nfrom bs4 import BeautifulSoup\n\nurl = 'https://wiki.instar.com/enhttps://wiki.instar.com/en/Advanced_User/INSTAR_MQTT_Broker/MQTTv5_API/'\nresponse = requests.get(url)\n\nprint('INFO :: Retrieving Web Content Successful?', response.ok)\nprint('INFO :: HTTP Status Code:', response.status_code)\n\nhtml = response.text\n\nsoup = BeautifulSoup(html, 'html.parser')\n\nfor el in soup.find_all('td', attrs={'class': 'MuiTableCell-body'}):\n    rows = el.get_text()\n    print(rows)\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'python main.py\nINFO :: Retrieving Web Content Successful? True\nINFO :: HTTP Status Code: 200\nCategory: Network\n\nnetwork/config/dhcp\n{"val":"1"}, {"val":"0"}\n\nnetwork/config/ipaddr\n{"val":"192.168.178.23"}\n\nnetwork/config/netmask\n{"val":"255.255.255.0"}\n\nnetwork/config/gateway\n{"val":"192.168.178.1"}\n\nnetwork/config/fdnsip\n{"val":"192.168.178.1"}\n\nnetwork/config/sdnsip\n{"val":"192.168.178.2"}\n\n...\n')),(0,a.kt)("p",null,"To find multiple tags and return them as a list:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"print(soup.find_all(['div', 'p']))\n")),(0,a.kt)("p",null,"Find elements by ID:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"print(soup.find_all('div', id='quick-start'))\n")),(0,a.kt)("p",null,"Find elements by Class:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"print(soup.find_all('a', class_='reference external'))\n")),(0,a.kt)("p",null,"Find all links on a page:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"print (soup.find_all('a', href=True))\n")),(0,a.kt)("p",null,"Strip the HTML:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-py"},"links = soup.find_all('a', href=True)\n\nfor link in links:\n    print(link.get('href'))\n")))}c.isMDXComponent=!0},96721:(e,t,n)=>{n.d(t,{Z:()=>r});const r=n.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-5f44d483789c3ce79f05418f930f5cd2.jpg"}}]);