"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[16743],{3905:(e,n,t)=>{t.d(n,{Zo:()=>u,kt:()=>m});var a=t(67294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function s(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=a.createContext({}),c=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):s(s({},n),e)),t},u=function(e){var n=c(e.components);return a.createElement(l.Provider,{value:n},e.children)},d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},p=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),p=c(t),m=r,h=p["".concat(l,".").concat(m)]||p[m]||d[m]||o;return t?a.createElement(h,s(s({ref:n},u),{},{components:t})):a.createElement(h,s({ref:n},u))}));function m(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=t.length,s=new Array(o);s[0]=p;var i={};for(var l in n)hasOwnProperty.call(n,l)&&(i[l]=n[l]);i.originalType=e,i.mdxType="string"==typeof e?e:r,s[1]=i;for(var c=2;c<o;c++)s[c]=t[c];return a.createElement.apply(null,s)}return a.createElement.apply(null,t)}p.displayName="MDXCreateElement"},34407:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>c});var a=t(87462),r=(t(67294),t(3905));const o={sidebar_position:8060,slug:"2021-08-05",title:"Hashicorp Consul Refresher - Service Discovery",authors:"mpolinowski",tags:["Consul","Linux"]},s=void 0,i={unversionedId:"DevOps/Hashicorp/2021-08-05--hashicorp-consul-service-discovery/index",id:"DevOps/Hashicorp/2021-08-05--hashicorp-consul-service-discovery/index",title:"Hashicorp Consul Refresher - Service Discovery",description:"Cheung Chau, Hongkong",source:"@site/docs/DevOps/Hashicorp/2021-08-05--hashicorp-consul-service-discovery/index.md",sourceDirName:"DevOps/Hashicorp/2021-08-05--hashicorp-consul-service-discovery",slug:"/DevOps/Hashicorp/2021-08-05--hashicorp-consul-service-discovery/2021-08-05",permalink:"/docs/DevOps/Hashicorp/2021-08-05--hashicorp-consul-service-discovery/2021-08-05",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/DevOps/Hashicorp/2021-08-05--hashicorp-consul-service-discovery/index.md",tags:[{label:"Consul",permalink:"/docs/tags/consul"},{label:"Linux",permalink:"/docs/tags/linux"}],version:"current",sidebarPosition:8060,frontMatter:{sidebar_position:8060,slug:"2021-08-05",title:"Hashicorp Consul Refresher - Service Discovery",authors:"mpolinowski",tags:["Consul","Linux"]},sidebar:"tutorialSidebar",previous:{title:"Hashicorp Consul Refresher - Loadbalancing with Fabio",permalink:"/docs/DevOps/Hashicorp/2021-08-06--hashicorp-consul-fabio-loadbalancing/2021-08-06"},next:{title:"Hashicorp Nomad Refresher - Job Specifications",permalink:"/docs/DevOps/Hashicorp/2021-08-04--hashicorp-nomad-job-specifications/2021-08-04"}},l={},c=[{value:"Installation",id:"installation",level:2},{value:"Debian11",id:"debian11",level:3},{value:"RHEL8",id:"rhel8",level:3},{value:"Consul Commandline Autocompletion",id:"consul-commandline-autocompletion",level:4},{value:"Test-Running",id:"test-running",level:2},{value:"Service Configuration",id:"service-configuration",level:2},{value:"Run Consul as a Service",id:"run-consul-as-a-service",level:2},{value:"Needed Ports",id:"needed-ports",level:3},{value:"Service Configuration",id:"service-configuration-1",level:2},{value:"Problems",id:"problems",level:3},{value:"Registering a Service in Nomad",id:"registering-a-service-in-nomad",level:2},{value:"Default Consul Configuration",id:"default-consul-configuration",level:2},{value:"Consul Service Error Message",id:"consul-service-error-message",level:2}],u={toc:c};function d(e){let{components:n,...o}=e;return(0,r.kt)("wrapper",(0,a.Z)({},u,o,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Cheung Chau, Hongkong",src:t(42723).Z,width:"1500",height:"386"})),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"This article is a bit messy... a lot of things changed since the ",(0,r.kt)("inlineCode",{parentName:"p"},"0.x")," releases of Consul and I ran into a few bumps on the way. A lot of things learnt, errors and solution documented. But I will have to write up a clean version of this to have a step-by-step guide for future reference.")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#installation"},"Installation"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#debian11"},"Debian11")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#rhel8"},"RHEL8"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#consul-commandline-autocompletion"},"Consul Commandline Autocompletion")))))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#test-running"},"Test-Running")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#service-configuration"},"Service Configuration")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#run-consul-as-a-service"},"Run Consul as a Service"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#needed-ports"},"Needed Ports")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#service-configuration-1"},"Service Configuration"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#problems"},"Problems")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#registering-a-service-in-nomad"},"Registering a Service in Nomad")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#default-consul-configuration"},"Default Consul Configuration")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#consul-service-error-message"},"Consul Service Error Message"))),(0,r.kt)("p",null,"Nomad schedules workloads of various types across a cluster of generic hosts. Because of this, placement is not known in advance and you will need to use service discovery to connect tasks to other services deployed across your cluster. Nomad integrates with Consul to provide service discovery and monitoring."),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://www.consul.io/"},"Consul")," allows services to easily register themselves in a central catalog when they start up. When an application or service needs to communicate with another component, the central catalog can be queried using either an API or DNS interface to provide the required addresses."),(0,r.kt)("h2",{id:"installation"},"Installation"),(0,r.kt)("h3",{id:"debian11"},"Debian11"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'curl -fsSL https://apt.releases.hashicorp.com/gpg | apt-key add -\napt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"\napt-get update && apt-get install consul\n')),(0,r.kt)("h3",{id:"rhel8"},"RHEL8"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"sudo yum install -y yum-utils\nsudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo\nsudo yum -y install consul\n")),(0,r.kt)("h4",{id:"consul-commandline-autocompletion"},"Consul Commandline Autocompletion"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"consul -autocomplete-install\ncomplete -C /usr/bin/consul consul\n")),(0,r.kt)("h2",{id:"test-running"},"Test-Running"),(0,r.kt)("p",null,"You can start the Consul Agent with ",(0,r.kt)("a",{parentName:"p",href:"https://www.consul.io/docs/agent/options#command-line-options"},"configuration flags"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"consul agent -datacenter=instaryun -data-dir=/opt/consul -bind '{{ GetInterfaceIP \"enp2s0\" }}'\n")),(0,r.kt)("p",null,"To get started I will execute the service in DEV mode on my master:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"consul agent -dev -datacenter=instaryun -data-dir=/opt/consul -bind '{{ GetInterfaceIP \"enp3s0\" }}'\n")),(0,r.kt)("p",null,"The Consul server GUI will be available on Port ",(0,r.kt)("inlineCode",{parentName:"p"},"8500")," and I can tunnel it through SSH with:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"ssh myuser@192.168.2.110 -L8500:localhost:8500\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Hashicorp Consul",src:t(45414).Z,width:"1140",height:"459"})),(0,r.kt)("h2",{id:"service-configuration"},"Service Configuration"),(0,r.kt)("p",null,"Again - just like with Nomad - I discovered that the default config is missing on Debian11, while it is located in ",(0,r.kt)("inlineCode",{parentName:"p"},"/etc/consul.d/")," on RHEL8. I will list the default ",(0,r.kt)("inlineCode",{parentName:"p"},"consul.hcl")," config at ",(0,r.kt)("a",{parentName:"p",href:"#default-consul-configuration"},"end of this article"),"."),(0,r.kt)("p",null,"We can use this configuration file - instead of adding all variables to the ",(0,r.kt)("inlineCode",{parentName:"p"},"consul agent")," command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"/usr/bin/consul agent -config-file=/etc/consul.d/consul.hcl\n\n/usr/bin/consul agent -config-dir=/etc/consul.d\n")),(0,r.kt)("p",null,"We can now ",(0,r.kt)("a",{parentName:"p",href:"https://www.consul.io/docs/agent/options"},"add the our configuration")," to ",(0,r.kt)("a",{parentName:"p",href:"#default-consul-configuration"},"/etc/consul.d/consul.hcl"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml"},'node_name = "consul-master"\ndatacenter = "instaryun"\ndata_dir = "/opt/consul"\n# allow all clients\nclient_addr = "0.0.0.0"\n# enable the ui\nui_config{\n  enabled = true\n}\n# make this instance the master server\nserver = true\n# add your servers IP\nbind_addr = "192.168.2.110"\nadvertise_addr = "192.168.2.110"\n# For testing I only have 1 - later 5 master servers are recommended\nbootstrap_expect=1\n# I only have 1 other client server. Set it to allow constant retries because it is not yet configured\nretry_join = ["192.168.2.111"]\nenable_syslog = true\nlog_level = "INFO"\n# https://www.consul.io/docs/agent/options#performance\nperformance{\n  raft_multiplier = 1\n}\n')),(0,r.kt)("p",null,"You can test run the configuration file - see if it is throwing us any errors:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"/usr/bin/consul agent -config-file=/etc/consul.d/consul.hcl\n")),(0,r.kt)("p",null,"Or run the Test command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"consul validate /etc/consul.d/consul.hcl\n\nBootstrapExpect is set to 1; this is the same as Bootstrap mode.\nbootstrap = true: do not enable unless necessary\nConfiguration is valid!\n")),(0,r.kt)("h2",{id:"run-consul-as-a-service"},"Run Consul as a Service"),(0,r.kt)("h3",{id:"needed-ports"},"Needed Ports"),(0,r.kt)("p",null,"Consul uses 3 ports:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"8500")," - Consul UI"),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"8301")," / ",(0,r.kt)("inlineCode",{parentName:"li"},"8300")," - LAN Gossip"),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"8600")," - DNS")),(0,r.kt)("p",null,"I will open those ports in my firewall (except the UI):"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"FirewallD")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"sudo firewall-cmd --permanent --zone=public --add-port={8300/tcp,8301/tcp,8600/tcp}\nsudo firewall-cmd --reload\n\nsudo firewall-cmd --zone=public --list-ports\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"ufw")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"ufw allow 8301,8600/tcp\nufw reload\n\nufw status verbose\n")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"The documentation I found said that the Gossip port is ",(0,r.kt)("inlineCode",{parentName:"p"},"3001"),". But when I started Consul up the first time it tried to connect through port ",(0,r.kt)("inlineCode",{parentName:"p"},"3000")," and the cluster join failed. But the next day Consul started using ",(0,r.kt)("inlineCode",{parentName:"p"},"3001")," \xaf","\\",(0,r.kt)("em",{parentName:"p"},"(\u30c4)"),"/\xaf")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'agent.client: RPC failed to server: method=KVS.List server=192.168.2.110:8300 error="rpc error getting client: failed to get conn: dial tcp 192.168.2.111:0->192.168.2.110:8300: connect: no route to host"\n')),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},(0,r.kt)("strong",{parentName:"p"},"Update"),": See above - happened again. It seems that you need both port ",(0,r.kt)("inlineCode",{parentName:"p"},"8300")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"8301"),".")),(0,r.kt)("h2",{id:"service-configuration-1"},"Service Configuration"),(0,r.kt)("p",null,"Create the ",(0,r.kt)("a",{parentName:"p",href:"https://learn.hashicorp.com/tutorials/consul/deployment-guide#configure-systemd"},"SystemD Service file")," in ",(0,r.kt)("inlineCode",{parentName:"p"},"/etc/systemd/system/consul.service"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cfg"},'[Unit]\nDescription="HashiCorp Consul"\nDocumentation=https://www.consul.io/\nRequires=network-online.target\nAfter=network-online.target\nConditionFileNotEmpty=/etc/consul.d/consul.hcl\n\n[Service]\nType=notify\nUser=consul\nGroup=consul\nExecStart=/usr/bin/consul agent -config-dir=/etc/consul.d/\nExecReload=/bin/kill --signal HUP $MAINPID\nKillMode=process\nKillSignal=SIGTERM\nRestart=on-failure\nLimitNOFILE=65536\n\n[Install]\nWantedBy=multi-user.target\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"sudo systemctl daemon-reload\nsudo service consul start\n")),(0,r.kt)("h3",{id:"problems"},"Problems"),(0,r.kt)("p",null,"In the beginning I ran into a permission error:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"Aug 31 14:03:44 nomad-master consul[54505]: ==> failed to setup node ID: open /opt/consul/node-id: permission denied\nAug 31 14:03:44 nomad-master systemd[1]: consul.service: Main process exited, code=exited, status=1/FAILURE\nAug 31 14:03:44 nomad-master systemd[1]: consul.service: Failed with result 'exit-code'.\n")),(0,r.kt)("p",null,"As a dirty fix I changed the entire data directory to ",(0,r.kt)("inlineCode",{parentName:"p"},"777")," /The ",(0,r.kt)("a",{parentName:"p",href:"https://learn.hashicorp.com/tutorials/consul/deployment-guide#install-consul"},"deployment guide")," creates an extra user for consul - I will go this route in the next test run."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"chmod -R 777 /opt/consul\n")),(0,r.kt)("p",null,"Now the service started but is failing because the Consul minion, that I did not configure yet, is not connecting - ",(0,r.kt)("a",{parentName:"p",href:"#consul-service-error-message"},"see Error Log"),"."),(0,r.kt)("p",null,"So now I added the identical ",(0,r.kt)("strong",{parentName:"p"},"Service file")," to my Debian11 minion and added the following ",(0,r.kt)("strong",{parentName:"p"},"Configuration")," ",(0,r.kt)("inlineCode",{parentName:"p"},"/etc/consul.d/consul.hcl"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml"},'node_name = "consul-minion"\ndatacenter = "instaryun"\ndata_dir = "/opt/consul"\n# allow all clients\nclient_addr = "0.0.0.0"\n# disable the ui\nui = false\n# make this instance the master server\nserver = false\n# add your servers IP\nbind_addr = "192.168.2.111"\nadvertise_addr = "192.168.2.111"\nretry_join = ["192.168.2.110"]\nenable_syslog = true\nlog_level = "INFO"\n# https://www.consul.io/docs/agent/options#performance\nperformance{\n  raft_multiplier = 1\n}\n')),(0,r.kt)("p",null,"Note that I set ",(0,r.kt)("inlineCode",{parentName:"p"},"server")," to false, removed the ",(0,r.kt)("inlineCode",{parentName:"p"},"bootstap")," variable and had to rewrite the ",(0,r.kt)("inlineCode",{parentName:"p"},"ui")," variable - the latter might be because I am using version ",(0,r.kt)("inlineCode",{parentName:"p"},"Consul v1.8.7")," while I am on ",(0,r.kt)("inlineCode",{parentName:"p"},"Consul v1.10.2")," on my master server."),(0,r.kt)("p",null,"As an alternative to ",(0,r.kt)("inlineCode",{parentName:"p"},"retry_join")," I can also manually join this client into an existing cluster with the join command (or leave):"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"consul join [IP address or domain of one of your Consul servers]\nconsul leave\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"This time both services started successfully!")," And the UI shows me that both nodes successfully joined the Consul cluster:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Hashicorp Consul",src:t(11190).Z,width:"1137",height:"388"})),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Note"),": The node name is taken from the server hostname instead of the Consul configuration file - hence I am having a ",(0,r.kt)("strong",{parentName:"p"},"Nomad Master")," instead of the ",(0,r.kt)("strong",{parentName:"p"},"consul-master")," I defined. To change your servers hostname run the following commands and restart the Consul service:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"hostname\n\nhostnamectl set-hostname consul-master\n\nhostname\n\nservice consul restart\n")),(0,r.kt)("p",null,"Now Consul displays the correct node name:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"consul operator raft list-peers\n\nNode           ID                                    Address             State   Voter  RaftProtocol\nconsul-master  d561f8d4-9606-8c9c-40d4-a5350857801e  192.168.2.110:8300  leader  true   3\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"consul members\n\nNode           Address             Status  Type    Build   Protocol  DC         Segment\nconsul-master  192.168.2.110:8301  alive   server  1.10.2  2         instaryun  <all>\nconsul-minion  192.168.2.111:8301  alive   client  1.8.7   2         instaryun  <default>\n")),(0,r.kt)("h2",{id:"registering-a-service-in-nomad"},"Registering a Service in Nomad"),(0,r.kt)("p",null,"There are ",(0,r.kt)("a",{parentName:"p",href:"https://learn.hashicorp.com/consul/getting-started/services"},"multiple ways to register a service in Consul"),". Fortunately Nomad has a first class integration that makes it very simple to add a service stanza to a job file to perform this registration for us. To register our Nomad deployed ",(0,r.kt)("a",{parentName:"p",href:"/docs/DevOps/Hashicorp/2021-08-04--hashicorp-nomad-job-specifications/2021-08-04"},"http-echo application"),", we simply add a ",(0,r.kt)("a",{parentName:"p",href:"https://www.nomadproject.io/docs/job-specification/service"},"service block")," to the Nomad job file:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'service {\n  name = "http-echo"\n  port = "heartbeat"\n\n  tags = [\n    "heartbeat",\n    "urlprefix-/http-echo",\n  ]\n\n  check {\n    type     = "http"\n    path     = "/health"\n    interval = "2s"\n    timeout  = "2s"\n  }\n}\n')),(0,r.kt)("p",null,"The ",(0,r.kt)("a",{parentName:"p",href:"/docs/DevOps/Hashicorp/2021-08-04--hashicorp-nomad-job-specifications/2021-08-04"},"http-echo job file")," now looks like:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"cat ~/nomad_jobs/http_echo_gui.nomad\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'job "http-echo-gui" {\n  datacenters = ["instaryun"]\n\n  group "echo" {\n\n    network {\n        port "heartbeat" {\n            static = 8080\n            }\n    }\n\n    count = 1\n    task "server" {\n      driver = "docker"\n      config {\n        image = "hashicorp/http-echo:latest"\n        ports = ["heartbeat"]\n        args  = [\n          "-listen", ":${NOMAD_PORT_heartbeat}",\n          "-text", "${attr.os.name}: server running on ${NOMAD_IP_heartbeat} with port ${NOMAD_PORT_heartbeat}",\n        ]\n      }\n      service {\n        name = "http-echo"\n        port = "heartbeat"\n\n        tags = [\n          "heartbeat",\n          "urlprefix-/http-echo",\n        ]\n\n        check {\n          type     = "http"\n          path     = "/health"\n          interval = "2s"\n          timeout  = "2s"\n        }\n      }\n    }\n  }\n}\n')),(0,r.kt)("p",null,"And can be directly updated from the Nomad GUI:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Hashicorp Consul",src:t(20215).Z,width:"1135",height:"865"})),(0,r.kt)("p",null,"First click on ",(0,r.kt)("strong",{parentName:"p"},"Plan")," and then ",(0,r.kt)("strong",{parentName:"p"},"Run")," to schedule the job. Once the task is running, check in Consul if the service ",(0,r.kt)("inlineCode",{parentName:"p"},"http-echo")," registered itself:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"consul catalog services\n\nconsul\nhttp-echo\nnomad\nnomad-client\n")),(0,r.kt)("p",null,"In the Consul UI I can see that the healthcheck URL is working:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Hashicorp Consul",src:t(70113).Z,width:"1307",height:"695"})),(0,r.kt)("p",null,"You can also test it from your browser with by visiting the URL listed by Consul ",(0,r.kt)("inlineCode",{parentName:"p"},"http://192.168.2.111:8080/health"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'{ "status": "ok" }\n')),(0,r.kt)("h2",{id:"default-consul-configuration"},"Default Consul Configuration"),(0,r.kt)("p",null,"From the default package manager installation of ",(0,r.kt)("em",{parentName:"p"},"Consul v1.10.2")," on RHEL8 in ",(0,r.kt)("inlineCode",{parentName:"p"},"/etc/consul.d/consul.hcl"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'# Full configuration options can be found at https://www.consul.io/docs/agent/options.html\n\n# datacenter\n# This flag controls the datacenter in which the agent is running. If not provided,\n# it defaults to "dc1". Consul has first-class support for multiple datacenters, but\n# it relies on proper configuration. Nodes in the same datacenter should be on a\n# single LAN.\n#datacenter = "my-dc-1"\n\n# data_dir\n# This flag provides a data directory for the agent to store state. This is required\n# for all agents. The directory should be durable across reboots. This is especially\n# critical for agents that are running in server mode as they must be able to persist\n# cluster state. Additionally, the directory must support the use of filesystem\n# locking, meaning some types of mounted folders (e.g. VirtualBox shared folders) may\n# not be suitable.\ndata_dir = "/opt/consul"\n\n# client_addr\n# The address to which Consul will bind client interfaces, including the HTTP and DNS\n# servers. By default, this is "127.0.0.1", allowing only loopback connections. In\n# Consul 1.0 and later this can be set to a space-separated list of addresses to bind\n# to, or a go-sockaddr template that can potentially resolve to multiple addresses.\n#client_addr = "0.0.0.0"\n\n# ui\n# Enables the built-in web UI server and the required HTTP routes. This eliminates\n# the need to maintain the Consul web UI files separately from the binary.\n# Version 1.10 deprecated ui=true in favor of ui_config.enabled=true\n#ui_config{\n#  enabled = true\n#}\n\n# server\n# This flag is used to control if an agent is in server or client mode. When provided,\n# an agent will act as a Consul server. Each Consul cluster must have at least one\n# server and ideally no more than 5 per datacenter. All servers participate in the Raft\n# consensus algorithm to ensure that transactions occur in a consistent, linearizable\n# manner. Transactions modify cluster state, which is maintained on all server nodes to\n# ensure availability in the case of node failure. Server nodes also participate in a\n# WAN gossip pool with server nodes in other datacenters. Servers act as gateways to\n# other datacenters and forward traffic as appropriate.\n#server = true\n\n# Bind addr\n# You may use IPv4 or IPv6 but if you have multiple interfaces you must be explicit.\n#bind_addr = "[::]" # Listen on all IPv6\n#bind_addr = "0.0.0.0" # Listen on all IPv4\n#\n# Advertise addr - if you want to point clients to a different address than bind or LB.\n#advertise_addr = "127.0.0.1"\n\n# Enterprise License\n# As of 1.10, Enterprise requires a license_path and does not have a short trial.\n#license_path = "/etc/consul.d/consul.hclic"\n\n# bootstrap_expect\n# This flag provides the number of expected servers in the datacenter. Either this value\n# should not be provided or the value must agree with other servers in the cluster. When\n# provided, Consul waits until the specified number of servers are available and then\n# bootstraps the cluster. This allows an initial leader to be elected automatically.\n# This cannot be used in conjunction with the legacy -bootstrap flag. This flag requires\n# -server mode.\n#bootstrap_expect=3\n\n# encrypt\n# Specifies the secret key to use for encryption of Consul network traffic. This key must\n# be 32-bytes that are Base64-encoded. The easiest way to create an encryption key is to\n# use consul keygen. All nodes within a cluster must share the same encryption key to\n# communicate. The provided key is automatically persisted to the data directory and loaded\n# automatically whenever the agent is restarted. This means that to encrypt Consul\'s gossip\n# protocol, this option only needs to be provided once on each agent\'s initial startup\n# sequence. If it is provided after Consul has been initialized with an encryption key,\n# then the provided key is ignored and a warning will be displayed.\n#encrypt = "..."\n\n# retry_join\n# Similar to -join but allows retrying a join until it is successful. Once it joins\n# successfully to a member in a list of members it will never attempt to join again.\n# Agents will then solely maintain their membership via gossip. This is useful for\n# cases where you know the address will eventually be available. This option can be\n# specified multiple times to specify multiple agents to join. The value can contain\n# IPv4, IPv6, or DNS addresses. In Consul 1.1.0 and later this can be set to a go-sockaddr\n# template. If Consul is running on the non-default Serf LAN port, this must be specified\n# as well. IPv6 must use the "bracketed" syntax. If multiple values are given, they are\n# tried and retried in the order listed until the first succeeds. Here are some examples:\n#retry_join = ["consul.domain.internal"]\n#retry_join = ["10.0.4.67"]\n#retry_join = ["[::1]:8301"]\n#retry_join = ["consul.domain.internal", "10.0.4.67"]\n# Cloud Auto-join examples:\n# More details - https://www.consul.io/docs/agent/cloud-auto-join\n#retry_join = ["provider=aws tag_key=... tag_value=..."]\n#retry_join = ["provider=azure tag_name=... tag_value=... tenant_id=... client_id=... subscription_id=... secret_access_key=..."]\n#retry_join = ["provider=gce project_name=... tag_value=..."]\n')),(0,r.kt)("h2",{id:"consul-service-error-message"},"Consul Service Error Message"),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"see ",(0,r.kt)("a",{parentName:"em",href:"#problems"},"Problems"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'Aug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [WARN]  agent: DEPRECATED Backwards compatibil>Aug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [INFO]  agent: Retry join is supported for the>Aug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [INFO]  agent: Joining cluster...: cluster=LAN\nAug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [INFO]  agent: (LAN) joining: lan_addresses=[1>Aug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [INFO]  agent: started state syncer\nAug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [INFO]  agent: Consul agent running!\nAug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [WARN]  agent: (LAN) couldn\'t join: number_of_>Aug 31 14:12:08 nomad-master consul[60088]:         * Failed to join 192.168.2.111: dial tcp 192.168.2.111:8301: connec>Aug 31 14:12:08 nomad-master consul[60088]: "\nAug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [WARN]  agent: Join cluster failed, will retry>Aug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.118+0800 [WARN]  agent.server.raft: heartbeat timeout r>Aug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.118+0800 [INFO]  agent.server.raft: entering candidate >Aug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.136+0800 [INFO]  agent.server.raft: election won: tally>Aug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.136+0800 [INFO]  agent.server.raft: entering leader sta>Aug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.136+0800 [INFO]  agent.server: cluster leadership acqui>Aug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.136+0800 [INFO]  agent.server: New leader elected: payl>Aug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.151+0800 [INFO]  agent.leader: started routine: routine>Aug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.151+0800 [INFO]  agent.leader: started routine: routine>Aug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.367+0800 [INFO]  agent: Synced node info\nAug 31 14:12:38 nomad-master consul[60088]: 2021-08-31T14:12:38.213+0800 [INFO]  agent: (LAN) joining: lan_addresses=[1>Aug 31 14:12:38 nomad-master consul[60088]: 2021-08-31T14:12:38.214+0800 [WARN]  agent: (LAN) couldn\'t join: number_of_>Aug 31 14:12:38 nomad-master consul[60088]:         * Failed to join 192.168.2.111: dial tcp 192.168.2.111:8301: connec>Aug 31 14:12:38 nomad-master consul[60088]: "\nAug 31 14:12:38 nomad-master consul[60088]: 2021-08-31T14:12:38.214+0800 [WARN]  agent: Join cluster failed, will retry>Aug 31 14:13:08 nomad-master consul[60088]: 2021-08-31T14:13:08.214+0800 [INFO]  agent: (LAN) joining: lan_addresses=[1>Aug 31 14:13:08 nomad-master consul[60088]: 2021-08-31T14:13:08.214+0800 [WARN]  agent: (LAN) couldn\'t join: number_of_>Aug 31 14:13:08 nomad-master consul[60088]:         * Failed to join 192.168.2.111: dial tcp 192.168.2.111:8301: connec>Aug 31 14:13:08 nomad-master consul[60088]: "\nAug 31 14:13:08 nomad-master consul[60088]: 2021-08-31T14:13:08.214+0800 [WARN]  agent: Join cluster failed, will retry>lines 3908-3936/3936 (END)\nAug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [WARN]  agent: DEPRECATED Backwards compatibility with pre-1.9 metrics enabled. These metrics will be removed in a future version of Consul. Set `telemetry { disable_compat_1.9 = true }` to disable them.\nAug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [INFO]  agent: Retry join is supported for the following discovery methods: cluster=LAN discovery_methods="aliyun aws azure digitalocean gce k8s linode mdns os packet scaleway softlayer tencentcloud triton vsphere"\nAug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [INFO]  agent: Joining cluster...: cluster=LAN\nAug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [INFO]  agent: (LAN) joining: lan_addresses=[192.168.2.111]\nAug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [INFO]  agent: started state syncer\nAug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [INFO]  agent: Consul agent running!\nAug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [WARN]  agent: (LAN) couldn\'t join: number_of_nodes=0 error="1 error occurred:\nAug 31 14:12:08 nomad-master consul[60088]:         * Failed to join 192.168.2.111: dial tcp 192.168.2.111:8301: connect: connection refused\nAug 31 14:12:08 nomad-master consul[60088]: "\nAug 31 14:12:08 nomad-master consul[60088]: 2021-08-31T14:12:08.212+0800 [WARN]  agent: Join cluster failed, will retry: cluster=LAN retry_interval=30s error=<nil>\nAug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.118+0800 [WARN]  agent.server.raft: heartbeat timeout reached, starting election: last-leader=\nAug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.118+0800 [INFO]  agent.server.raft: entering candidate state: node="Node at 192.168.2.110:8300 [Candidate]" term=5\nAug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.136+0800 [INFO]  agent.server.raft: election won: tally=1\nAug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.136+0800 [INFO]  agent.server.raft: entering leader state: leader="Node at 192.168.2.110:8300 [Leader]"\nAug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.136+0800 [INFO]  agent.server: cluster leadership acquired\nAug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.136+0800 [INFO]  agent.server: New leader elected: payload=nomad-master\nAug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.151+0800 [INFO]  agent.leader: started routine: routine="federation state anti-entropy"\nAug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.151+0800 [INFO]  agent.leader: started routine: routine="federation state pruning"\nAug 31 14:12:15 nomad-master consul[60088]: 2021-08-31T14:12:15.367+0800 [INFO]  agent: Synced node info\nAug 31 14:12:38 nomad-master consul[60088]: 2021-08-31T14:12:38.213+0800 [INFO]  agent: (LAN) joining: lan_addresses=[192.168.2.111]\nAug 31 14:12:38 nomad-master consul[60088]: 2021-08-31T14:12:38.214+0800 [WARN]  agent: (LAN) couldn\'t join: number_of_nodes=0 error="1 error occurred:\nAug 31 14:12:38 nomad-master consul[60088]:         * Failed to join 192.168.2.111: dial tcp 192.168.2.111:8301: connect: connection refused\nAug 31 14:12:38 nomad-master consul[60088]: "\nAug 31 14:12:38 nomad-master consul[60088]: 2021-08-31T14:12:38.214+0800 [WARN]  agent: Join cluster failed, will retry: cluster=LAN retry_interval=30s error=<nil>\nAug 31 14:13:08 nomad-master consul[60088]: 2021-08-31T14:13:08.214+0800 [INFO]  agent: (LAN) joining: lan_addresses=[192.168.2.111]\nAug 31 14:13:08 nomad-master consul[60088]: 2021-08-31T14:13:08.214+0800 [WARN]  agent: (LAN) couldn\'t join: number_of_nodes=0 error="1 error occurred:\nAug 31 14:13:08 nomad-master consul[60088]:         * Failed to join 192.168.2.111: dial tcp 192.168.2.111:8301: connect: connection refused\nAug 31 14:13:08 nomad-master consul[60088]: "\nAug 31 14:13:08 nomad-master consul[60088]: 2021-08-31T14:13:08.214+0800 [WARN]  agent: Join cluster failed, will retry: cluster=LAN retry_interval=30s error=<nil>\n')))}d.isMDXComponent=!0},45414:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/Hashicorp_Consul_01-7fe7c1a0275a1539d314e6887332c91b.png"},20215:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/Hashicorp_Consul_02-027e6c68c37b63220b83614d41c2c957.png"},11190:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/Hashicorp_Consul_03-c51dfacf36a0d58ee288f98d07553eb0.png"},70113:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/Hashicorp_Consul_04-e0e29a4ab71c214b38e276b952bf9272.png"},42723:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-825ad0c1979a3b8d8834b2806be1b28e.jpg"}}]);