"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[74100],{3905:(e,n,t)=>{t.d(n,{Zo:()=>m,kt:()=>u});var a=t(67294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var i=a.createContext({}),d=function(e){var n=a.useContext(i),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},m=function(e){var n=d(e.components);return a.createElement(i.Provider,{value:n},e.children)},c={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},p=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,o=e.originalType,i=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),p=d(t),u=r,h=p["".concat(i,".").concat(u)]||p[u]||c[u]||o;return t?a.createElement(h,l(l({ref:n},m),{},{components:t})):a.createElement(h,l({ref:n},m))}));function u(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=t.length,l=new Array(o);l[0]=p;var s={};for(var i in n)hasOwnProperty.call(n,i)&&(s[i]=n[i]);s.originalType=e,s.mdxType="string"==typeof e?e:r,l[1]=s;for(var d=2;d<o;d++)l[d]=t[d];return a.createElement.apply(null,l)}return a.createElement.apply(null,t)}p.displayName="MDXCreateElement"},33705:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>i,contentTitle:()=>l,default:()=>c,frontMatter:()=>o,metadata:()=>s,toc:()=>d});var a=t(87462),r=(t(67294),t(3905));const o={sidebar_position:9e3,slug:"2021-08-01",title:"Hashicorp Nomad Refresher - Installation",authors:"mpolinowski",tags:["Nomad","Linux"]},l=void 0,s={unversionedId:"DevOps/Hashicorp/2021-08-01--hashicorp-nomad-refresher/index",id:"DevOps/Hashicorp/2021-08-01--hashicorp-nomad-refresher/index",title:"Hashicorp Nomad Refresher - Installation",description:"Shenzhen, China",source:"@site/docs/DevOps/Hashicorp/2021-08-01--hashicorp-nomad-refresher/index.md",sourceDirName:"DevOps/Hashicorp/2021-08-01--hashicorp-nomad-refresher",slug:"/DevOps/Hashicorp/2021-08-01--hashicorp-nomad-refresher/2021-08-01",permalink:"/docs/DevOps/Hashicorp/2021-08-01--hashicorp-nomad-refresher/2021-08-01",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/DevOps/Hashicorp/2021-08-01--hashicorp-nomad-refresher/index.md",tags:[{label:"Nomad",permalink:"/docs/tags/nomad"},{label:"Linux",permalink:"/docs/tags/linux"}],version:"current",sidebarPosition:9e3,frontMatter:{sidebar_position:9e3,slug:"2021-08-01",title:"Hashicorp Nomad Refresher - Installation",authors:"mpolinowski",tags:["Nomad","Linux"]},sidebar:"tutorialSidebar",previous:{title:"Hashicorp Nomad Refresher - Security",permalink:"/docs/DevOps/Hashicorp/2021-08-02--hashicorp-nomad-security/2021-08-02"},next:{title:"HashiCorp Packer Provisioning",permalink:"/docs/DevOps/Hashicorp/2020-10-26--hashicorp-packer-provisioner/2020-10-26"}},i={},d=[{value:"Single Server Install",id:"single-server-install",level:2},{value:"Configuration",id:"configuration",level:3},{value:"Firewall Config - Open Ports",id:"firewall-config---open-ports",level:3},{value:"Start the DevMode",id:"start-the-devmode",level:3},{value:"Nomad Cluster Installation",id:"nomad-cluster-installation",level:2},{value:"Start the Service",id:"start-the-service",level:3},{value:"Removing Nodes",id:"removing-nodes",level:2}],m={toc:d};function c(e){let{components:n,...o}=e;return(0,r.kt)("wrapper",(0,a.Z)({},m,o,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Shenzhen, China",src:t(4097).Z,width:"1500",height:"478"})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#single-server-install"},"Single Server Install"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#configuration"},"Configuration")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#firewall-config---open-ports"},"Firewall Config - Open Ports")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#start-the-devmode"},"Start the DevMode")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#nomad-cluster-installation"},"Nomad Cluster Installation"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#start-the-service"},"Start the Service")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#removing-nodes"},"Removing Nodes"))),(0,r.kt)("h2",{id:"single-server-install"},"Single Server Install"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Ubuntu20/Debian11")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'curl -fsSL https://apt.releases.hashicorp.com/gpg | apt-key add -\napt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"\napt-get update && apt-get install nomad\n')),(0,r.kt)("p",null,"Verify that Nomad installed successfully:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"nomad -v\nNomad v0.12.10\n")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},(0,r.kt)("strong",{parentName:"p"},"Issue"),": Using those command left me with an very old version of Nomad - the current version is 1.1.3! So I will have to do a manual install from source instead.")),(0,r.kt)("p",null,"I am going to use a variation of the installation script that ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/hashicorp/guides-configuration/blob/master/nomad/scripts/install-nomad.sh"},"Hashicorp provides on Github"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'#!/bin/bash\nset -x\n\necho "Running"\n\nNOMAD_VERSION=1.1.3\nNOMAD_ZIP=nomad_${NOMAD_VERSION}_linux_amd64.zip\nNOMAD_URL=${URL:-https://releases.hashicorp.com/nomad/${NOMAD_VERSION}/${NOMAD_ZIP}}\nNOMAD_DIR=/usr/local/bin\nNOMAD_PATH=${NOMAD_DIR}/nomad\nNOMAD_CONFIG_DIR=/etc/nomad.d\nNOMAD_DATA_DIR=/opt/nomad/data\nNOMAD_TLS_DIR=/opt/nomad/tls\nNOMAD_ENV_VARS=${NOMAD_CONFIG_DIR}/nomad.conf\nNOMAD_PROFILE_SCRIPT=/etc/profile.d/nomad.sh\n\necho "Downloading Nomad ${NOMAD_VERSION}"\n[ 200 -ne $(curl --write-out %{http_code} --silent --output /tmp/${NOMAD_ZIP} ${NOMAD_URL}) ] && exit 1\n\necho "Installing Nomad"\nunzip -o /tmp/${NOMAD_ZIP} -d ${NOMAD_DIR}\nchmod 0755 ${NOMAD_PATH}\nchown ${USER}:${GROUP} ${NOMAD_PATH}\necho "$(${NOMAD_PATH} --version)"\n\necho "Configuring Nomad ${NOMAD_VERSION}"\nmkdir -pm 0755 ${NOMAD_CONFIG_DIR} ${NOMAD_DATA_DIR} ${NOMAD_TLS_DIR}\n\necho "Start Nomad in -dev mode"\ntee ${NOMAD_ENV_VARS} > /dev/null <<ENVVARS\nFLAGS=-bind 0.0.0.0 -dev\nENVVARS\n\necho "Update directory permissions"\nchown -R ${USER}:${GROUP} ${NOMAD_CONFIG_DIR} ${NOMAD_DATA_DIR} ${NOMAD_TLS_DIR}\nchmod -R 0644 ${NOMAD_CONFIG_DIR}/*\n\necho "Set Nomad profile script"\ntee ${NOMAD_PROFILE_SCRIPT} > /dev/null <<PROFILE\nexport NOMAD_ADDR=http://127.0.0.1:4646\nPROFILE\n\necho "Complete"\n')),(0,r.kt)("p",null,"Write the script to file ",(0,r.kt)("inlineCode",{parentName:"p"},"install_nomad.sh")," and make it executable. Remove the old version of nomad and run the script:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"chmod +x install_nomad.sh\napt remove nomad\nsh ./install_nomad.sh\n")),(0,r.kt)("p",null,"And this looks a lot better:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"nomad -v\nNomad v1.1.3 (8c0c8140997329136971e66e4c2337dfcf932692)\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"CentOS8/RHEL8")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"sudo yum install -y yum-utils\nsudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo\nsudo yum -y install nomad\n")),(0,r.kt)("p",null,"The installation under RHEL8 went without a hitch."),(0,r.kt)("h3",{id:"configuration"},"Configuration"),(0,r.kt)("p",null,"Nomad already comes with a basic setup on my RHEL8 server:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"cat /etc/nomad.d/nomad.hcl\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml"},'## https://www.nomadproject.io/docs/agent/configuration\n\ndata_dir = "/opt/nomad/data"\nbind_addr = "0.0.0.0"\n\nserver {\n  enabled = true\n  bootstrap_expect = 1\n}\n\nclient {\n  enabled = true\n  servers = ["127.0.0.1"]\n}\n\n## https://www.nomadproject.io/docs/agent/configuration/index.html#log_level\n## [WARN|INFO|DEBUG]\nlog_level = "INFO"\n')),(0,r.kt)("p",null,"While my Debian install only has this file:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"cat /etc/nomad.d/nomad.conf\nFLAGS=-bind 0.0.0.0 -dev\n")),(0,r.kt)("h3",{id:"firewall-config---open-ports"},"Firewall Config - Open Ports"),(0,r.kt)("p",null,"Nomad requires 3 different ports to work properly on servers and 2 on clients, some on TCP, UDP, or both protocols. Below we document the requirements for each port."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"HTTP API (Default ",(0,r.kt)("strong",{parentName:"li"},"4646"),"). This is used by clients and servers to serve the HTTP API. TCP only."),(0,r.kt)("li",{parentName:"ul"},"RPC (Default ",(0,r.kt)("strong",{parentName:"li"},"4647"),"). This is used for internal RPC communication between client agents and servers, and for inter-server traffic. TCP only."),(0,r.kt)("li",{parentName:"ul"},"Serf WAN (Default ",(0,r.kt)("strong",{parentName:"li"},"4648"),"). This is used by servers to gossip both over the LAN and WAN to other servers. It isn't required that Nomad clients can reach this address. TCP and UDP.")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"CentOS8/RHEL8")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"sudo firewall-cmd --permanent --zone=public --add-port=4646/tcp --add-port=4647/tcp  --add-port=4648/tcp  --add-port=4648/udp\nsudo firewall-cmd --reload\nsudo firewall-cmd --zone=public --list-ports\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Ubuntu20/Debian11")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"ufw allow 4646:4647/tcp\nufw allow 4648\nufw reload\nufw status verbose\n")),(0,r.kt)("h3",{id:"start-the-devmode"},"Start the DevMode"),(0,r.kt)("p",null,"The RHEL8 installation looks fine - but let's test if the manual installation on Debian actually worked by executing the Nomad Agent DevMode:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"nomad agent -dev -bind 0.0.0.0\n")),(0,r.kt)("p",null,"And you should see the Nomad UI come up on port ",(0,r.kt)("inlineCode",{parentName:"p"},"4646"),":"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Hashicorp Nomad",src:t(32139).Z,width:"1082",height:"388"})),(0,r.kt)("p",null,"You can also use the Nomad CLI in a secondary terminal:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"nomad server members\n\nName             Address        Port  Status  Leader  Protocol  Build    Datacenter  Region\ndebian11.global  192.168.2.111  4648  alive   true    2         0.12.10  dc1         global\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"nomad node status\n\nID        DC   Name      Class   Drain  Eligibility  Status\nf25cd5fe  dc1  debian11  <none>  false  eligible     ready\n")),(0,r.kt)("p",null,"Everything seems to be working."),(0,r.kt)("h2",{id:"nomad-cluster-installation"},"Nomad Cluster Installation"),(0,r.kt)("p",null,"In production I want to use a dedicated Nomad master (RHEL8) to control all other servers as Nomad minions (only 1 Debian11 for now). For this I will modify the default configuration to my master server and add the same file to my minion:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"sudo nano /etc/nomad.d/nomad.hcl\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'data_dir = "/opt/nomad/data"\nbind_addr = "0.0.0.0"\ndatacenter = "instaryun"\n')),(0,r.kt)("p",null,"For the master (RHEL8) I will add a file:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"sudo nano /etc/nomad.d/server.hcl\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},"server {\n  enabled = true\n  bootstrap_expect = 1\n}\n")),(0,r.kt)("p",null,"This enables the server mode and tells Nomad that there will only be one master server for this cluster. And for my minion I create a file:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"nano /etc/nomad.d/client.hcl\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'client {\n  enabled = true\n  servers = ["192.168.2.110"]\n}\n')),(0,r.kt)("p",null,"This enables the client mode and tells Nomad that the master of this cluster can be reached on the IP ",(0,r.kt)("inlineCode",{parentName:"p"},"192.168.2.110"),". To make this a little bit robust we could also ",(0,r.kt)("inlineCode",{parentName:"p"},"nano /etc/hosts")," and add a name resolution for our master server IP and use that domain name instead of the IP address (that might change during the life cycle of the applications we want to use Nomad for):"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"192.168.2.110 nomad-master\n192.168.2.111 nomad-minion\n")),(0,r.kt)("p",null,"So now we can use the following client configuration:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'client {\n  enabled = true\n  servers = ["nomad-master"]\n}\n')),(0,r.kt)("h3",{id:"start-the-service"},"Start the Service"),(0,r.kt)("p",null,"After the configuration start / enable the service on both the client and the master server:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl enable --now nomad\nsystemctl status nomad\n")),(0,r.kt)("p",null,"This worked fine on my master server - but again the manual installed version of Nomad for my minion is acting up. First I got an error that the service was masked:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl unmask nomad\n")),(0,r.kt)("p",null,"And then I saw that the service file that was linked in was missing. So I copied in the one from my master server and modified it to fit:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"nano /lib/systemd/system/nomad.service\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml"},"[Unit]\nDescription=Nomad\nDocumentation=https://nomadproject.io/docs/\nWants=network-online.target\nAfter=network-online.target\n\n# When using Nomad with Consul it is not necessary to start Consul first. These\n# lines start Consul before Nomad as an optimization to avoid Nomad logging\n# that Consul is unavailable at startup.\n#Wants=consul.service\n#After=consul.service\n\n[Service]\nExecReload=/bin/kill -HUP $MAINPID\nExecStart=/usr/local/bin/nomad agent -config /etc/nomad.d\nKillMode=process\nKillSignal=SIGINT\nLimitNOFILE=65536\nLimitNPROC=infinity\nRestart=on-failure\nRestartSec=2\n\n## Configure unit start rate limiting. Units which are started more than\n## *burst* times within an *interval* time span are not permitted to start any\n## more. Use `StartLimitIntervalSec` or `StartLimitInterval` (depending on\n## systemd version) to configure the checking interval and `StartLimitBurst`\n## to configure how many starts per interval are allowed. The values in the\n## commented lines are defaults.\n\n# StartLimitBurst = 5\n\n## StartLimitIntervalSec is used for systemd versions >= 230\n# StartLimitIntervalSec = 10s\n\n## StartLimitInterval is used for systemd versions < 230\n# StartLimitInterval = 10s\n\nTasksMax=infinity\nOOMScoreAdjust=-1000\n\n[Install]\nWantedBy=multi-user.target\n")),(0,r.kt)("p",null,"Ok, one more time, with more feeling:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl enable --now nomad\nsystemctl status nomad\n")),(0,r.kt)("p",null,"And it is working! I can also access the Nomad UI on my master server and see both the minion and master entry - success!"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Hashicorp Nomad",src:t(17864).Z,width:"1077",height:"386"})),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Hashicorp Nomad",src:t(39931).Z,width:"1074",height:"274"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"nomad server members\n\nName                    Address        Port  Status  Leader  Protocol  Build  Datacenter  Region\nlinux.fritz.box.global  192.168.2.110  4648  alive   true    2         1.1.3  instaryun   global\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"nomad node status\n\nID        DC         Name      Class   Drain  Eligibility  Status\n3d32b138  instaryun  debian11  <none>  false  eligible     ready\n")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},(0,r.kt)("strong",{parentName:"p"},"Debugging"),": If the minion did not show up you can manually join it from your master with ",(0,r.kt)("inlineCode",{parentName:"p"},"nomad server join nomad-minion"),". The other way around - you can also tell your client to join a node with ",(0,r.kt)("inlineCode",{parentName:"p"},"nomad node config -update-servers nomad-master"),". This might become more of an issue when you have more than 1 master server and don't see all your clients in only 1 of them.")),(0,r.kt)("h2",{id:"removing-nodes"},"Removing Nodes"),(0,r.kt)("p",null,"To remove a minion from our cluster we can set it to be ",(0,r.kt)("strong",{parentName:"p"},"not eligible")," to receive new workload (or toggle eligibility in the Nomad UI):"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"nomad node eligibility -disable {node-id}\n")),(0,r.kt)("p",null,"To actively remove all running jobs from a node we can use the drain command (or click on the drain button in the Nomad UI):"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"nomad node drain -enable {node-id}\n")),(0,r.kt)("p",null,"Such nodes will then automatically be removed from the cluster ",(0,r.kt)("strong",{parentName:"p"},"after 24 hrs"),"."))}c.isMDXComponent=!0},32139:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/Hashicorp_Nomad_01-9eb2738d5ec3071cd75a8872f7d67b78.png"},17864:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/Hashicorp_Nomad_02-a9bf33a3a3a2b04ac2fc1eefe14ec644.png"},39931:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/Hashicorp_Nomad_03-da114b9f6be1f182f76cfc631f9c475b.png"},4097:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-ddd81a2c3e22e41089cabc9238916bda.jpg"}}]);