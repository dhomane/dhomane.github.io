"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[17479],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>u});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var p=a.createContext({}),s=function(e){var t=a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},d=function(e){var t=s(e.components);return a.createElement(p.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,l=e.originalType,p=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),c=s(n),u=r,h=c["".concat(p,".").concat(u)]||c[u]||m[u]||l;return n?a.createElement(h,o(o({ref:t},d),{},{components:n})):a.createElement(h,o({ref:t},d))}));function u(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=n.length,o=new Array(l);o[0]=c;var i={};for(var p in t)hasOwnProperty.call(t,p)&&(i[p]=t[p]);i.originalType=e,i.mdxType="string"==typeof e?e:r,o[1]=i;for(var s=2;s<l;s++)o[s]=n[s];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},58811:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>o,default:()=>m,frontMatter:()=>l,metadata:()=>i,toc:()=>s});var a=n(87462),r=(n(67294),n(3905));const l={sidebar_position:5080,slug:"2022-02-19",title:"Yolo App - Flask Web Application",authors:"mpolinowski",tags:["Tensorflow","Machine Learning","Python","YOLO"]},o=void 0,i={unversionedId:"IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/index",id:"IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/index",title:"Yolo App - Flask Web Application",description:"Shenzhen, China",source:"@site/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask",slug:"/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/2022-02-19",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/2022-02-19",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/index.md",tags:[{label:"Tensorflow",permalink:"/docs/tags/tensorflow"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Python",permalink:"/docs/tags/python"},{label:"YOLO",permalink:"/docs/tags/yolo"}],version:"current",sidebarPosition:5080,frontMatter:{sidebar_position:5080,slug:"2022-02-19",title:"Yolo App - Flask Web Application",authors:"mpolinowski",tags:["Tensorflow","Machine Learning","Python","YOLO"]},sidebar:"tutorialSidebar",previous:{title:"Yolo App - YOLOv5 Data Preparation",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20"},next:{title:"Yolo App - Tesseract Optical Character Recognition",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-02-18--yolo-app-ocr/2022-02-18"}},p={},s=[{value:"Setting Up Flask",id:"setting-up-flask",level:2},{value:"Hello World",id:"hello-world",level:3},{value:"Rendering HTML Templates",id:"rendering-html-templates",level:3},{value:"Template Inheritance",id:"template-inheritance",level:3},{value:"Create an Image File Upload",id:"create-an-image-file-upload",level:3},{value:"Number Plate Detection",id:"number-plate-detection",level:2},{value:"Integrating the Tensorflow Model",id:"integrating-the-tensorflow-model",level:3},{value:"Integrating Tesseract OCR",id:"integrating-tesseract-ocr",level:3},{value:"Use Detection in Flask",id:"use-detection-in-flask",level:3},{value:"Display Results on Page",id:"display-results-on-page",level:3}],d={toc:s};function m(e){let{components:t,...l}=e;return(0,r.kt)("wrapper",(0,a.Z)({},d,l,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Shenzhen, China",src:n(47819).Z,width:"1500",height:"688"})),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/2022-02-15"},"Prepare your Images and get Data")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-02-16--yolo-app-tensorflow-model/2022-02-16"},"Train your Tensorflow Model")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-02-17--yolo-app-prediction-pipeline/2022-02-17"},"Use your Model to do Predictions")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-02-18--yolo-app-ocr/2022-02-18"},"Use Tesseract to Read Number Plates")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/2022-02-19"},"Flask Web Application")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20"},"Yolo v5 - Data Prep"))),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#setting-up-flask"},"Setting Up Flask"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#hello-world"},"Hello World")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#rendering-html-templates"},"Rendering HTML Templates")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#template-inheritance"},"Template Inheritance")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#create-an-image-file-upload"},"Create an Image File Upload")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#number-plate-detection"},"Number Plate Detection"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#integrating-the-tensorflow-model"},"Integrating the Tensorflow Model")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#integrating-tesseract-ocr"},"Integrating Tesseract OCR")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#use-detection-in-flask"},"Use Detection in Flask")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#display-results-on-page"},"Display Results on Page"))))),(0,r.kt)("h2",{id:"setting-up-flask"},"Setting Up Flask"),(0,r.kt)("h3",{id:"hello-world"},"Hello World"),(0,r.kt)("p",null,"Install Flask using PIP:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pip install flask \n")),(0,r.kt)("p",null,"And create a simple Flask app:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},'from flask import Flask\n\n# Create flask app\napp = Flask(__name__)\n\n# Add app routes\n@app.route(\'/\')\n\n# Create server response\ndef index():\n    return "Hi"\n\n\nif __name__ == "__main__":\n    app.run()\n')),(0,r.kt)("p",null,"Run the app from your console:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'python app.py\n\n * Serving Flask app "app" (lazy loading)\n * Environment: production\n   WARNING: This is a development server. Do not use it in a production deployment.\n   Use a production WSGI server instead.\n * Debug mode: off\n * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n')),(0,r.kt)("p",null,"Verify that the app is running:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"curl http://127.0.0.1:5000/\nHi\n")),(0,r.kt)("h3",{id:"rendering-html-templates"},"Rendering HTML Templates"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"mkdir templates\nnano layout.html\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'<!DOCTYPE html>\n<html lang="">\n  <head>\n    <meta charset="utf-8">\n    <title>Numberplate OCR App</title>\n  </head>\n  <body>\n    <header>\n      <h1>Numberplate Reader</h1>\n    </header>\n    <main></main>\n    <footer></footer>\n  </body>\n</html>\n')),(0,r.kt)("p",null,"Add an import for ",(0,r.kt)("inlineCode",{parentName:"p"},"render_template")," and a route for your template HTML:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"from flask import Flask, render_template\n\n...\n\n@app.route('/app')\ndef application():\n    return render_template('layout.html')\n\n...\n\n")),(0,r.kt)("p",null,"Restart the web app and verify that the HTML is served by Flask:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'curl http://127.0.0.1:5000/app\n\n<!DOCTYPE html>\n<html lang="">\n  <head>\n    <meta charset="utf-8">\n    <title>Numberplate OCR</title>\n  </head>\n  <body>\n    <header>\n      <h1>Numberplate Reader</h1>\n    </header>\n    <main></main>\n    <footer></footer>\n  </body>\n</html>\n')),(0,r.kt)("h3",{id:"template-inheritance"},"Template Inheritance"),(0,r.kt)("p",null,"I now want to use this layout file as a parent component for my later HTML content. I will create another HTML file inside the ",(0,r.kt)("inlineCode",{parentName:"p"},"templates")," folder that should be loaded as a block into the layout page - we can add this to the layout using the JinJa templating engine:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},"<main>\n\n  {% block body %}\n\n\n  {% endblock %}\n\n</main>\n")),(0,r.kt)("p",null,"In my child page I can now extend this ",(0,r.kt)("inlineCode",{parentName:"p"},"body")," section of the layout:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},"{% extends 'layout.html' %}\n\n{% block body %}\n  <div class=\"container is-fluid\">\n    <h1>Body Content</h1>\n  </div>\n{% endblock %}\n")),(0,r.kt)("p",null,"In our app we now have to call the child component that is extending the layout instead of the layout itself:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"@app.route('/')\ndef application():\n    return render_template('index.html')\n")),(0,r.kt)("h3",{id:"create-an-image-file-upload"},"Create an Image File Upload"),(0,r.kt)("p",null,"To upload a file to our Flask server I need to add a form element that allows me to choose a file, assigned a file name of ",(0,r.kt)("inlineCode",{parentName:"p"},"image_name"),", and a submit button that uses the ",(0,r.kt)("strong",{parentName:"p"},"POST")," method to submit this file:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'<form action="#" method="POST" enctype="multipart/form-data">\n  <input class="file-input" type="file" name="image_name" required>\n  <a class="button is-info" type="submit" value="Upload">\n    Submit\n  </a>\n</form>\n')),(0,r.kt)("p",null,"Now I need a handler for the ",(0,r.kt)("strong",{parentName:"p"},"POST")," method in the app route that takes the file and saves it inside an upload directory:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"BASE_PATH = os.getcwd()\nUPLOAD_PATH = os.path.join(BASE_PATH, 'static/upload')\n\n@app.route('/', methods=['GET', 'POST'])\ndef application():\n    if request.method == 'POST':\n        upload_file = request.file['image_name']\n        filename = upload_file.filename\n        path_save = os.path.join(UPLOAD_PATH, filename)\n        upload_file.save(path_save)\n\n        return render_template('index.html')\n\n    return render_template('index.html')\n")),(0,r.kt)("h2",{id:"number-plate-detection"},"Number Plate Detection"),(0,r.kt)("h3",{id:"integrating-the-tensorflow-model"},"Integrating the Tensorflow Model"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"model = tf.keras,models.load_model('./static/models/number_plate_detection.h5')\n\ndef plate_detection(path, filename):\n    # Read image\n    image = load_img(path) # PIL object\n    image = np.array(image,dtype=np.uint8) # 8 bit array (0,255)\n    image1 = load_img(path,target_size=(224,224))\n    # Data preprocessing\n    image_arr_224 = img_to_array(image1)/255.0  # convert into array and get the normalized output\n    h,w,d = image.shape\n    test_arr = image_arr_224.reshape(1,224,224,3)\n    # Make predictions\n    coords = model.predict(test_arr)\n    # De-normalize the values\n    denorm = np.array([w,w,h,h])\n    coords = (coords * denorm).astype(np.int32)\n    # Draw bounding on top the image\n    xmin, xmax,ymin,ymax = coords[0]\n    pt1 =(xmin,ymin)\n    pt2 =(xmax,ymax)\n    print(pt1, pt2)\n    cv2.rectangle(image,pt1,pt2,(0,255,0),3)\n    # Convert into BGR\n    image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    # Save to prediction folder\n    cv2.imwrite('./static/predictions/{}'.format(filename), image_bgr)\n\n    return coords\n")),(0,r.kt)("h3",{id:"integrating-tesseract-ocr"},"Integrating Tesseract OCR"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"def OCR(path, filename):\n    # Read image\n    img = np.array(load_img(path))\n    # Run plate detection\n    coords = plate_detection(path, filename)\n    # Extract bounding box coordinates\n    xmin ,xmax,ymin,ymax = cods[0]\n    # Define bounding box\n    roi = img[ymin:ymax,xmin:xmax]\n    # Convert into BGR\n    roi_bgr = cv2.cvtColor(roi, cv2.COLOR_RGB2BGR)\n\n    # Turn grayscale\n    gray_roi = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2GRAY)\n    gray_roi = cv2.bitwise_not(gray_roi)\n\n    # threshold the image, setting all foreground pixels to\n    # 255 and all background pixels to 0 (invert)\n    thresh_roi = cv2.threshold(gray_roi, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n\n    # Save cut outs to roi folder\n    #cv2.imwrite('./static/roi/{}'.format(filename), roi_bgr)\n    cv2.imwrite('./static/roi/{}'.format(filename), thresh_roi)\n\n    # OCR the ROI using Tesseract\n    text_roi = pt.image_to_string(roi_bgr)\n    print('Original:',text_roi)\n    text_thresh = pt.image_to_string(thresh_roi)\n    print('Threshold:',text_thresh)\n\n    return text_roi, text_thresh\n")),(0,r.kt)("h3",{id:"use-detection-in-flask"},"Use Detection in Flask"),(0,r.kt)("p",null,"Now I can import the ",(0,r.kt)("strong",{parentName:"p"},"OCR function")," and call it from my app route:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"from tf_detection import OCR\n\n@app.route('/', methods=['GET', 'POST'])\ndef application():\n    if request.method == 'POST':\n        # Take uploaded image\n        upload_file = request.files['image_name']\n        filename = str(nowTime) + '_' + upload_file.filename\n        path_save = os.path.join(UPLOAD_PATH, filename)\n        # Store image in upload directory\n        upload_file.save(path_save)\n        # Take image and perform OCR\n        text_roi, text_thresh = OCR(path_save, filename)\n        print(text_roi + '\\n' + text_thresh)\n\n        return render_template('index.html', upload = True, upload_image = filename)\n\n    return render_template('index.html', upload = False)\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Plate Detection Flask App",src:n(51398).Z,width:"1484",height:"624"})),(0,r.kt)("h3",{id:"display-results-on-page"},"Display Results on Page"),(0,r.kt)("p",null,"In the IF statement above I am setting ",(0,r.kt)("inlineCode",{parentName:"p"},"upload = True")," if an upload was processed and ",(0,r.kt)("inlineCode",{parentName:"p"},"upload_image")," is defined. I can now use this variable in the Jinja Template to display the results on my index page."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-html"},'  {% if upload %}\n\n    <div class="container">\n      <br/><br/>\n      <table>\n        <tr>\n          <td>\n            <img class="float-left img-fluid" src="/static/upload/{{ upload_image }}" alt="Source Image" />\n          </td>\n          <td>\n            <img class="float-right img-fluid" src="/static/predictions/{{ upload_image }}" alt="Prediction Image" />\n          </td>\n        </tr>\n      </table>\n      <table>\n        <tr>\n          <th>Region of Interest</th>\n          <th>Detected Text</th>\n          <th>Region of Interest (Threshold)</th>\n          <th>Detected Text</th>\n        </tr>\n        <tr>\n          <td>\n            <img class="float-left img-fluid" src="/static/roi/{{ upload_image + \'_roi\'}} " alt="Region of Interest" />\n          </td>\n          <td>\n            <h3>{{ ocr_roi }}</h3>\n          </td>\n          <td>\n            <img class="float-left img-fluid" src="/static/roi/{{ upload_image + \'_threshroi\'}} " alt="Region of Interest" />\n          </td>\n          <td>\n            <h3>{{ ocr_thresh }}</h3>\n          </td>\n        </tr>\n      </table>\n    </div>\n\n  {% endif %}\n')),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Plate Detection Flask App",src:n(54375).Z,width:"1067",height:"546"})))}m.isMDXComponent=!0},51398:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Plate_Detection_Flask_App_01-ae7889bb85c928d4ac36b540938e1a82.png"},54375:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/Plate_Detection_Flask_App_02-e68e7c222e96636093580512cf96d4f1.png"},47819:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-ffe80356d19fb4b090a3bef79b45aab3.jpg"}}]);