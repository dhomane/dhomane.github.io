"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[43939],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>m});var n=a(67294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,i=function(e,t){if(null==e)return{};var a,n,i={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var o=n.createContext({}),p=function(e){var t=n.useContext(o),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(o.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},g=n.forwardRef((function(e,t){var a=e.components,i=e.mdxType,s=e.originalType,o=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),g=p(a),m=i,h=g["".concat(o,".").concat(m)]||g[m]||d[m]||s;return a?n.createElement(h,r(r({ref:t},c),{},{components:a})):n.createElement(h,r({ref:t},c))}));function m(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var s=a.length,r=new Array(s);r[0]=g;var l={};for(var o in t)hasOwnProperty.call(t,o)&&(l[o]=t[o]);l.originalType=e,l.mdxType="string"==typeof e?e:i,r[1]=l;for(var p=2;p<s;p++)r[p]=a[p];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}g.displayName="MDXCreateElement"},24736:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>r,default:()=>d,frontMatter:()=>s,metadata:()=>l,toc:()=>p});var n=a(87462),i=(a(67294),a(3905));const s={sidebar_position:4980,slug:"2022-12-10",title:"Breast Histopathology Image Segmentation Part 1",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Data Inspection and Pre-processing"},r=void 0,l={unversionedId:"IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1/index",id:"IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1/index",title:"Breast Histopathology Image Segmentation Part 1",description:"Data Inspection and Pre-processing",source:"@site/docs/IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1",slug:"/IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1/2022-12-10",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1/2022-12-10",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Tensorflow",permalink:"/docs/tags/tensorflow"}],version:"current",sidebarPosition:4980,frontMatter:{sidebar_position:4980,slug:"2022-12-10",title:"Breast Histopathology Image Segmentation Part 1",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Data Inspection and Pre-processing"},sidebar:"tutorialSidebar",previous:{title:"Breast Histopathology Image Segmentation Part 2",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part2/2022-12-11"},next:{title:"Deep Docker on Arch",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning/2022-11-27"}},o={},p=[{value:"Data Preprocessing",id:"data-preprocessing",level:2},{value:"Create the Training, Test and Validation Set",id:"create-the-training-test-and-validation-set",level:3},{value:"Custom Model Building and Evaluation",id:"custom-model-building-and-evaluation",level:2},{value:"Requirements",id:"requirements",level:3},{value:"Exploring the Dataset",id:"exploring-the-dataset",level:3},{value:"Distribution",id:"distribution",level:4},{value:"Sample Images",id:"sample-images",level:4}],c={toc:p};function d(e){let{components:t,...s}=e;return(0,i.kt)("wrapper",(0,n.Z)({},c,s,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Guangzhou, China",src:a(61127).Z,width:"1500",height:"383"})),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1/2022-12-10"},"Part 1: Data Inspection and Pre-processing")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part2/2022-12-11"},"Part 2: Weights, Data Augmentations and Generators")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part3/2022-12-11"},"Part 3: Model creation based on a pre-trained and a custom model")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part4/2022-12-11"},"Part 4: Train our model to fit the dataset")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-12-12-tf-breast-cancer-classification-part5/2022-12-12"},"Part 5: Evaluate the performance of your trained model")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-12-12-tf-breast-cancer-classification-part6/2022-12-12"},"Part 6: Running Predictions"))),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},(0,i.kt)("a",{parentName:"p",href:"https://github.com/mpolinowski/tf-bc-classification"},"Github"))),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#data-preprocessing"},"Data Preprocessing"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#create-the-training-test-and-validation-set"},"Create the Training, Test and Validation Set")))),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#custom-model-building-and-evaluation"},"Custom Model Building and Evaluation"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#requirements"},"Requirements")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#exploring-the-dataset"},"Exploring the Dataset"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#distribution"},"Distribution")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#sample-images"},"Sample Images"))))))),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"Based on ",(0,i.kt)("a",{parentName:"p",href:"https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images"},"Breast Histopathology Images")," by ",(0,i.kt)("a",{parentName:"p",href:"https://www.kaggle.com/paultimothymooney"},"Paul Mooney"),".\n",(0,i.kt)("inlineCode",{parentName:"p"},"Invasive Ductal Carcinoma (IDC) is the most common subtype of all breast cancers. To assign an aggressiveness grade to a whole mount sample, pathologists typically focus on the regions which contain the IDC. As a result, one of the common pre-processing steps for automatic aggressiveness grading is to delineate the exact regions of IDC inside of a whole mount slide."),"\n",(0,i.kt)("a",{parentName:"p",href:"https://youtu.be/8XsiMQQ-4mM"},"Can recurring breast cancer be spotted with AI tech? - BBC News"))),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Citation: ",(0,i.kt)("a",{parentName:"li",href:"https://pubmed.ncbi.nlm.nih.gov/27563488/"},"Deep learning for digital pathology image analysis: A comprehensive tutorial with selected use cases")),(0,i.kt)("li",{parentName:"ul"},"Dataset: 198,738 IDC(negative) image patches; 78,786 IDC(positive) image patches")),(0,i.kt)("h2",{id:"data-preprocessing"},"Data Preprocessing"),(0,i.kt)("p",null,"After ",(0,i.kt)("a",{parentName:"p",href:"https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images"},"downloading")," the source photographs unzip them into a folder ",(0,i.kt)("inlineCode",{parentName:"p"},"./dataset/raw"),". Now we need to process this data and process it for the model training."),(0,i.kt)("h3",{id:"create-the-training-test-and-validation-set"},"Create the Training, Test and Validation Set"),(0,i.kt)("p",null,"The configuration file defines the location where data will be stored as well as setting the parameter for the model training:"),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"utils/config.py")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},'import os\n\n# Project location\nPROJECT_PATH = "./"\n# Input dataset directory\nRAW_INPUT_PATH = "./dataset/raw"\n# Result dataset directory\nSPLIT_INPUT_PATH = "./dataset/split"\n# Output directory\nOUTPUT_PATH = "./output"\n\n# Training testing, validation\nTRAIN_PATH = os.path.sep.join([SPLIT_INPUT_PATH, "training"])\nVAL_PATH = os.path.sep.join([SPLIT_INPUT_PATH, "validation"])\nTEST_PATH = os.path.sep.join([SPLIT_INPUT_PATH, "testing"])\n\n# Data splitting\nTRAIN_SPLIT = 0.8\nVAL_SPLIT = 0.1\n\n# Parameters\nCLASSES = ["benign","malignant"]\nBATCH_SIZE = 32\nINIT_LR = 1e-4\nEPOCHS = 20\n\n# Path to serialized model after training\nMODEL_PATH = os.path.sep.join([OUTPUT_PATH, "CarcinomaPrediction.model"])\n\n# Path to training history plots\nMODEL_PATH = os.path.sep.join([OUTPUT_PATH, "TrainingHistory.png"])\n')),(0,i.kt)("p",null,"First we need to split the raw dataset into training and validation set, according to the split ratio set above:"),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"utils/create","_","dataset.py")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},'import config\nimport getPaths\nimport shutil\nimport random\nimport os\n\n\n# Get content of the original input directory and shuffle images\nallImagePaths = list(getPaths.listImages(config.RAW_INPUT_PATH))\nrandom.seed(42)\nrandom.shuffle(allImagePaths)\n\n# Only take 10% of the images to speed up the process\nprint(len(allImagePaths))\nimagePaths = allImagePaths[0:20000]\nprint(len(allImagePaths))\n\n# Split into training and testing data\ni = int(len(allImagePaths) * config.TRAIN_SPLIT)\ntrainPaths = allImagePaths[:i]\ntestPaths = allImagePaths[i:]\n\n# Separate validation split from training data\ni = int(len(trainPaths) * config.VAL_SPLIT)\nvalPaths = trainPaths[:i]\ntrainPaths = trainPaths[i:]\n\n# Defining the datasets which will be build in the result folder\ndatasets = [\n    ("training", config.TRAIN_PATH, trainPaths),\n    ("validation", config.VAL_PATH, valPaths),\n    ("testing", config.TEST_PATH, testPaths)\n]\n\n# Copy images from the initial into the result path\n# while splitting them into train, validation and test data\nfor (dSType, basePath, allImagePaths) in datasets:\n    print("Making \'{}\' split".format(dSType))\n    if not os.path.exists(basePath):\n        print("\'Creating {}\' directory".format(basePath))\n        os.makedirs(basePath)\n    # Looping over the image paths\n    for inputPath in allImagePaths:\n        # Extracting the filename of the input image\n        # Extracting class label ("0" for "Benign" and "1" for "Malignant")\n        filename = inputPath.split(os.path.sep)[-1]\n        label = filename[-5:-4]\n        # Making the path to form the label directory\n        labelPath = os.path.sep.join([basePath, label])\n        if not os.path.exists(labelPath):\n            print("\'creating {}\' directory".format(labelPath))\n            os.makedirs(labelPath)\n        # Creating the path to the destination image and then copying it\n        finalPath = os.path.sep.join([labelPath, filename])\n        shutil.copy2(inputPath, finalPath)\n')),(0,i.kt)("p",null,"This file imports a helper function ",(0,i.kt)("strong",{parentName:"p"},"getPaths")," that helps us decide what files inside the dataset we actually want to use based on their file extension:"),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"utils/getPaths.py")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'import os\n\n# Defining image types you want to allow\nimageTypes = (".jpg", ".jpeg", ".png", ".tif", ".tiff", ".bmp")\n\n\ndef listImages(basePath, contains=None):\n    return listFiles(basePath, validExts=imageTypes, contains=contains)\n\n\ndef listFiles(basePath, validExts=None, contains=None):\n    for (baseDir, dirNames, filenames) in os.walk(basePath):\n        for filename in filenames:\n            # Get all files in filename / ignore empty directories\n            if contains is not None and filename.find(contains) == -1:\n                continue\n\n            # Extracting the file extension\n            fileExt = filename[filename.rfind("."):].lower()\n\n            # Only process files that are of imageTypes\n            if validExts is None or fileExt.endswith(validExts):\n                # Construct the path to the image and yield it\n                imagePath = os.path.join(baseDir, filename)\n                yield imagePath\n')),(0,i.kt)("p",null,"Running the script: "),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"python ./utils/create_dataset.py\nMaking 'training' split\n'Creating ./dataset/split/training' directory\n'creating ./dataset/split/training/0' directory\n'creating ./dataset/split/training/1' directory\nMaking 'validation' split\n'Creating ./dataset/split/validation' directory\n'creating ./dataset/split/validation/0' directory\n'creating ./dataset/split/validation/1' directory\nMaking 'testing' split\n'Creating ./dataset/split/testing' directory\n'creating ./dataset/split/testing/0' directory\n'creating ./dataset/split/testing/1' directory\n")),(0,i.kt)("p",null,"will now go through the raw images in ",(0,i.kt)("inlineCode",{parentName:"p"},"./dataset/raw")," and split them into the ",(0,i.kt)("inlineCode",{parentName:"p"},"./dataset/split")," folders:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},".\n\u251c\u2500\u2500 raw\n\u251c\u2500\u2500 split\n\u2502\xa0\xa0 \u251c\u2500\u2500 testing\n|   \u2502\xa0\xa0 \u251c\u2500\u2500 0\n|   \u2502\xa0\xa0 \u2514\u2500\u2500 1\n\u2502\xa0\xa0 \u251c\u2500\u2500 training\n|   \u2502\xa0\xa0 \u251c\u2500\u2500 0\n|   \u2502\xa0\xa0 \u2514\u2500\u2500 1\n\u2502\xa0\xa0 \u2514\u2500\u2500 validation\n|   \u2502\xa0\xa0 \u251c\u2500\u2500 0\n|   \u2502\xa0\xa0 \u2514\u2500\u2500 1\n")),(0,i.kt)("p",null,"We will get a ",(0,i.kt)("inlineCode",{parentName:"p"},"80%")," training, ",(0,i.kt)("inlineCode",{parentName:"p"},"10%")," testing and ",(0,i.kt)("inlineCode",{parentName:"p"},"10%")," validation split. And based on the file names the images will be separated into ",(0,i.kt)("em",{parentName:"p"},"benign")," ",(0,i.kt)("inlineCode",{parentName:"p"},"0")," and ",(0,i.kt)("em",{parentName:"p"},"malignant")," ",(0,i.kt)("inlineCode",{parentName:"p"},"1"),"."),(0,i.kt)("h2",{id:"custom-model-building-and-evaluation"},"Custom Model Building and Evaluation"),(0,i.kt)("h3",{id:"requirements"},"Requirements"),(0,i.kt)("p",null,"Install the dependencies using ",(0,i.kt)("inlineCode",{parentName:"p"},"pip")," or ",(0,i.kt)("a",{parentName:"p",href:"/docs/Development/Python/2022-12-11-pipenv/2022-12-11"},"pipenv"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"pipenv install tensorflow-gpu scikit-learn matplotlib numpy pandas seaborn opencv-python\n")),(0,i.kt)("p",null,"or"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"pip install -r requirements.txt --upgrade\n")),(0,i.kt)("h3",{id:"exploring-the-dataset"},"Exploring the Dataset"),(0,i.kt)("h4",{id:"distribution"},"Distribution"),(0,i.kt)("p",null,(0,i.kt)("em",{parentName:"p"},"utils/plotDistribution.py")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"# Plotting the count of images within each segment in a directories\ndef plotData(dirPath):\n    # Get the path to the benign and malignant sub-directories\n    benign_cases_dir = dirPath+ '/0/'\n    malignant_cases_dir = dirPath + '/1/'\n\n    # Get the list of all the images from those paths\n    benign_cases = glob.glob(benign_cases_dir + '*.png')\n    malignant_cases = glob.glob(malignant_cases_dir + '*.png')\n\n    # An empty list\n    data1 = []\n\n    # Add all benign cases to list with label `0`\n    for img in benign_cases:\n        data1.append((img,0))\n\n    # Add all benign cases to list with label `1`\n    for img in malignant_cases:\n        data1.append((img, 1))\n\n    # data => pandas dataframe\n    data1 = pd.DataFrame(data1, columns=['image', 'label'],index=None)\n\n    # Shuffle the data \n    data1 = data1.sample(frac=1.).reset_index(drop=True)\n    \n    # Get the counts for each segment\n    cases_count = data1['label'].value_counts()\n    print(cases_count)\n\n    # Plot the results \n    plt.figure(figsize=(10,8))\n    sns.barplot(x=cases_count.index, y= cases_count.values)\n    plt.title('Number of cases', fontsize=14)\n    plt.xlabel('Case type', fontsize=12)\n    plt.ylabel('Count', fontsize=12)\n    plt.xticks(range(len(cases_count.index)), ['benign(0)', 'malignant(1)'])\n    plt.show()\n\ntry:\n    function = sys.argv[1]\n    globals()[function]()\nexcept IndexError:\n    raise Exception(\"Please provide function name\")\nexcept KeyError:\n    raise Exception(\"Function {} hasn't been found\".format(function))\n")),(0,i.kt)("p",null,"By importing the configuration file ",(0,i.kt)("inlineCode",{parentName:"p"},"from utils import config")," we can now print out the distribution of benign and malignant cases in all three folders by running the following commands after adding a little helper function:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},'def exploreData():\n    plotData(config.TRAIN_PATH,"Training Path")\n    # plotData(config.VAL_PATH,"Validation Path")\n    # plotData(config.TEST_PATH,"Test Path")\n')),(0,i.kt)("p",null,"The function can be executed directly:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"pipenv run python ./utils/plotDistribution.py exploreData\n")),(0,i.kt)("p",null,"We can see that we are working with a skewed dataset that is heavy on benign cases. But the splitting of images into the three paths was successful - we did not change the distribution:"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Breast Histopathology Image Segmentation",src:a(23273).Z,width:"2389",height:"635"})),(0,i.kt)("h4",{id:"sample-images"},"Sample Images"),(0,i.kt)("p",null,"Now we can inspect our data by printing a sample of each class:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"# Get the path to the benign and malignant sub-directories\nbenign_cases_dir = config.TRAIN_PATH + '/0/'\nmalignant_cases_dir = config.TRAIN_PATH + '/1/'\n\n# Get the list of all the images from those paths\nbenign_cases = glob.glob(benign_cases_dir + '*.png')\nmalignant_cases = glob.glob(malignant_cases_dir + '*.png')\n\n# An empty list\ntrain_data1 = []\n\n## Add all benign cases to list with label `0`\nfor img in benign_cases:\n    train_data1.append((img,0))\n\n# Go through all the malignant cases. The label for these cases will be 1\nfor img in malignant_cases:\n    train_data1.append((img, 1))\n\n# Add all benign cases to list with label `1`\ntrain_data1 = pd.DataFrame(train_data1, columns=['image', 'label'],index=None)\n\n# Get first 5 images for both classes\nmalignant_samples = (train_data1[train_data1['label']==1]['image'].iloc[:5]).tolist()\nbenign_samples = (train_data1[train_data1['label']==0]['image'].iloc[:5]).tolist()\n\n# Concat the data in a single list and del the above two list\nsamples = malignant_samples + benign_samples\ndel malignant_samples, benign_samples\n\n# Plot the data \nf, ax = plt.subplots(2,5, figsize=(30,10))\nfor i in range(10):\n    img = cv2.imread(samples[i])\n    ax[i//5, i%5].imshow(img, cmap='gray')\n    if i<5:\n        ax[i//5, i%5].set_title(\"benign\")\n    else:\n        ax[i//5, i%5].set_title(\"malignant\")\n    ax[i//5, i%5].axis('off')\n    ax[i//5, i%5].set_aspect('auto')\nplt.show()\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"pipenv run python ./utils/sampleSet.py\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Breast Histopathology Image Segmentation",src:a(89548).Z,width:"2010",height:"792"})))}d.isMDXComponent=!0},23273:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Breast_Histopathology_Image_Segmentation_01-6d3a714b0e24b2c043ff5ada7ed4e067.png"},89548:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Breast_Histopathology_Image_Segmentation_02-d48e4d9da9baae2434aa5554f9e2dee0.png"},61127:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-918471126c0472aad97358a725e1a399.jpg"}}]);