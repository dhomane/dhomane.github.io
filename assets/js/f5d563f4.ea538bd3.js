"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[43180],{3905:(e,a,n)=>{n.d(a,{Zo:()=>d,kt:()=>h});var t=n(67294);function r(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function i(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),n.push.apply(n,t)}return n}function o(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?i(Object(n),!0).forEach((function(a){r(e,a,n[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))}))}return e}function l(e,a){if(null==e)return{};var n,t,r=function(e,a){if(null==e)return{};var n,t,r={},i=Object.keys(e);for(t=0;t<i.length;t++)n=i[t],a.indexOf(n)>=0||(r[n]=e[n]);return r}(e,a);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)n=i[t],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var p=t.createContext({}),s=function(e){var a=t.useContext(p),n=a;return e&&(n="function"==typeof e?e(a):o(o({},a),e)),n},d=function(e){var a=s(e.components);return t.createElement(p.Provider,{value:a},e.children)},m={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},c=t.forwardRef((function(e,a){var n=e.components,r=e.mdxType,i=e.originalType,p=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),c=s(n),h=r,g=c["".concat(p,".").concat(h)]||c[h]||m[h]||i;return n?t.createElement(g,o(o({ref:a},d),{},{components:n})):t.createElement(g,o({ref:a},d))}));function h(e,a){var n=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=c;var l={};for(var p in a)hasOwnProperty.call(a,p)&&(l[p]=a[p]);l.originalType=e,l.mdxType="string"==typeof e?e:r,o[1]=l;for(var s=2;s<i;s++)o[s]=n[s];return t.createElement.apply(null,o)}return t.createElement.apply(null,n)}c.displayName="MDXCreateElement"},1338:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>p,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>l,toc:()=>s});var t=n(87462),r=(n(67294),n(3905));const i={sidebar_position:5070,slug:"2022-02-20",title:"Yolo App - YOLOv5 Data Preparation",authors:"mpolinowski",tags:["Tensorflow","Machine Learning","Python","YOLO"]},o=void 0,l={unversionedId:"IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/index",id:"IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/index",title:"Yolo App - YOLOv5 Data Preparation",description:"Shenzhen, China",source:"@site/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep",slug:"/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/index.md",tags:[{label:"Tensorflow",permalink:"/docs/tags/tensorflow"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Python",permalink:"/docs/tags/python"},{label:"YOLO",permalink:"/docs/tags/yolo"}],version:"current",sidebarPosition:5070,frontMatter:{sidebar_position:5070,slug:"2022-02-20",title:"Yolo App - YOLOv5 Data Preparation",authors:"mpolinowski",tags:["Tensorflow","Machine Learning","Python","YOLO"]},sidebar:"tutorialSidebar",previous:{title:"Deep Audio",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/2022-04-01"},next:{title:"Yolo App - Flask Web Application",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/2022-02-19"}},p={},s=[{value:"Data Preparation",id:"data-preparation",level:2},{value:"Load Labels",id:"load-labels",level:3},{value:"Parse XML Data",id:"parse-xml-data",level:3},{value:"Calculate Bounding Box",id:"calculate-bounding-box",level:3},{value:"Split Testing and Training Data",id:"split-testing-and-training-data",level:2}],d={toc:s};function m(e){let{components:a,...i}=e;return(0,r.kt)("wrapper",(0,t.Z)({},d,i,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Shenzhen, China",src:n(47973).Z,width:"1500",height:"688"})),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/2022-02-15"},"Prepare your Images and get Data")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-02-16--yolo-app-tensorflow-model/2022-02-16"},"Train your Tensorflow Model")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-02-17--yolo-app-prediction-pipeline/2022-02-17"},"Use your Model to do Predictions")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-02-18--yolo-app-ocr/2022-02-18"},"Use Tesseract to Read Number Plates")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/2022-02-19"},"Flask Web Application")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20"},"Yolo v5 - Data Prep"))),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#data-preparation"},"Data Preparation"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#load-labels"},"Load Labels")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#parse-xml-data"},"Parse XML Data")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#calculate-bounding-box"},"Calculate Bounding Box")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#split-testing-and-training-data"},"Split Testing and Training Data"))),(0,r.kt)("p",null,"I now have a clean dataset, a working model and a web application for testing. But the detection process is relatively slow and not suitable for real-time video detection. This is where YOLOv5 comes in."),(0,r.kt)("h2",{id:"data-preparation"},"Data Preparation"),(0,r.kt)("p",null,"There is only one problem with the data that was used to train the Tensorflow model. There I needed to define the bounding box around detect license plates byt the variables ",(0,r.kt)("inlineCode",{parentName:"p"},"xmin"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"xmax"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"ymin"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"ymax"),". But YOLO expects an X & Y value for the center point of the region of interest and it's height & width."),(0,r.kt)("h3",{id:"load-labels"},"Load Labels"),(0,r.kt)("p",null,"Let's start by importing the labels files for our images:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"import numpy as np\nimport pandas as pd\nfrom glob import glob\nimport xml.etree.ElementTree as xet\nimport cv2\nimport os\nimport shutil import copy\n\nimportdf = pd.read_csv('../labels.csv')\ndf.head()\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"    filepath                    xmin    xmax    ymin    ymax\n0   ../resources/cars_170.xml   224     439     77    167\n1   ../resources/cars_171.xml   416     620     536     600\n2   ../resources/cars_172.xml   184     325     114     148\n3   ../resources/cars_173.xml   154     373     91    149\n4   ../resources/cars_174.xml   131     279     213     256\n")),(0,r.kt)("h3",{id:"parse-xml-data"},"Parse XML Data"),(0,r.kt)("p",null,"I now need to convert these bbox values to ",(0,r.kt)("inlineCode",{parentName:"p"},"center_x"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"center_y"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"width")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"height")," and normalize them to their image size. I can start by extracting the image width and height from the generated XML label:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"<annotation>\n    <folder>resources</folder>\n    <filename>cars_1.jpg</filename>\n    <path>/opt/yolo-app/resources/cars_1.jpg</path>\n    <source>\n        <database>Unknown</database>\n    </source>\n    <size>\n        <width>1600</width>\n        <height>1153</height>\n        <depth>3</depth>\n    </size>\n    <segmented>0</segmented>\n    <object>\n        <name>number_plate</name>\n        <pose>Unspecified</pose>\n        <truncated>0</truncated>\n        <difficult>0</difficult>\n        <bndbox>\n            <xmin>1085</xmin>\n            <ymin>561</ymin>\n            <xmax>1354</xmax>\n            <ymax>683</ymax>\n        </bndbox>\n    </object>\n</annotation>\n")),(0,r.kt)("p",null,"The function to parse the image label is:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"# Parsing XML labels\ndef xmlparsing(path):\n    parser = xet.parse(path).getroot()\n    image_path = '../' + parser.find('folder').text + '/' + parser.find('filename').text\n    image_size = parser.find('size')\n    width = int(image_size.find('width').text)\n    height = int(image_size.find('height').text)\n    \n    return image_path, width, height\n")),(0,r.kt)("p",null,"Now I can append the image width and height to my Pandas dataframe with:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"# Take filepath from df and function to append\n# image_path, width and height from XML label\ndf[['image_path','width','height']] = df['filepath'].apply(xmlparsing).apply(pd.Series)\ndf.head()\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"    filepath                      xmin  xmax    ymin    ymax    image_path                  width height\n0   ../resources/cars_170.xml   224     439     77    167   ../resources/cars_170.jpeg  500     234\n1   ../resources/cars_171.xml   416     620     536     600     ../resources/cars_171.jpeg  1070    907\n2   ../resources/cars_172.xml   184     325     114     148     ../resources/cars_172.jpeg  500     333\n3   ../resources/cars_173.xml   154     373     91    149   ../resources/cars_173.jpeg  500     250\n4   ../resources/cars_174.xml   131     279     213     256     ../resources/cars_174.jpeg  414     432\n")),(0,r.kt)("h3",{id:"calculate-bounding-box"},"Calculate Bounding Box"),(0,r.kt)("p",null,"And now to getting the variables that are needed by Yolo:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"# Calculate center_x, center_y, width and height of bounding box\n# and normalize them to image size\ndf['center_x'] = (df['xmax'] + df['xmin'])/(2*df['width'])\ndf['center_y'] = (df['ymax'] + df['ymin'])/(2*df['height'])\n\ndf['bb_width'] = (df['xmax'] - df['xmin'])/df['width']\ndf['bb_height'] = (df['ymax'] - df['ymin'])/df['height']\n\ndf.head()\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"    filepath         image_path           width height  center_x    center_y    bb_width    bb_height\n0 .../cars_170.xml .../cars_170.jpeg    500     234       0.663000  0.521368    0.430000    0.384615\n1 .../cars_171.xml .../cars_171.jpeg    1070    907       0.484112  0.626240    0.190654    0.070562\n2 .../cars_172.xml .../cars_172.jpeg    500     333       0.509000  0.393393    0.282000    0.102102\n3 .../cars_173.xml .../cars_173.jpeg    500     250       0.527000  0.480000    0.438000    0.232000\n4 .../cars_174.xml .../cars_174.jpeg    414     432       0.495169  0.542824    0.357488    0.099537\n")),(0,r.kt)("h2",{id:"split-testing-and-training-data"},"Split Testing and Training Data"),(0,r.kt)("p",null,"Divide image into files used for training and for testing:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"# Take first 220 images for training\ndf_train = df.iloc[:220]\n# Take remaining images for testing\ndf_test = df.iloc[220:]\n")),(0,r.kt)("p",null,"Create labels for training images and copy everything into the trainings folder:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"# Training Data\ntrain_folder = '../data/train'\n\ntrain_values = df_train[['image_path', 'center_x', 'center_y', 'bb_width', 'bb_height']].values\n\n# Create label and copy images to folder\nfor fname, x, y, w, h in train_values:\n    # Get filename from filepath\n    image_name = os.path.split(fname)[-1]\n    # Remove file extension\n    label_name = os.path.splitext(image_name)[0]\n    \n    # Copy training images to train folder\n    dst_image_path = os.path.join(train_folder, image_name)\n    copy(fname,dst_image_path)\n    \n    # Create image label file\n    label_values = f'0 {x} {y} {w} {h}' \n    label_path = os.path.join(train_folder, label_name + '.txt')\n    with open(label_path , mode='w') as f:\n        f.write(label_values)\n        f.close()\n")),(0,r.kt)("p",null,"And repeat this step for the testing images:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"# Testing Data\ntest_folder = '../data/test'\n\ntest_values = df_test[['image_path', 'center_x', 'center_y', 'bb_width', 'bb_height']].values\n\n# Create label and copy images to folder\nfor fname, x, y, w, h in test_values:\n    # Get filename from filepath\n    image_name = os.path.split(fname)[-1]\n    # Remove file extension\n    label_name = os.path.splitext(image_name)[0]\n    \n    # Copy training images to train folder\n    dst_image_path = os.path.join(test_folder, image_name)\n    copy(fname,dst_image_path)\n    \n    # Create image label file\n    label_values = f'0 {x} {y} {w} {h}' \n    label_path = os.path.join(test_folder, label_name + '.txt')\n    with open(label_path , mode='w') as f:\n        f.write(label_values)\n        f.close()\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Plate Detection Flask App",src:n(42153).Z,width:"1484",height:"624"})))}m.isMDXComponent=!0},42153:(e,a,n)=>{n.d(a,{Z:()=>t});const t=n.p+"assets/images/Plate_Detection_Yolo_App_01-ae7889bb85c928d4ac36b540938e1a82.png"},47973:(e,a,n)=>{n.d(a,{Z:()=>t});const t=n.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-ffe80356d19fb4b090a3bef79b45aab3.jpg"}}]);