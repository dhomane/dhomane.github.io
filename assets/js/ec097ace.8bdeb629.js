"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[51448],{3905:(e,t,a)=>{a.d(t,{Zo:()=>d,kt:()=>m});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},d=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),u=p(a),m=r,g=u["".concat(s,".").concat(m)]||u[m]||c[m]||l;return a?n.createElement(g,i(i({ref:t},d),{},{components:a})):n.createElement(g,i({ref:t},d))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,i=new Array(l);i[0]=u;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:r,i[1]=o;for(var p=2;p<l;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},70048:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>c,frontMatter:()=>l,metadata:()=>o,toc:()=>p});var n=a(87462),r=(a(67294),a(3905));const l={sidebar_position:9080,slug:"2021-10-31",title:"Tesseract OCR on Arch Linux",authors:"mpolinowski",tags:["Machine Learning","Python"]},i=void 0,o={unversionedId:"IoT-and-Machine-Learning/ML/2021-10-31--tesseract_ocr_arch_linux/index",id:"IoT-and-Machine-Learning/ML/2021-10-31--tesseract_ocr_arch_linux/index",title:"Tesseract OCR on Arch Linux",description:"Victoria Harbour, Hongkong",source:"@site/docs/IoT-and-Machine-Learning/ML/2021-10-31--tesseract_ocr_arch_linux/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2021-10-31--tesseract_ocr_arch_linux",slug:"/IoT-and-Machine-Learning/ML/2021-10-31--tesseract_ocr_arch_linux/2021-10-31",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-10-31--tesseract_ocr_arch_linux/2021-10-31",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2021-10-31--tesseract_ocr_arch_linux/index.md",tags:[{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Python",permalink:"/docs/tags/python"}],version:"current",sidebarPosition:9080,frontMatter:{sidebar_position:9080,slug:"2021-10-31",title:"Tesseract OCR on Arch Linux",authors:"mpolinowski",tags:["Machine Learning","Python"]},sidebar:"tutorialSidebar",previous:{title:"Introduction to Keras",permalink:"/docs/IoT-and-Machine-Learning/ML/2019-04-01--introduction-to-keras/2019-04-01"},next:{title:"Introduction to TensorFlow 2 Beta",permalink:"/docs/IoT-and-Machine-Learning/ML/2019-03-31--introduction-to-tensorflow-2-beta/2019-03-31"}},s={},p=[{value:"Project Setup",id:"project-setup",level:2},{value:"Loading Image files from Disk",id:"loading-image-files-from-disk",level:2},{value:"Text Extraction",id:"text-extraction",level:2},{value:"Data Preparation",id:"data-preparation",level:2},{value:"Drawing Bounding Box",id:"drawing-bounding-box",level:3},{value:"Import all Cards",id:"import-all-cards",level:2},{value:"Extract all Text",id:"extract-all-text",level:2},{value:"Write Extracted Text to File",id:"write-extracted-text-to-file",level:2},{value:"Labeling your Data",id:"labeling-your-data",level:2}],d={toc:p};function c(e){let{components:t,...l}=e;return(0,r.kt)("wrapper",(0,n.Z)({},d,l,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Victoria Harbour, Hongkong",src:a(14690).Z,width:"1500",height:"663"})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2021-10-31--tesseract_ocr_arch_linux/2021-10-31"},"Part I - Tesseract OCR on Arch Linux")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2021-11-01--spacy_natural_language_processing/2021-11-01"},"Part II - spaCy NER on Arch Linux")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2021-11-02--spacy_ner_predictions/2021-11-02"},"Part III - spaCy NER Predictions"))),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/tesseract-ocr/tesseract"},"Tesseract")," is an optical character recognition engine for various operating systems. It is free software, released under the Apache License. Originally developed by Hewlett-Packard as proprietary software in the 1980s, it was released as open source in 2005 and development has been sponsored by Google since 2006."),(0,r.kt)("p",null,"In 2006, Tesseract was considered one of the most accurate open-source OCR engines available."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#project-setup"},"Project Setup")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#loading-image-files-from-disk"},"Loading Image files from Disk")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#text-extraction"},"Text Extraction")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#data-preparation"},"Data Preparation"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#drawing-bounding-box"},"Drawing Bounding Box")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#import-all-cards"},"Import all Cards")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#extract-all-text"},"Extract all Text")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#write-extracted-text-to-file"},"Write Extracted Text to File")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#labeling-your-data"},"Labeling your Data"))),(0,r.kt)("h2",{id:"project-setup"},"Project Setup"),(0,r.kt)("p",null,"Make sure you have Python installed and added to PATH:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"python --version\nPython 3.9.7\n\npip --version\npip 21.3.1\n")),(0,r.kt)("p",null,"Create a work directory and set up a virtual environment:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"mkdir -p opt/Python/pyOCR\npython -m venv .env\nsource .env/bin/activate\n")),(0,r.kt)("p",null,"Create a file ",(0,r.kt)("inlineCode",{parentName:"p"},"dependencies.txt")," with all the necessary dependencies:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"numpy\npandas\nscipy\nmatplotlib\npillow\nopencv-python\nopencv-contrib-python\njupyter\n")),(0,r.kt)("p",null,"And install them via the Python package manager:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pip install -r dependencies.txt\n")),(0,r.kt)("p",null,"Install Tesseract globally with PACMAN:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pacman -Syu tesseract\n\nlooking for conflicting packages...\nPackages (2) leptonica-1.82.0-1  tesseract-4.1.1-7\n")),(0,r.kt)("p",null,"Verify that the installation was sucessful:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"tesseract -v\ntesseract 4.1.1\n")),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/tesseract-ocr/tessdata"},"Install the trainings data")," you need depending on your language requirement - e.g. English:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"sudo pacman -S tesseract-data-eng\n")),(0,r.kt)("p",null,"Now we can add our last dependency - a libray that allows us to use Tesseract in our program:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pip install pytesseract\nSuccessfully installed Pillow-8.4.0 pytesseract-0.3.8\n")),(0,r.kt)("p",null,"I am going to use a Jupyter notebook to experiment with Tesseract:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"jupyter notebook\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tesseract",src:a(63547).Z,width:"994",height:"329"})),(0,r.kt)("p",null,"When you are bale to import all dependencies without getting an error message you are all set!"),(0,r.kt)("h2",{id:"loading-image-files-from-disk"},"Loading Image files from Disk"),(0,r.kt)("p",null,"I want to train a model that allows me to extract contact information from business cards. To get started you can download card templates:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tesseract",src:a(42629).Z,width:"1161",height:"902"})),(0,r.kt)("p",null,"Download them to ",(0,r.kt)("inlineCode",{parentName:"p"},"./images")," and try to import them into your notebook using OpenCV and Pillow:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import numpy as np\nimport pandas as pd\nimport PIL as pl\nimport cv2 as cv\nimport pytesseract as ts\n\n# Pillow\n# Use the full path here\nimg_pl = pl.Image.open('/opt/Python/pyOCR/images/card_46.jpg')\nimg_pl\n\n# OpenCV\n# Use the full path here\nimg_cv = cv2.imread('/opt/Python/pyOCR/images/card_46.jpg')\ncv.startWindowThread()\ncv.imshow('Business Card', img_cv)\ncv.waitKey(0)\ncv.destoyAllWindows()\n")),(0,r.kt)("p",null,"Pillow returns a Jpg image file, while OpenCV returns an array:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"type(img_pl) #PIL.JpegImagePlugin.JpegImageFile\n\ntype(img_cv) #numpy.ndarray\n")),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"There seems to be an ",(0,r.kt)("a",{parentName:"p",href:"https://stackoverflow.com/questions/13734276/python-freezes-after-cv2-destroywindow"},"issue with the OpenCV destroyAllWindows method under Linux"),". I will exclude it for now and work with Pillow instead.")),(0,r.kt)("h2",{id:"text-extraction"},"Text Extraction"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"text_pl = ts.image_to_string(img_pl)\nprint(text_pl)\n")),(0,r.kt)("p",null,"Test your business cards and see which one are readable and which one are not. I downloaded quite a few that were too low in resolution and had to be discarded."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"data = ts.image_to_data(img_pl)\n")),(0,r.kt)("p",null,"Now that we can read the text we now have to write it into an data object to be able to work with it. The data is structured by ",(0,r.kt)("inlineCode",{parentName:"p"},"\\n")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"\\t")," markers:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"'level\\tpage_num\\tblock_num\\tpar_num\\tline_num\\tword_num\\tleft\\ttop\\twidth\\theight\\tconf\\ttext\\n1\\t1\\t0\\t0\\t0\\t0\\t0\\t0\\t875\\t518\\t-1\\t\\n2\\t1\\t1\\t0\\t0\\t0\\t532\\t37\\t306\\t38\\t-1\\t\\n3\\t1\\t1\\t1\\t0\\t0\\t532\\t37\\t306\\t38\\t-1\\t\\n4\\t1\\t1\\t1\\t1 ...\n")),(0,r.kt)("p",null,"We can clean up this data with a map:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"dataList = list(map(lambda x: x.split('\\t'),data.split('\\n')))\n")),(0,r.kt)("p",null,"We can now wrap this data into a Pandas Dataframe:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"df = pd.DataFrame(dataList[1:],columns=dataList[0])\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"df.info()\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 56 entries, 0 to 55\nData columns (total 12 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   level      56 non-null     object\n 1   page_num   55 non-null     object\n 2   block_num  55 non-null     object\n 3   par_num    55 non-null     object\n 4   line_num   55 non-null     object\n 5   word_num   55 non-null     object\n 6   left       55 non-null     object\n 7   top        55 non-null     object\n 8   width      55 non-null     object\n 9   height     55 non-null     object\n 10  conf       55 non-null     object\n 11  text       55 non-null     object\ndtypes: object(12)\nmemory usage: 5.4+ KB\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Note")," the height column corresponds to the font size of your word. You can see a confidence drop when the size is too small."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"df.head(10)\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tesseract",src:a(44938).Z,width:"932",height:"514"})),(0,r.kt)("h2",{id:"data-preparation"},"Data Preparation"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"df.dropna(inplace=True) # Drop empty values and rows\ncol_int = ['level','page_num','block_num','par_num','line_num','word_num','left','top','width','height','conf']\ndf[col_int] = df[col_int].astype(int) # Change all columns with number values to type int\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"df.dtypes\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"level         int64\npage_num      int64\nblock_num     int64\npar_num       int64\nline_num      int64\nword_num      int64\nleft          int64\ntop           int64\nwidth         int64\nheight        int64\nconf          int64\ntext         object\ndtype: object\n")),(0,r.kt)("h3",{id:"drawing-bounding-box"},"Drawing Bounding Box"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"image = img_cv.copy()\nlevel = 'word'\nfor l,x,y,w,h,c,t in df[['level','left','top','width','height','conf','text']].values:\n    #print(l,x,y,w,h,c)\n    \n    if level == 'page':\n          if l == 1:\n                cv.rectangle(image,(x,y),(x+w,y+h),(0,0,0,),2)\n          else:\n            continue\n            \n    elif level == 'block':\n          if l == 2:\n                cv.rectangle(image,(x,y),(x+w,y+h),(255,0,0,),1)\n          else:\n            continue\n            \n    elif level == 'paragraph':\n          if l == 3:\n                cv.rectangle(image,(x,y),(x+w,y+h),(0,255,0,),1)\n          else:\n            continue\n            \n    elif level == 'line':\n          if l == 4:\n                cv.rectangle(image,(x,y),(x+w,y+h),(255,0,51,),1)\n          else:\n            continue\n            \n    elif level == 'word':\n          if l == 5:\n                cv.rectangle(image,(x,y),(x+w,y+h),(0,0,255,),1)\n                cv.putText(image,t,(x,y),cv.FONT_HERSHEY_COMPLEX_SMALL,1,(255,255,255),1)\n          else:\n            continue\n                             \ncv.imshow(\"bounding box\",image)\ncv.waitKey(0)\ncv.destoyAllWindows()\ncv.waitKey(1)\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tesseract",src:a(58268).Z,width:"952",height:"727"})),(0,r.kt)("h2",{id:"import-all-cards"},"Import all Cards"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import numpy as np\nimport pandas as pd\nimport cv2 as cv\nimport pytesseract as ts\n\nimport os\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimgPaths = glob('/opt/Python/pyOCR/images/*.jpg')\n")),(0,r.kt)("p",null,"Try ",(0,r.kt)("inlineCode",{parentName:"p"},"print(imgPaths)")," to see if your images are found - note that I had to use the absolute path to my images folder here."),(0,r.kt)("p",null,"Extract the filename:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"imgPath = imgPaths[0]\n_, filename = os.path.split(imgPath)\n")),(0,r.kt)("p",null,"Run ",(0,r.kt)("inlineCode",{parentName:"p"},"print(filename)")," - now it only returns the image name instead of the entire path."),(0,r.kt)("h2",{id:"extract-all-text"},"Extract all Text"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"image = cv.imread(imgPath)\ndata = ts.image_to_data(image)\n\ndataList = list(map(lambda x: x.split('\\t'),data.split('\\n')))\ndf = pd.DataFrame(dataList[1:], columns=dataList[0])\n")),(0,r.kt)("p",null,"Print the value of ",(0,r.kt)("inlineCode",{parentName:"p"},"df")," to see if your image was sucessfully read."),(0,r.kt)("p",null,"Now we can filter for text (",(0,r.kt)("inlineCode",{parentName:"p"},"level=5"),") that has a suitable confidence value (e.g. ",(0,r.kt)("strong",{parentName:"p"},">30%"),"):"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"df.dropna(inplace=True)\ndf['conf'] = df['conf'].astype(int)\ntextData = df.query('conf >= 30')\n\nbusinessCard = pd.DataFrame()\nbusinessCard['text'] = textData['text']\nbusinessCard['id'] = filename\n")),(0,r.kt)("p",null,"Print out ",(0,r.kt)("inlineCode",{parentName:"p"},"businessCard")," and you will see all the text that was discovered on your ",(0,r.kt)("strong",{parentName:"p"},"first (index 0) business card")," that had a confidence level of over ",(0,r.kt)("strong",{parentName:"p"},"30%"),"."),(0,r.kt)("p",null,"Now all we have to do is to take this code and run a loop over it to capture all images inside the directory:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"allBusinessCards = pd.DataFrame(columns=['id', 'text'])\n\nfor imgPath in tqdm(imgPaths,desc=\"Business Card\"):\n\n    # Get Filenames\n    _, filename = os.path.split(imgPath)\n    # Extract Data\n    image = cv.imread(imgPath)\n    data = ts.image_to_data(image)\n    # Write Data to Frame\n    dataList = list(map(lambda x: x.split('\\t'),data.split('\\n')))\n    df = pd.DataFrame(dataList[1:], columns=dataList[0])\n    # Drop Everything that is not useful\n    df.dropna(inplace=True)\n    df['conf'] = df['conf'].astype(int)\n    textData = df.query('conf >= 30')\n    # Define a Business Card Entity\n    businessCard = pd.DataFrame()\n    businessCard['text'] = textData['text']\n    businessCard['id'] = filename\n    # Add Card to All Cards\n    allBusinessCards = pd.concat((allBusinessCards,businessCard))\n")),(0,r.kt)("h2",{id:"write-extracted-text-to-file"},"Write Extracted Text to File"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"allBusinessCards.to_csv('businessCards.csv', index=False)\n")),(0,r.kt)("p",null,"The data will be written to ",(0,r.kt)("inlineCode",{parentName:"p"},"./src/businessCards.csv")," for further processing."),(0,r.kt)("h2",{id:"labeling-your-data"},"Labeling your Data"),(0,r.kt)("p",null,"Mark the start and end of each word of importance:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null}),(0,r.kt)("th",{parentName:"tr",align:null}))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"B")),(0,r.kt)("td",{parentName:"tr",align:null},"Beginning")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"I")),(0,r.kt)("td",{parentName:"tr",align:null},"Inside")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"O")),(0,r.kt)("td",{parentName:"tr",align:null},"Outside")))),(0,r.kt)("p",null,"And define the entities you want to search for:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null}),(0,r.kt)("th",{parentName:"tr",align:null}))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"NAME")),(0,r.kt)("td",{parentName:"tr",align:null},"Name")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"DES")),(0,r.kt)("td",{parentName:"tr",align:null},"Designation")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"ORG")),(0,r.kt)("td",{parentName:"tr",align:null},"Organisation")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"PHONE")),(0,r.kt)("td",{parentName:"tr",align:null},"Phone Number")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"EMAIL")),(0,r.kt)("td",{parentName:"tr",align:null},"Email Address")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("strong",{parentName:"td"},"WEB")),(0,r.kt)("td",{parentName:"tr",align:null},"Website")))),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tesseract",src:a(93358).Z,width:"942",height:"560"})))}c.isMDXComponent=!0},63547:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Tesseract_01-aaa50dea5b1d674a13d5d7ab1c1e5886.png"},42629:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Tesseract_02-1bcd79edbbed3742dde953cd039b3eb3.png"},44938:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Tesseract_03-29b7a1ddc04cfe7529784643fe5c92df.png"},58268:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Tesseract_04-6d261271a3b0bc723f4989b427f22d23.png"},93358:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/Tesseract_05-6f0fdccac87f9c4cd4cbf66bf2a48083.png"},14690:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-4f747fa38245d3c618169ab90d8c3f77.jpg"}}]);