"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[52964],{3905:(e,n,t)=>{t.d(n,{Zo:()=>d,kt:()=>m});var a=t(67294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,o=function(e,n){if(null==e)return{};var t,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var l=a.createContext({}),p=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},d=function(e){var n=p(e.components);return a.createElement(l.Provider,{value:n},e.children)},u={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},c=a.forwardRef((function(e,n){var t=e.components,o=e.mdxType,i=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),c=p(t),m=o,h=c["".concat(l,".").concat(m)]||c[m]||u[m]||i;return t?a.createElement(h,r(r({ref:n},d),{},{components:t})):a.createElement(h,r({ref:n},d))}));function m(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var i=t.length,r=new Array(i);r[0]=c;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,r[1]=s;for(var p=2;p<i;p++)r[p]=t[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,t)}c.displayName="MDXCreateElement"},25241:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>p});var a=t(87462),o=(t(67294),t(3905));const i={sidebar_position:9e3,slug:"2019-03-05",title:"Setting up an OKD Cluster",authors:"mpolinowski",tags:["LINUX","Docker","OpenShift"]},r=void 0,s={unversionedId:"DevOps/Kubernetes/2019-03-05--first-openshift3-cluster/index",id:"DevOps/Kubernetes/2019-03-05--first-openshift3-cluster/index",title:"Setting up an OKD Cluster",description:"Mustang, Nepal",source:"@site/docs/DevOps/Kubernetes/2019-03-05--first-openshift3-cluster/index.mdx",sourceDirName:"DevOps/Kubernetes/2019-03-05--first-openshift3-cluster",slug:"/DevOps/Kubernetes/2019-03-05--first-openshift3-cluster/2019-03-05",permalink:"/docs/DevOps/Kubernetes/2019-03-05--first-openshift3-cluster/2019-03-05",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/DevOps/Kubernetes/2019-03-05--first-openshift3-cluster/index.mdx",tags:[{label:"LINUX",permalink:"/docs/tags/linux"},{label:"Docker",permalink:"/docs/tags/docker"},{label:"OpenShift",permalink:"/docs/tags/open-shift"}],version:"current",sidebarPosition:9e3,frontMatter:{sidebar_position:9e3,slug:"2019-03-05",title:"Setting up an OKD Cluster",authors:"mpolinowski",tags:["LINUX","Docker","OpenShift"]},sidebar:"tutorialSidebar",previous:{title:"Kubernetes Beyond the Edge",permalink:"/docs/DevOps/Kubernetes/2022-11-19--k3s-air-gapped-kubernetes/2022-11-19"},next:{title:"Red Hat OpenShift 3 Container Platform",permalink:"/docs/DevOps/Kubernetes/2019-03-02--installing-openshift-3-on-centos-7/2019-03-02"}},l={},p=[{value:"System and environment requirements",id:"system-and-environment-requirements",level:2},{value:"SELinux requirements",id:"selinux-requirements",level:3},{value:"Optional: Configuring Core Usage",id:"optional-configuring-core-usage",level:3},{value:"DNS Requirements",id:"dns-requirements",level:3},{value:"Packages Requirements",id:"packages-requirements",level:3},{value:"OpenShift Installation",id:"openshift-installation",level:2},{value:"Enable NetworkManager and Docker Services",id:"enable-networkmanager-and-docker-services",level:3},{value:"Install Ansible and Clone Openshift-Ansible on the Master Node",id:"install-ansible-and-clone-openshift-ansible-on-the-master-node",level:3},{value:"Generate SSH Keys on the Master Node",id:"generate-ssh-keys-on-the-master-node",level:3},{value:"Creating the OpenShift Inventory File",id:"creating-the-openshift-inventory-file",level:2}],d={toc:p};function u(e){let{components:n,...i}=e;return(0,o.kt)("wrapper",(0,a.Z)({},d,i,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Mustang, Nepal",src:t(66362).Z,width:"1500",height:"530"})),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#system-and-environment-requirements"},"System and environment requirements"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#selinux-requirements"},"SELinux requirements")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#optional-configuring-core-usage"},"Optional: Configuring Core Usage")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#dns-requirements"},"DNS Requirements")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#packages-requirements"},"Packages Requirements")))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#openshift-installation"},"OpenShift Installation"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#enable-networkmanager-and-docker-services"},"Enable NetworkManager and Docker Services")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#install-ansible-and-clone-openshift-ansible-on-the-master-node"},"Install Ansible and Clone Openshift-Ansible on the Master Node")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#generate-ssh-keys-on-the-master-node"},"Generate SSH Keys on the Master Node")))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#creating-the-openshift-inventory-file"},"Creating the OpenShift Inventory File"))),(0,o.kt)("p",null,"OKD brings together Docker and Kubernetes, and provides an API to manage these services. OKD allows you to create and manage containers."),(0,o.kt)("p",null,"Containers are standalone processes that run within their own environment, independent of the operating system and the underlying infrastructure. OKD helps you to develop, deploy, and manage container-based applications. It provides you with a self-service platform to create, modify, and deploy applications on demand, thus enabling faster development and release life cycles."),(0,o.kt)("h2",{id:"system-and-environment-requirements"},"System and environment requirements"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Master hosts")," In a highly available OKD cluster with external etcd, a master host needs to meet the minimum requirements and have 1 CPU core and 1.5 GB of memory for each 1000 pods. Therefore, the recommended size of a master host in an OKD cluster of 2000 pods is the minimum requirements of 2 CPU cores and 16 GB of RAM, plus 2 CPU cores and 3 GB of RAM, totaling 4 CPU cores and 19 GB of RAM.")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Node hosts"),": The size of a node host depends on the expected size of its workload. As an OKD cluster administrator, you need to calculate the expected workload and add about 10 percent for overhead. For production environments, allocate enough resources so that a node host failure does not affect your maximum capacity.")),(0,o.kt)("hr",null),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"/var/lib/openshift"))),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Used for etcd storage only when in single master mode and etcd is embedded in the atomic-openshift-master process."),(0,o.kt)("li",{parentName:"ul"},"Less than 10GB."),(0,o.kt)("li",{parentName:"ul"},"Will grow slowly with the environment. Only storing metadata.")),(0,o.kt)("ol",{start:2},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"/var/lib/etcd"))),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Used for etcd storage when in Multi-Master mode or when etcd is made standalone by an administrator."),(0,o.kt)("li",{parentName:"ul"},"Less than 20 GB."),(0,o.kt)("li",{parentName:"ul"},"Will grow slowly with the environment. Only storing metadata.")),(0,o.kt)("ol",{start:3},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"/var/lib/docker"))),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"When the run time is docker, this is the mount point. Storage used for active container runtimes (including pods) and storage of local images (not used for registry storage). Mount point should be managed by docker-storage rather than manually."),(0,o.kt)("li",{parentName:"ul"},"50 GB for a Node with 16 GB memory. Additional 20-25 GB for every additional 8 GB of memory."),(0,o.kt)("li",{parentName:"ul"},"Growth is limited by the capacity for running containers.")),(0,o.kt)("ol",{start:4},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"/var/lib/containers"))),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"When the run time is CRI-O, this is the mount point. Storage used for active container runtimes (including pods) and storage of local images (not used for registry storage)."),(0,o.kt)("li",{parentName:"ul"},"50 GB for a Node with 16 GB memory. Additional 20-25 GB for every additional 8 GB of memory."),(0,o.kt)("li",{parentName:"ul"},"Growth limited by capacity for running containers")),(0,o.kt)("ol",{start:5},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"/var/lib/origin/openshift.local.volumes"))),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Ephemeral volume storage for pods. This includes anything external that is mounted into a container at runtime. Includes environment variables, kube secrets, and data volumes not backed by persistent storage PVs."),(0,o.kt)("li",{parentName:"ul"},"Varies"),(0,o.kt)("li",{parentName:"ul"},"Minimal if pods requiring storage are using persistent volumes. If using ephemeral storage, this can grow quickly.")),(0,o.kt)("ol",{start:6},(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"/var/log"))),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Log files for all components."),(0,o.kt)("li",{parentName:"ul"},"10 to 30 GB."),(0,o.kt)("li",{parentName:"ul"},"Log files can grow quickly; size can be managed by growing disks or managed using log rotate.")),(0,o.kt)("hr",null),(0,o.kt)("h3",{id:"selinux-requirements"},"SELinux requirements"),(0,o.kt)("p",null,"Security-Enhanced Linux (SELinux) must be enabled on all of the servers before installing OKD or the installer will fail. Also, configure ",(0,o.kt)("inlineCode",{parentName:"p"},"SELINUX=enforcing")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"SELINUXTYPE=targeted")," in the ",(0,o.kt)("inlineCode",{parentName:"p"},"/etc/selinux/config")," file:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-cfg"},"# This file controls the state of SELinux on the system.\n# SELINUX= can take one of these three values:\n#     enforcing - SELinux security policy is enforced.\n#     permissive - SELinux prints warnings instead of enforcing.\n#     disabled - No SELinux policy is loaded.\nSELINUX=enforcing\n# SELINUXTYPE= can take one of three two values:\n#     targeted - Targeted processes are protected,\n#     minimum - Modification of targeted policy. Only selected processes are protected.\n#     mls - Multi Level Security protection.\nSELINUXTYPE=targeted\n")),(0,o.kt)("h3",{id:"optional-configuring-core-usage"},"Optional: Configuring Core Usage"),(0,o.kt)("p",null,"By default, OKD masters and nodes use all available cores in the system they run on. You can choose the number of cores you want OKD to use by setting the GOMAXPROCS environment variable. For example, run the following before starting the server to make OKD only run on one core:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"# export GOMAXPROCS=1\n")),(0,o.kt)("h3",{id:"dns-requirements"},"DNS Requirements"),(0,o.kt)("p",null,"Adding entries into the ",(0,o.kt)("inlineCode",{parentName:"p"},"nano /etc/hosts")," file on each host is not enough (",(0,o.kt)("em",{parentName:"p"},"? According to the official documentation ?"),"). In the example below all three host - one master and two minions - are resolved by their domain name ",(0,o.kt)("inlineCode",{parentName:"p"},"in-centos-master"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"in-centos-minion1"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"in-centos-minion2"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"# The following lines are desirable for IPv4 capable hosts\n127.0.0.1 localhost.localdomain localhost\n127.0.0.1 localhost4.localdomain4 localhost4\n\n# The following lines are desirable for IPv6 capable hosts\n::1 localhost.localdomain localhost\n::1 localhost6.localdomain6 localhost6\n\n# Kubernetes Cluster\n193.101.18.2 in-centos-master master\n116.211.18.8 in-centos-minion1 minion1\n78.33.18.14 in-centos-minion2 minion2\n")),(0,o.kt)("p",null,"You can test that the nodes are able to reach each other by sending a ping: ",(0,o.kt)("inlineCode",{parentName:"p"},"ping master"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"ping minion1"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"ping minion2"),". You can set those hostnames on each node with the following command:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"hostnamectl set-hostname in-centos-master  # for the master node, etc.\n")),(0,o.kt)("h3",{id:"packages-requirements"},"Packages Requirements"),(0,o.kt)("p",null,"On a fresh Centos-minimal install you will have to install the following packages on all nodes:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"yum install -y wget git zile nano net-tools docker bind-utils iptables-services bridge-utils bash-completion kexec-tools sos psacct openssl-devel httpd-tools NetworkManager python-cryptography python2-pip python-devel python-passlib java-1.8.0-openjdk-headless '@Development Tools'\n")),(0,o.kt)("h2",{id:"openshift-installation"},"OpenShift Installation"),(0,o.kt)("p",null,"Add the Epel Release (and disable it by default) and the Centos Openshift Mirror:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"rpm -ivh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm\n\nsed -i -e 's/^enabled=1/enabled=0/' /etc/yum.repos.d/epel.repo\n\nnano /etc/yum.repos.d/Openshift.repo\n")),(0,o.kt)("p",null,"Add the following configuration:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"[openshift]\nname=CentOS-OpenShift\nbaseurl=http://mirror.centos.org/centos/7/paas/x86_64/openshift-origin39\ngpgcheck=0\nenabled=1\n")),(0,o.kt)("p",null,"And check that both have been added with:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"yum repolist\n")),(0,o.kt)("h3",{id:"enable-networkmanager-and-docker-services"},"Enable NetworkManager and Docker Services"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"systemctl start NetworkManager\nsystemctl enable NetworkManager\nsystemctl status NetworkManager\n\nsystemctl start docker\nsystemctl enable docker\nsystemctl status docker\n")),(0,o.kt)("h3",{id:"install-ansible-and-clone-openshift-ansible-on-the-master-node"},"Install Ansible and Clone Openshift-Ansible on the Master Node"),(0,o.kt)("p",null,"Now we can install ",(0,o.kt)("a",{parentName:"p",href:"https://docs.ansible.com/"},"Ansible")," from the Epel repository - note you need to enable it first if you followed along and disabled it earlier:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"yum -y --enablerepo=epel install ansible pyOpenSSL\ngit clone https://github.com/openshift/openshift-ansible.git\ncd openshift-ansible && git fetch && git checkout release-3.11\n")),(0,o.kt)("p",null,"Now we have the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/openshift/openshift-ansible"},"OpenShift-Ansible")," package cloned and the checked out the latest stable version 3.11."),(0,o.kt)("h3",{id:"generate-ssh-keys-on-the-master-node"},"Generate SSH Keys on the Master Node"),(0,o.kt)("p",null,"We can now generate an SSH key on our master and copy it to the minion nodes:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"ssh-keygen -f ~/.ssh/id_rsa -N ''\n")),(0,o.kt)("p",null,"This will generate a key in ",(0,o.kt)("inlineCode",{parentName:"p"},"~/.ssh/id_rsa.pub")," that you have to copy to each node to be able to ssh into those nodes without a password:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"ssh-copy-id -i ~/.ssh/id_rsa.pub master -p 22\nssh-copy-id -i ~/.ssh/id_rsa.pub minion1 -p 22\nssh-copy-id -i ~/.ssh/id_rsa.pub minion2 -p 22\n")),(0,o.kt)("p",null,"Now verify that you are able to access each node from the master without having to use your password to login:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"ssh root@master -p 22\nssh root@minion1 -p 22\nssh root@minion2 -p 22\n")),(0,o.kt)("h2",{id:"creating-the-openshift-inventory-file"},"Creating the OpenShift Inventory File"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://docs.ansible.com/ansible/latest/user_guide/playbooks_intro.html"},"Playbooks")," are a completely different way to use ansible than in ad-hoc task execution mode, and are particularly powerful."),(0,o.kt)("p",null,"Simply put, playbooks are the basis for a really simple configuration management and multi-machine deployment system, unlike any that already exist, and one that is very well suited to deploying complex applications. Playbooks can declare configurations, but they can also orchestrate steps of any manual ordered process, even as different steps must bounce back and forth between sets of machines in particular orders. They can launch tasks synchronously or asynchronously."),(0,o.kt)("p",null,"Ansible works against multiple systems in your infrastructure at the same time. It does this by selecting portions of systems listed in ",(0,o.kt)("a",{parentName:"p",href:"https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html"},"Ansible\u2019s inventory"),". You can check out ",(0,o.kt)("inlineCode",{parentName:"p"},"cd ~/openshift-ansible/inventory")," for some example files."),(0,o.kt)("p",null,"Based on those files we can create our first own ",(0,o.kt)("inlineCode",{parentName:"p"},"nano inventory.ini"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-ini"},"# OpenShift-Ansible host inventory\n\n# Create an OSEv3 group that contains the masters and nodes groups\n[OSEv3:children]\nmasters\nnodes\netcd\n\n\n# Set variables common for all OSEv3 hosts\n[OSEv3:vars]\nansible_ssh_user=root\nenable_excluders=False\nenable_docker_excluder=False\nopenshift_enable_service_catalog=False\nansible_service_broker_install=False\n\n# Debug level for all OpenShift components (Defaults to 2)\ndebug_level=2\n\ncontainerized=True\nos_sdn_network_plugin_name='redhat/openshift-ovs-multitenant'\nopenshift_disable_check=disk_availability,docker_storage,memory_availability,docker_image_availability\n\nopenshift_node_kubelet_args={'pods-per-core': ['10']}\n\ndeployment_type=origin\nopenshift_deployment_type=origin\n\nopenshift_release=v3.11.0\nopenshift_pkg_version=v3.11.0\nopenshift_image_tag=v3.11.0\nopenshift_service_catalog_image_version=v3.11.0\nopenshift_service_broker_image_version=v3.11.0\nosm_use_cockpit=true\n\n# Router on dedicated Infra Node\nopenshift_hosted_router_selector='region=infra'\nopenshift_master_default_subdomain=apps.test.instar.wiki\nopenshift_public_hostname=master.test.instar.wiki\n\n# Image Registry on dedicated Infra Node\nopenshift_hosted_registry_selector='region=infra'\n\n# htpasswd authentication with OSAdmin / dmlAjICyfrYXCsEH3NOoeeZMBkbo9G0JJy70z4etiO1dlCoo\nopenshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider', 'filename': '/etc/origin/master/htpasswd'}]\nopenshift_master_htpasswd_users={'OSAdmin': '$apr1$de7aZ7AQ$b0/L6hgDDskpuKekx/kfe.'}\n\n# Check http://www.htaccesstools.com/htpasswd-generator/\n\n[masters]\nin-centos-master openshift_ip=195.201.148.210 openshift_port=45454\n\n\n[etcd]\nin-centos-master openshift_ip=195.201.148.210 openshift_port=45454\n\n\n[nodes]\nin-centos-master openshift_ip=195.201.148.210 openshift_port=56721 openshift_schedulable=true\nin-centos-minion1 openshift_ip=116.203.51.18 openshift_schedulable=true openshift_node_labels='{'region': 'infra', 'zone': 'default'}'\nin-centos-minion2 openshift_ip=78.46.145.148 openshift_port=35745 openshift_schedulable=true openshift_node_labels='{'region': 'primary', 'zone': 'default'}'\n")),(0,o.kt)("p",null,"We can now use the Ansible Playbook command to check the prerequisites to deploy the OpenShift Cluster:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"ansible-playbook -i inventory/inventory.ini playbooks/prerequisites.yml\n")))}u.isMDXComponent=!0},66362:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/photo-875sdfgd_67456dfdj_o-73448288699040d408fe83b3a9fe2865.jpg"}}]);