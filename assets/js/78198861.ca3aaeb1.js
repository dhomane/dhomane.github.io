"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[55131],{3905:(e,a,t)=>{t.d(a,{Zo:()=>p,kt:()=>h});var n=t(67294);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function s(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);a&&(n=n.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?s(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):s(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function o(e,a){if(null==e)return{};var t,n,r=function(e,a){if(null==e)return{};var t,n,r={},s=Object.keys(e);for(n=0;n<s.length;n++)t=s[n],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)t=s[n],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var c=n.createContext({}),l=function(e){var a=n.useContext(c),t=a;return e&&(t="function"==typeof e?e(a):i(i({},a),e)),t},p=function(e){var a=l(e.components);return n.createElement(c.Provider,{value:a},e.children)},d={inlineCode:"code",wrapper:function(e){var a=e.children;return n.createElement(n.Fragment,{},a)}},u=n.forwardRef((function(e,a){var t=e.components,r=e.mdxType,s=e.originalType,c=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),u=l(t),h=r,m=u["".concat(c,".").concat(h)]||u[h]||d[h]||s;return t?n.createElement(m,i(i({ref:a},p),{},{components:t})):n.createElement(m,i({ref:a},p))}));function h(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var s=t.length,i=new Array(s);i[0]=u;var o={};for(var c in a)hasOwnProperty.call(a,c)&&(o[c]=a[c]);o.originalType=e,o.mdxType="string"==typeof e?e:r,i[1]=o;for(var l=2;l<s;l++)i[l]=t[l];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}u.displayName="MDXCreateElement"},56901:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>c,contentTitle:()=>i,default:()=>d,frontMatter:()=>s,metadata:()=>o,toc:()=>l});var n=t(87462),r=(t(67294),t(3905));const s={sidebar_position:7090,slug:"2022-02-02",title:"Performing an Elasticsearch v8 Upgrade",authors:"mpolinowski",tags:["LINUX","Elasticsearch"]},i=void 0,o={unversionedId:"DevOps/Elasticsearch/2022-02-02--elasticsearch-v8-upgrade/index",id:"DevOps/Elasticsearch/2022-02-02--elasticsearch-v8-upgrade/index",title:"Performing an Elasticsearch v8 Upgrade",description:"TST, Hong Kong",source:"@site/docs/DevOps/Elasticsearch/2022-02-02--elasticsearch-v8-upgrade/index.md",sourceDirName:"DevOps/Elasticsearch/2022-02-02--elasticsearch-v8-upgrade",slug:"/DevOps/Elasticsearch/2022-02-02--elasticsearch-v8-upgrade/2022-02-02",permalink:"/docs/DevOps/Elasticsearch/2022-02-02--elasticsearch-v8-upgrade/2022-02-02",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/DevOps/Elasticsearch/2022-02-02--elasticsearch-v8-upgrade/index.md",tags:[{label:"LINUX",permalink:"/docs/tags/linux"},{label:"Elasticsearch",permalink:"/docs/tags/elasticsearch"}],version:"current",sidebarPosition:7090,frontMatter:{sidebar_position:7090,slug:"2022-02-02",title:"Performing an Elasticsearch v8 Upgrade",authors:"mpolinowski",tags:["LINUX","Elasticsearch"]},sidebar:"tutorialSidebar",previous:{title:"Elasticsearch v8, Filebeat (Docker) and NGINX",permalink:"/docs/DevOps/Elasticsearch/2022-02-03--elasticsearch-v8-data-ingestion/2022-02-03"},next:{title:"Elastic Filebeat and NGINX Access Logs",permalink:"/docs/DevOps/Elasticsearch/2021-04-01-elastic-filebeats-for-nginx-logs/2021-04-01"}},c={},l=[{value:"Modifications",id:"modifications",level:2},{value:"Blind Dry Run",id:"blind-dry-run",level:2},{value:"Intermediate Version",id:"intermediate-version",level:3},{value:"Change the Kibana User",id:"change-the-kibana-user",level:3},{value:"Create Random User Logins",id:"create-random-user-logins",level:3},{value:"Replace Kibana User Login",id:"replace-kibana-user-login",level:3},{value:"Creating an Anonymous User",id:"creating-an-anonymous-user",level:2}],p={toc:l};function d(e){let{components:a,...s}=e;return(0,r.kt)("wrapper",(0,n.Z)({},p,s,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"TST, Hong Kong",src:t(2005).Z,width:"1500",height:"547"})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#modifications"},"Modifications")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#blind-dry-run"},"Blind Dry Run"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#intermediate-version"},"Intermediate Version")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#change-the-kibana-user"},"Change the Kibana User")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#create-random-user-logins"},"Create Random User Logins")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#replace-kibana-user-login"},"Replace Kibana User Login")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#creating-an-anonymous-user"},"Creating an Anonymous User"))),(0,r.kt)("p",null,"I want to upgrade a production instance of Elasticsearch / Kibana ",(0,r.kt)("strong",{parentName:"p"},"v7.16.3")," to ",(0,r.kt)("strong",{parentName:"p"},"v8.0.0"),". I am going to use the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/mpolinowski/docker-elk"},"docker-elk repository")," as a starting point and add a few little tweaks to it. I will commit the updated version to ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/mpolinowski/elk-server-compose"},"elk-server-compose"),"."),(0,r.kt)("h2",{id:"modifications"},"Modifications"),(0,r.kt)("p",null,"First, I am not going to use Logstash. The service is commented out. If you need to configure Logstash please refer to ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/deviantony/docker-elk#configuration"},"here"),"."),(0,r.kt)("p",null,"Open Elasticsearch for a ",(0,r.kt)("strong",{parentName:"p"},"read-only, anonymous search agent")," and set ",(0,r.kt)("strong",{parentName:"p"},"CORS")," to allow everything and ",(0,r.kt)("strong",{parentName:"p"},"deactivate the paid XPACK features"),":"),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"elasticsearch/config/elasticsearch.yml")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml"},'# xpack.license.self_generated.type: trial\nxpack.license.self_generated.type: basic\nxpack.security.enabled: true\nxpack.monitoring.collection.enabled: true\nxpack.security.authc:\n    anonymous:\n      username: anonymous_user \n      roles: search_agent\n      authz_exception: true \n\n\n## CORS\nhttp.cors.enabled : true\nhttp.cors.allow-origin: "*"\nhttp.cors.allow-methods: OPTIONS, HEAD, GET, POST, PUT, DELETE\nhttp.cors.allow-credentials: true\nhttp.cors.allow-headers: X-Requested-With, X-Auth-Token, Content-Type, Content-Length, Authorization, Access-Control-Allow-Headers, Accept\n')),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Explanation"),": My Elasticsearch instance provides full-text search that is accessed from a variety of clients. I do not want those clients to have to use a user authentication to access the API. And since the request will not only come from a single URL I cannot use CORS to limit access - no matter where the request is coming from the API has to be available. To secure the database I will have to add the ",(0,r.kt)("strong",{parentName:"p"},"search","_","agent")," role in Kibana, once the instance is up and running. Users using this role will only have read access to selected indexes."),(0,r.kt)("h2",{id:"blind-dry-run"},"Blind Dry Run"),(0,r.kt)("p",null,"Clone the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/mpolinowski/docker-elk"},"docker-elk repository")," to a test server and change the ",(0,r.kt)("inlineCode",{parentName:"p"},"ELK_VERSION=7.16.3")," variable in ",(0,r.kt)("inlineCode",{parentName:"p"},".env")," to ",(0,r.kt)("inlineCode",{parentName:"p"},"ELK_VERSION=8.0.0")," and see what happens :)"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker-compose build\ndocker-compose up\n")),(0,r.kt)("p",null,"The instance is coming up but Elasticsearch is exiting complaining that it needs to be updated to version ",(0,r.kt)("strong",{parentName:"p"},"7.17.0")," before you can go to version ",(0,r.kt)("strong",{parentName:"p"},"8.0.0"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"elasticsearch_1  | java.lang.IllegalStateException: cannot upgrade a node from version [7.16.3] directly to version [8.0.0], upgrade to version [7.17.0] first.\nelasticsearch_1  |      at org.elasticsearch.env.NodeMetadata.verifyUpgradeToCurrentVersion(NodeMetadata.java:122)\nelasticsearch_1  |      at org.elasticsearch.env.NodeEnvironment.checkForIndexCompatibility(NodeEnvironment.java:500)\nelasticsearch_1  |      at org.elasticsearch.env.NodeEnvironment.upgradeLegacyNodeFolders(NodeEnvironment.java:397)\nelasticsearch_1  |      at org.elasticsearch.env.NodeEnvironment.<init>(NodeEnvironment.java:290)\nelasticsearch_1  |      at org.elasticsearch.node.Node.<init>(Node.java:388)\nelasticsearch_1  |      at org.elasticsearch.node.Node.<init>(Node.java:277)\nelasticsearch_1  |      at org.elasticsearch.bootstrap.Bootstrap$5.<init>(Bootstrap.java:234)\nelasticsearch_1  |      at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:234)\nelasticsearch_1  |      at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:358)\nelasticsearch_1  |      at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:166)\nelasticsearch_1  |      at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:157)\nelasticsearch_1  |      at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:77)\nelasticsearch_1  |      at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:112)\nelasticsearch_1  |      at org.elasticsearch.cli.Command.main(Command.java:77)\nelasticsearch_1  |      at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:122)\nelasticsearch_1  |      at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:80)\nelasticsearch_1  | For complete error details, refer to the log at /usr/share/elasticsearch/logs/docker-cluster.lo\nwiki_elk-master_elasticsearch_1 exited with code 1\n")),(0,r.kt)("h3",{id:"intermediate-version"},"Intermediate Version"),(0,r.kt)("p",null,"So let's change the version to ",(0,r.kt)("inlineCode",{parentName:"p"},"ELK_VERSION=7.17.0")," and re-run:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker-compose build\ndocker-compose up\n")),(0,r.kt)("p",null,"Everything is working as expected. I am able to create an index. Now I want to see if I can bring this index into ESv8 without breaking anything. So let's change the version back to ",(0,r.kt)("inlineCode",{parentName:"p"},"ELK_VERSION=8.0.0")," and re-run:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker-compose build\ndocker-compose up\n")),(0,r.kt)("p",null,"The instance is coming up again and Elasticsearch is no longer complaining. But I have a new error from Kibana. With version 8 I am no longer allowed to use the default Elasticsearch admin account to connect Kibana to Elasticsearch:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'kibana_1         | [2022-02-12T13:46:59.393+00:00][FATAL][root] Error: [config validation of [elasticsearch].username]: value of "elastic" is forbidden. This is a superuser account that cannot write to system indices that Kibana needs to function. Use a service account token instead. Learn more: https://www.elastic.co/guide/en/elasticsearch/reference/8.0/service-accounts.html\nkibana_1         | [2022-02-12T13:47:28.906+00:00][FATAL][root] Error: [config validation of [elasticsearch].username]: value of "elastic" is forbidden. This is a superuser account that cannot write to system indices that Kibana needs to function. Use a service account token instead. Learn more: https://www.elastic.co/guide/en/elasticsearch/reference/8.0/service-accounts.html\nkibana_1         |     at ensureValidConfiguration (/usr/share/kibana/src/core/server/config/ensure_valid_configuration.js:25:11)\nkibana_1         |     at Server.preboot (/usr/share/kibana/src/core/server/server.js:160:5)\nkibana_1         |     at Root.preboot (/usr/share/kibana/src/core/server/root/index.js:48:14)\nkibana_1         |     at bootstrap (/usr/share/kibana/src/core/server/bootstrap.js:99:9)\nkibana_1         |     at Command.<anonymous> (/usr/share/kibana/src/cli/serve/serve.js:216:5)\nkibana_1         |\nkibana_1         |  FATAL  Error: [config validation of [elasticsearch].username]: value of "elastic" is forbidden. This is a superuser account that cannot write to system indices that Kibana needs to function. Use a service account token instead. Learn more: https://www.elastic.co/guide/en/elasticsearch/reference/8.0/service-accounts.html\nwiki_elk-master_kibana_1 exited with code 78\n')),(0,r.kt)("h3",{id:"change-the-kibana-user"},"Change the Kibana User"),(0,r.kt)("p",null,"When we are starting the stack for the very first time, we now ",(0,r.kt)("strong",{parentName:"p"},"MUST")," initialize a password for the built-in ",(0,r.kt)("a",{parentName:"p",href:"https://www.elastic.co/guide/en/elasticsearch/reference/current/built-in-users.html"},"kibana_system user")," to be able to start and access Kibana. First I need to change the user Kibana is configured to use:"),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"kibana/config/kibana.yml")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml"},"## X-Pack security credentials\n#\nelasticsearch.username: elastic\nelasticsearch.password: 'changeme'\n")),(0,r.kt)("p",null,"Change the ",(0,r.kt)("inlineCode",{parentName:"p"},"elastic")," user to ",(0,r.kt)("inlineCode",{parentName:"p"},"kibana_system"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml"},"## X-Pack security credentials\n#\nelasticsearch.username: kibana_system\nelasticsearch.password: 'changeme'\n")),(0,r.kt)("p",null,"Bringing the cluster back up with ",(0,r.kt)("inlineCode",{parentName:"p"},"docker-compose up")," I can now see that the Error disappeared and was replaced by a warning that the Kibana instances tried to connect but failed:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'elasticsearch    | {"@timestamp":"2022-02-13T08:12:05.668Z", "log.level": "INFO", "message":"Authentication of [kibana_system] was terminated by realm [reserved] - failed to authenticate user [kibana_system]", "ecs.version": "1.2.0","service.name":"ES_ECS","event.dataset":"elasticsearch.server","process.thread.name":"elasticsearch[63d89c8e892b][system_critical_read][T#1]","log.logger":"org.elasticsearch.xpack.security.authc.RealmsAuthenticator","elasticsearch.cluster.uuid":"6rdcLQTFRmWdJlOQasPOHA","elasticsearch.node.id":"2ybJ-D0PRvOHkklDputWqQ","elasticsearch.node.name":"63d89c8e892b","elasticsearch.cluster.name":"docker-cluster"}\n')),(0,r.kt)("h3",{id:"create-random-user-logins"},"Create Random User Logins"),(0,r.kt)("p",null,"Now I can connect to the running Elasticsearch container and generate random passwords for both the ",(0,r.kt)("inlineCode",{parentName:"p"},"elastic")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"kibana_system")," user - ",(0,r.kt)("strong",{parentName:"p"},"Copy those passwords and store them somewhere save"),"!"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker-compose exec -T elasticsearch bin/elasticsearch-reset-password --batch --user elastic\n\nWARNING: Owner of file [/usr/share/elasticsearch/config/users] used to be [root], but now is [elasticsearch]\nWARNING: Owner of file [/usr/share/elasticsearch/config/users_roles] used to be [root], but now is [elasticsearch]\nPassword for the [elastic] user successfully reset.\nNew value: a1hyme+ry1-AltBfpqxY\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker-compose exec -T elasticsearch bin/elasticsearch-reset-password --batch --user kibana_system\n\nPassword for the [kibana_system] user successfully reset.\nNew value: Fug1bNAI3XJW7UWA5Ahm\n")),(0,r.kt)("h3",{id:"replace-kibana-user-login"},"Replace Kibana User Login"),(0,r.kt)("p",null,"Replace the password of the ",(0,r.kt)("inlineCode",{parentName:"p"},"kibana_system")," user inside the Kibana configuration file with the password generated in the previous step:"),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"kibana/config/kibana.yml")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml"},"elasticsearch.username: kibana_system\nelasticsearch.password: 'Fug1bNAI3XJW7UWA5Ahm'\n")),(0,r.kt)("p",null,"And change the ",(0,r.kt)("strong",{parentName:"p"},"ELASTIC_PASSWORD")," environment variable from the elasticsearch service inside the Compose file ",(0,r.kt)("inlineCode",{parentName:"p"},"docker-compose.yml"),". But it is only used to initialize the keystore during the initial startup of Elasticsearch, and is ignored on subsequent runs:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yml"},"ELASTIC_PASSWORD: 'a1hyme+ry1-AltBfpqxY'\n")),(0,r.kt)("p",null,"And for another try:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker-compose up\n")),(0,r.kt)("p",null,"A long and exciting log-scroll later I finally read:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kibana           | [2022-02-13T08:19:21.592+00:00][INFO ][plugins.fleet] Fleet setup completed\nkibana           | [2022-02-13T08:19:21.598+00:00][INFO ][plugins.securitySolution] Dependent plugin setup complete - Starting ManifestTask\n")),(0,r.kt)("p",null,"And I am able to access the Kibana web frontend on port ",(0,r.kt)("inlineCode",{parentName:"p"},"5601")," - use the ",(0,r.kt)("inlineCode",{parentName:"p"},"elastic")," user combined with the generated login. In my case this was ",(0,r.kt)("inlineCode",{parentName:"p"},"a1hyme+ry1-AltBfpqxY"),":"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Elastic Stack v8",src:t(42808).Z,width:"1050",height:"471"})),(0,r.kt)("p",null,"And to my delight my index was successfully ported to version 8:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Elastic Stack v8",src:t(38472).Z,width:"1050",height:"417"})),(0,r.kt)("h2",{id:"creating-an-anonymous-user"},"Creating an Anonymous User"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Elastic Stack v8",src:t(74910).Z,width:"1036",height:"235"})),(0,r.kt)("p",null,"Here I can add the user role ",(0,r.kt)("a",{parentName:"p",href:"#modifications"},"search_agent user role")," that I added to the ",(0,r.kt)("inlineCode",{parentName:"p"},"elasticsearch.yml")," and enable the read access to my index:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Elastic Stack v8",src:t(22401).Z,width:"1038",height:"833"})),(0,r.kt)("p",null,"I can try accessing the cluster using ",(0,r.kt)("strong",{parentName:"p"},"CURL"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'curl -XGET \'http://192.168.2.111:9200/wiki_index/_search?pretty=true&q=9020+Full+HD\'\n{\n  "took" : 34,\n  "timed_out" : false,\n  "_shards" : {\n    "total" : 1,\n    "successful" : 1,\n    "skipped" : 0,\n    "failed" : 0\n  },\n  "hits" : {\n    "total" : {\n      "value" : 398,\n      "relation" : "eq"\n    },\n    "max_score" : 12.786632,\n    "hits" : [ ... ]\n')),(0,r.kt)("p",null,"Success!"))}d.isMDXComponent=!0},42808:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/Elastic_Stack_v8_01-9aac6a436c9a85406e0d2cd2086b3285.png"},38472:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/Elastic_Stack_v8_02-cee61677ef30686abe2e3918f79ed0ff.png"},74910:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/Elastic_Stack_v8_03-0dbd9b09c4f5e581ae741a185d879f20.png"},22401:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/Elastic_Stack_v8_04-6c8d88c68b22b4ed83d70940a3fc6296.png"},2005:(e,a,t)=>{t.d(a,{Z:()=>n});const n=t.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-5124c74efbbadd90a9fcfa6be641f69c.jpg"}}]);