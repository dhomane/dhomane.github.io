"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[62163],{3905:(e,n,a)=>{a.d(n,{Zo:()=>d,kt:()=>p});var t=a(67294);function i(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function r(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function A(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?r(Object(a),!0).forEach((function(n){i(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function o(e,n){if(null==e)return{};var a,t,i=function(e,n){if(null==e)return{};var a,t,i={},r=Object.keys(e);for(t=0;t<r.length;t++)a=r[t],n.indexOf(a)>=0||(i[a]=e[a]);return i}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(t=0;t<r.length;t++)a=r[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=t.createContext({}),l=function(e){var n=t.useContext(s),a=n;return e&&(a="function"==typeof e?e(n):A(A({},n),e)),a},d=function(e){var n=l(e.components);return t.createElement(s.Provider,{value:n},e.children)},m={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},g=t.forwardRef((function(e,n){var a=e.components,i=e.mdxType,r=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),g=l(a),p=i,c=g["".concat(s,".").concat(p)]||g[p]||m[p]||r;return a?t.createElement(c,A(A({ref:n},d),{},{components:a})):t.createElement(c,A({ref:n},d))}));function p(e,n){var a=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var r=a.length,A=new Array(r);A[0]=g;var o={};for(var s in n)hasOwnProperty.call(n,s)&&(o[s]=n[s]);o.originalType=e,o.mdxType="string"==typeof e?e:i,A[1]=o;for(var l=2;l<r;l++)A[l]=a[l];return t.createElement.apply(null,A)}return t.createElement.apply(null,a)}g.displayName="MDXCreateElement"},83381:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>s,contentTitle:()=>A,default:()=>m,frontMatter:()=>r,metadata:()=>o,toc:()=>l});var t=a(87462),i=(a(67294),a(3905));const r={sidebar_position:4850,slug:"2022-12-28",title:"Deep Convolutional Generative Adversarial Network",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Use Adversarial Networks to generate Images"},A=void 0,o={unversionedId:"IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator/index",id:"IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator/index",title:"Deep Convolutional Generative Adversarial Network",description:"Use Adversarial Networks to generate Images",source:"@site/docs/IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator",slug:"/IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator/2022-12-28",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator/2022-12-28",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Tensorflow",permalink:"/docs/tags/tensorflow"}],version:"current",sidebarPosition:4850,frontMatter:{sidebar_position:4850,slug:"2022-12-28",title:"Deep Convolutional Generative Adversarial Network",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Use Adversarial Networks to generate Images"},sidebar:"tutorialSidebar",previous:{title:"Recurrent Neural Networks",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-31-tf-rnn-text-generation/2022-12-31"},next:{title:"Tensorflow Downsampling",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/2022-12-21"}},s={},l=[{value:"Training Dataset",id:"training-dataset",level:2},{value:"Building the Generator",id:"building-the-generator",level:2},{value:"Building the Discriminator",id:"building-the-discriminator",level:2},{value:"Loss Function",id:"loss-function",level:2},{value:"Model Training",id:"model-training",level:2}],d={toc:l};function m(e){let{components:n,...r}=e;return(0,i.kt)("wrapper",(0,t.Z)({},d,r,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Guangzhou, China",src:a(92942).Z,width:"1500",height:"662"})),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#training-dataset"},"Training Dataset")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#building-the-generator"},"Building the Generator")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#building-the-discriminator"},"Building the Discriminator")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#loss-function"},"Loss Function")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"#model-training"},"Model Training"))),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://www.tensorflow.org/tutorials/generative/dcgan"},"Generative Adversarial Networks")," (GANs) are one of the most interesting ideas in computer science today. Two models are trained simultaneously by an adversarial process. A ",(0,i.kt)("strong",{parentName:"p"},"Generator"),' ("the artist") learns to create images that look real, while a ',(0,i.kt)("strong",{parentName:"p"},"Discriminator"),' ("the art critic") learns to tell real images apart from fakes.'),(0,i.kt)("p",null,"During training, the generator progressively becomes better at creating images that look real, while the discriminator becomes better at telling them apart. The process reaches equilibrium when the discriminator can no longer distinguish real images from fakes."),(0,i.kt)("h2",{id:"training-dataset"},"Training Dataset"),(0,i.kt)("p",null,"To train the discriminator I am going to use the ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/zalandoresearch/fashion-mnist"},"Fashion mnist dataset")," provided by Keras:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"# configuration\nBUFFER_SIZE = 60000\nBATCH_SIZE = 256\nEPOCHS = 100\nnoise_dim = 100\nnum_examples_to_generate = 16\nseed = tf.random.normal([num_examples_to_generate, noise_dim])\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-4)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n\n\n# import keras fashion mnist fashion dataset (60000 labeled images 28x28)\n(train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n## preprocess images\n# print(rain_images.shape[0])\n## 60000\ntrain_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\ntrain_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]\n## batch / shuffle images\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n")),(0,i.kt)("p",null,"Fashion-MNIST is a dataset of Zalando's article images\u2014consisting of a training set of ",(0,i.kt)("inlineCode",{parentName:"p"},"60,000")," examples. Each example is a ",(0,i.kt)("inlineCode",{parentName:"p"},"28"),"x",(0,i.kt)("inlineCode",{parentName:"p"},"28")," grayscale image, associated with a label from ",(0,i.kt)("inlineCode",{parentName:"p"},"10")," classes:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"# visualize dataset\nplt.imshow(train_images[59999].reshape((28,28)) , cmap = 'gray')\nplt.show()\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Tensorflow Transfer Learning",src:a(62574).Z,width:"640",height:"480"})),(0,i.kt)("h2",{id:"building-the-generator"},"Building the Generator"),(0,i.kt)("p",null,"The Discriminator expects an image as provided by the Fashion mnist dataset - grayscale and with the dimensions 28px times 28px. We can mow build a generator function that based from a random noise seed can generate an image like that:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"# build image generator\n## the generator should take noise and transform it\n## into something the discriminator accepts as a true image\n\ndef make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((7, 7, 256)))\n\n    # Because we used \"same\" padding and stride = 1, the output is the same size as input 7 x 7 but with 128 filters instead\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)) \n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    # Because we used \"same\" padding and stride = 2, the output is double the size of the input 14 x 14 but with 64 filters instead\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    # Because we used \"same\" padding and stride = 2, the output is double the size of the input 28 x 28 but with 1 filter instead\n    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n    model.summary()\n\n    return model\n\ngenerator = make_generator_model()\n")),(0,i.kt)("p",null,"The final layer outputs an image representation with the dimensions ",(0,i.kt)("inlineCode",{parentName:"p"},"(None, 28, 28, 1)"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'Model: "sequential"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 12544)             1254400   \n                                                                 \n batch_normalization (BatchN  (None, 12544)            50176     \n ormalization)                                                   \n                                                                 \n leaky_re_lu (LeakyReLU)     (None, 12544)             0         \n                                                                 \n reshape (Reshape)           (None, 7, 7, 256)         0         \n                                                                 \n conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        819200    \n nspose)                                                         \n                                                                 \n batch_normalization_1 (Batc  (None, 7, 7, 128)        512       \n hNormalization)                                                 \n                                                                 \n leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 128)         0         \n                                                                 \n conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       204800    \n ranspose)                                                       \n                                                                 \n batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n hNormalization)                                                 \n                                                                 \n leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 64)        0         \n                                                                 \n conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1600      \n ranspose)                                                       \n                                                                 \n=================================================================\nTotal params: 2,330,944\nTrainable params: 2,305,472\nNon-trainable params: 25,472\n_________________________________________________________________\n')),(0,i.kt)("p",null,"Since we are not yet providing any training the entire function will just take any noise and upscale it to our image dimensions:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"# run the generator with a random noise seed\nnoise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training=False)\nprint(generated_image.shape)\nplt.imshow(generated_image[0,:,:,0], cmap='gray')\nplt.show()\n")),(0,i.kt)("p",null,"The generated image shape is ",(0,i.kt)("inlineCode",{parentName:"p"},"(1, 28, 28, 1)")," and is represented by:"),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Tensorflow Transfer Learning",src:a(76007).Z,width:"640",height:"480"})),(0,i.kt)("h2",{id:"building-the-discriminator"},"Building the Discriminator"),(0,i.kt)("p",null,"Now that we have our generator - that takes in noise and transforms them into whatever we want to train him to do - we can now build the discriminator - who's task it is going to be to evaluate those generated images (or data in general):"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"# build image discriminator\ndef make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    ## the input image is reduced to a single output\n    ## yes/no - how close is this image to a true image\n    model.add(layers.Dense(1))\n    model.summary()\n\n    return model\n\ndiscriminator = make_discriminator_model()\n")),(0,i.kt)("p",null,"Now we can take the generated image from before and let the - yet to be trained - discriminator decide if it is a real image or not:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},'## feed random seed generated image to discriminator\n## the model will have to be trained to output\n## positive => real images / negative => detected false\ndecision = discriminator(generated_image)\nprint ("Decision: ", decision)\n')),(0,i.kt)("p",null,"Currently, the output is not yet that helpful. The discriminator decided that the noisy input is ",(0,i.kt)("inlineCode",{parentName:"p"},"0.00307573")," - which means nothing. yet:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"Decision:  tf.Tensor([[0.00307573]], shape=(1, 1), dtype=float32)\n")),(0,i.kt)("h2",{id:"loss-function"},"Loss Function"),(0,i.kt)("p",null,"To be able to give feedback on the performance of the prediction model we need a numeric representation of it. For the discriminator training we can compare it's prediction to ",(0,i.kt)("inlineCode",{parentName:"p"},"1")," when the input image was a true image from our training dataset and compare it to ",(0,i.kt)("inlineCode",{parentName:"p"},"0")," for fake, generated images:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"# define loss function that calculates the difference\n# between a model prediction and the the true label\ncross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\n## discriminator loss compares predictions on true images to an array of 1s\n## and predictions on generated images to an array of 0s.\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss # sum up both losses\n    return total_loss\n")),(0,i.kt)("p",null,"During the training Tensorflow will try to minimize this loss - the deviation from the expected value. So that every true image will result in a value close to ",(0,i.kt)("inlineCode",{parentName:"p"},"1")," and every fake one will end up with ",(0,i.kt)("inlineCode",{parentName:"p"},"0"),"."),(0,i.kt)("p",null,"So with the discriminator training set we now need to quantify the generator performance. Here the optimum performance is reached when the discriminator judges the generated image to be a true image and assigns it a value close to ",(0,i.kt)("inlineCode",{parentName:"p"},"1"),":"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"## generator loss is low when it's output is judged as a `1` by the discriminator\ndef generator_loss(fake_output):\n    gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n    return gen_loss\n")),(0,i.kt)("h2",{id:"model-training"},"Model Training"),(0,i.kt)("p",null,"Before running the training we can define ",(0,i.kt)("strong",{parentName:"p"},"Checkpoints")," that allow us to use the weights generated by an earlier training:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"checkpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)\n")),(0,i.kt)("p",null,"Now we can take both the discriminator and generator and train them to minimize their respective loss functions. The training steps are defined as:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"## training steps\n@tf.function\ndef train_step(images):\n    ## generate random noise as generator input\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n      ## call the generator and feed in the noise seed\n      generated_images = generator(noise, training=True)\n      ## pass the true images to discriminator to perform classification\n      real_output = discriminator(images, training=True)\n      ## pass the generated images to discriminator to perform classification\n      fake_output = discriminator(generated_images, training=True)\n      ## generator loss function\n      gen_loss = generator_loss(fake_output)\n      ## discriminator loss function\n      disc_loss = discriminator_loss(real_output, fake_output)\n\n    ## calculate the gradient of the losses\n    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n    ## apply the optimizers and update weights\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) \n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n")),(0,i.kt)("p",null,"Those steps will be handled by the training function:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"## training function\ndef train(dataset, epochs):\n  for epoch in range(epochs):\n    start = time.time()\n\n    for image_batch in dataset:\n      train_step(image_batch)\n\n    ## save images that are being generated\n    display.clear_output(wait=True)\n    generate_and_save_images(generator,\n                             epoch + 1,\n                             seed)\n\n    ## create checkpoint every 15 epochs\n    if (epoch + 1) % 15 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n\n    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n  ## generate after the final epoch\n  display.clear_output(wait=True)\n  generate_and_save_images(generator,\n                           epochs,\n                           seed)\n")),(0,i.kt)("p",null,"The training function will display the generated images  after each epoch and allows us to follow the progress of the training:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-py"},"## create visual representation of generated images over epochs\ndef generate_and_save_images(model, epoch, test_input):\n  predictions = model(test_input, training=False)\n\n  fig = plt.figure(figsize=(4,4))\n\n  for i in range(predictions.shape[0]):\n      plt.subplot(4, 4, i+1)\n      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n      plt.axis('off')\n\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n  # plt.show()\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Tensorflow Transfer Learning",src:a(86580).Z,width:"400",height:"400"})))}m.isMDXComponent=!0},62574:(e,n,a)=>{a.d(n,{Z:()=>t});const t="data:image/png;base64,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"},76007:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/Tensorflow_Transfer_Learning_02-040d0c721709afd4b5d75eab81f890c9.png"},92942:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-296769d73822f07b0ac5dc952f56bfa1.jpg"},86580:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/timelapse-c8ceb2801f0787167cbcd0e2be622279.gif"}}]);