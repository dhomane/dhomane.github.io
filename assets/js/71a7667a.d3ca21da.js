"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[31528],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>m});var a=t(67294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var d=a.createContext({}),l=function(e){var n=a.useContext(d),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},c=function(e){var n=l(e.components);return a.createElement(d.Provider,{value:n},e.children)},p={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,o=e.originalType,d=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),u=l(t),m=r,g=u["".concat(d,".").concat(m)]||u[m]||p[m]||o;return t?a.createElement(g,i(i({ref:n},c),{},{components:t})):a.createElement(g,i({ref:n},c))}));function m(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=t.length,i=new Array(o);i[0]=u;var s={};for(var d in n)hasOwnProperty.call(n,d)&&(s[d]=n[d]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var l=2;l<o;l++)i[l]=t[l];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},51165:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>i,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var a=t(87462),r=(t(67294),t(3905));const o={sidebar_position:4860,slug:"2022-12-21",title:"Tensorflow Downsampling",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Using Representation Learning to Downsample Images"},i=void 0,s={unversionedId:"IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/index",id:"IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/index",title:"Tensorflow Downsampling",description:"Using Representation Learning to Downsample Images",source:"@site/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling",slug:"/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/2022-12-21",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/2022-12-21",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Tensorflow",permalink:"/docs/tags/tensorflow"}],version:"current",sidebarPosition:4860,frontMatter:{sidebar_position:4860,slug:"2022-12-21",title:"Tensorflow Downsampling",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Using Representation Learning to Downsample Images"},sidebar:"tutorialSidebar",previous:{title:"Deep Convolutional Generative Adversarial Network",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator/2022-12-28"},next:{title:"Tensorflow Deep Dream",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-deepdream/2022-12-21"}},d={},l=[{value:"Build the Autoencoder",id:"build-the-autoencoder",level:2},{value:"Train the Autoencoder",id:"train-the-autoencoder",level:2},{value:"Evaluation",id:"evaluation",level:2}],c={toc:l};function p(e){let{components:n,...o}=e;return(0,r.kt)("wrapper",(0,a.Z)({},c,o,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Guangzhou, China",src:t(91382).Z,width:"1500",height:"383"})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#build-the-autoencoder"},"Build the Autoencoder")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#train-the-autoencoder"},"Train the Autoencoder")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#evaluation"},"Evaluation"))),(0,r.kt)("p",null,"Using ",(0,r.kt)("a",{parentName:"p",href:"/docs/IoT-and-Machine-Learning/ML/2022-12-20-tf-representation/2022-12-19"},"Representation Learning")," to downsample images."),(0,r.kt)("h2",{id:"build-the-autoencoder"},"Build the Autoencoder"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},'# build autoencoder model\nautoencoder = tf.keras.models.Sequential()\n\n# build the encoder CNN\nautoencoder.add(tf.keras.layers.Conv2D(64, (3,3), strides=1, padding="same", input_shape=(32, 32, 3)))\nautoencoder.add(tf.keras.layers.BatchNormalization())\nautoencoder.add(tf.keras.layers.Activation(\'relu\'))\nautoencoder.add(tf.keras.layers.AveragePooling2D((2,2), padding="same"))\n\nautoencoder.add(tf.keras.layers.Conv2D(32, (3,3), strides=1, padding="same"))\nautoencoder.add(tf.keras.layers.BatchNormalization())\nautoencoder.add(tf.keras.layers.Activation(\'relu\'))\n\n# representation layer\nautoencoder.add(tf.keras.layers.AveragePooling2D((2,2), padding="same"))\n\n# build the decoder CNN \nautoencoder.add(tf.keras.layers.BatchNormalization())\nautoencoder.add(tf.keras.layers.Activation(\'relu\'))\nautoencoder.add(tf.keras.layers.UpSampling2D((2, 2)))\n\nautoencoder.add(tf.keras.layers.Conv2D(64, (3,3), strides=1, padding="same"))\nautoencoder.add(tf.keras.layers.BatchNormalization())\nautoencoder.add(tf.keras.layers.Activation(\'relu\'))\nautoencoder.add(tf.keras.layers.UpSampling2D((2, 2)))\n\nautoencoder.add(tf.keras.layers.Conv2D(3, (3,3), strides=1, activation=\'sigmoid\', padding="same"))\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"# compile model\nautoencoder.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.01))\nautoencoder.summary()\n")),(0,r.kt)("h2",{id:"train-the-autoencoder"},"Train the Autoencoder"),(0,r.kt)("p",null,"Before I used ",(0,r.kt)("a",{parentName:"p",href:"/docs/IoT-and-Machine-Learning/ML/2022-12-20-tf-representation/2022-12-19"},"Representation Learning to remove digital noise from image files"),". There we needed to compare the generated image from our CNN layers with a noise-free version of the image as a performance metric. For downsampling we need to compare the de-compressed image to the original image - the model first compresses features (encoding) and then de-compresses them (decoding) to try to match the original input:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"# fit model to dataset\nautoencoder.fit(X_train,          \n          X_train, \n          epochs=20, \n          batch_size=200, \n          validation_data=(X_test, X_test))\n")),(0,r.kt)("h2",{id:"evaluation"},"Evaluation"),(0,r.kt)("p",null,"And we end up with a lightly compressed version of the input images:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"# test training\n# take 15 images from test set and predict compressed image\npredicted = autoencoder.predict(X_test[:10].reshape(-1, 32, 32, 3))\n# plot input vs output\nfig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\nfor images, row in zip([X_test[:10], predicted], axes):\n    for img, ax in zip(images, row):\n        ax.imshow(img.reshape((32, 32, 3)))\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\nplt.show()\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow Transfer Learning",src:t(21065).Z,width:"1573",height:"319"})))}p.isMDXComponent=!0},21065:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/Tensorflow_Transfer_Learning_01-bcedf01b351e75791b7d551b984abefd.png"},91382:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-918471126c0472aad97358a725e1a399.jpg"}}]);