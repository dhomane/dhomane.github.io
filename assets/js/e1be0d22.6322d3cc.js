"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[19073],{3905:(e,t,n)=>{n.d(t,{Zo:()=>s,kt:()=>u});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},s=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},k=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,s=c(e,["components","mdxType","originalType","parentName"]),k=p(n),u=r,g=k["".concat(l,".").concat(u)]||k[u]||d[u]||i;return n?a.createElement(g,o(o({ref:t},s),{},{components:n})):a.createElement(g,o({ref:t},s))}));function u(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=k;var c={};for(var l in t)hasOwnProperty.call(t,l)&&(c[l]=t[l]);c.originalType=e,c.mdxType="string"==typeof e?e:r,o[1]=c;for(var p=2;p<i;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}k.displayName="MDXCreateElement"},2266:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>c,toc:()=>p});var a=n(87462),r=(n(67294),n(3905));const i={sidebar_position:6070,slug:"2021-12-06",title:"OpenCV Object Tracking",authors:"mpolinowski",tags:["Machine Learning","Python","OpenCV"]},o=void 0,c={unversionedId:"IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking/index",id:"IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking/index",title:"OpenCV Object Tracking",description:"Shenzhen, China",source:"@site/docs/IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking",slug:"/IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking/2021-12-06",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking/2021-12-06",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking/index.md",tags:[{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Python",permalink:"/docs/tags/python"},{label:"OpenCV",permalink:"/docs/tags/open-cv"}],version:"current",sidebarPosition:6070,frontMatter:{sidebar_position:6070,slug:"2021-12-06",title:"OpenCV Object Tracking",authors:"mpolinowski",tags:["Machine Learning","Python","OpenCV"]},sidebar:"tutorialSidebar",previous:{title:"OpenCV Object Detection and Tracking",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-12-07--opencv-detection-and-tracking/2021-12-07"},next:{title:"OpenCV Face Detection and Privacy",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-12-05--opencv-face-detection/2021-12-05"}},l={},p=[{value:"Setting up OpenCV",id:"setting-up-opencv",level:2},{value:"Single Track",id:"single-track",level:2},{value:"Select Tracking Algorithm",id:"select-tracking-algorithm",level:3},{value:"BOOSTING vs KCF",id:"boosting-vs-kcf",level:4},{value:"MOSSE vs CSRT",id:"mosse-vs-csrt",level:4},{value:"Load Video File",id:"load-video-file",level:3},{value:"Select Object to Track",id:"select-object-to-track",level:3},{value:"Track the Object",id:"track-the-object",level:3},{value:"Record the Output Video",id:"record-the-output-video",level:3},{value:"User Input by Arguments",id:"user-input-by-arguments",level:3},{value:"Multitrack and GOTURN",id:"multitrack-and-goturn",level:2}],s={toc:p};function d(e){let{components:t,...i}=e;return(0,r.kt)("wrapper",(0,a.Z)({},s,i,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Shenzhen, China",src:n(26016).Z,width:"2385",height:"919"})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#setting-up-opencv"},"Setting up OpenCV")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#single-track"},"Single Track"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#select-tracking-algorithm"},"Select Tracking Algorithm"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#boosting-vs-kcf"},"BOOSTING vs KCF")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#mosse-vs-csrt"},"MOSSE vs CSRT")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#load-video-file"},"Load Video File")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#select-object-to-track"},"Select Object to Track")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#track-the-object"},"Track the Object")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#record-the-output-video"},"Record the Output Video")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#user-input-by-arguments"},"User Input by Arguments")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#multitrack-and-goturn"},"Multitrack and GOTURN"))),(0,r.kt)("p",null,"Tracking Objects in videos with OpenCV - see also ",(0,r.kt)("a",{parentName:"p",href:"https://www.pyimagesearch.com/2018/07/30/opencv-object-tracking/"},"pyimagesearch"),". And on ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/mpolinowski/opencv-object-tracking"},"Github"),"."),(0,r.kt)("h2",{id:"setting-up-opencv"},"Setting up OpenCV"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"python -m venv .env\nsource .env/bin/activate\npython -m pip install --upgrade pip\n")),(0,r.kt)("p",null,"Add a file ",(0,r.kt)("inlineCode",{parentName:"p"},"dependencies.txt")," with all project ",(0,r.kt)("strong",{parentName:"p"},"pip dependencies"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"opencv-python\nopencv-contrib-python\n")),(0,r.kt)("p",null,"Install all dependencies with:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pip install -r dependencies.txt\n")),(0,r.kt)("p",null,"Test installation of OpenCV by running the following Python script:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import cv2\nprint(cv2.__version__)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"python scripts/main.py\n4.5.5\n")),(0,r.kt)("h2",{id:"single-track"},"Single Track"),(0,r.kt)("h3",{id:"select-tracking-algorithm"},"Select Tracking Algorithm"),(0,r.kt)("p",null,"OpenCV includes 7 separate legacy object tracking implementations:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"BOOSTING Tracker"),": Based on the same algorithm used by Haar cascades (AdaBoost). Slow and doesn\u2019t work very well."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"MIL Tracker"),": Better accuracy than BOOSTING tracker."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"KCF Tracker"),": Kernelized Correlation Filters. Faster than BOOSTING and MIL. Similar to MIL and KCF, does not handle full occlusion well."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"TLD Tracker"),": ?"),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"MedianFlow Tracker"),": Does a nice job reporting failures; doesn't handle big changes in motion / lighting very well."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"MOSSE Tracker"),": Not as accurate as CSRT or KCF. Good choice for speed."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"CSRT Tracker"),": Discriminative Correlation Filter (with Channel and Spatial Reliability). More accurate than KCF but slightly slower.")),(0,r.kt)("p",null,"In the following video (downloaded free stock from ",(0,r.kt)("a",{parentName:"p",href:"https://www.pexels.com/videos/"},"pexels.com"),") I am selecting the woman in the brown coat in the background to the right. All algorithms do well to the point where she is blocked from view - non of them reacquire her:"),(0,r.kt)("h4",{id:"boosting-vs-kcf"},"BOOSTING vs KCF"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"OpenCV - Select Tracking Algorithm",src:n(11555).Z,width:"838",height:"233"})),(0,r.kt)("h4",{id:"mosse-vs-csrt"},"MOSSE vs CSRT"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"OpenCV - Select Tracking Algorithm",src:n(22052).Z,width:"838",height:"233"})),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"CSRT"),": high tracking accuracy but slower FPS throughput."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"KCF"),": the FPS I am getting are slightly higher but accuracy is supposed to be slightly worse than CSRT."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"MOSSE"),": for easy to track objects - only speed matters.")),(0,r.kt)("p",null,"Interesting - the ",(0,r.kt)("strong",{parentName:"p"},"MOSSE")," algorithm seems to keeps the ROI size constant. Which must make it more difficult to recognize the object if it moves towards or away from the camera:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"OpenCV - Select Tracking Algorithm",src:n(33347).Z,width:"844",height:"234"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import cv2\n\ntracker_types = ['BOOSTING', 'MIL', 'KCF', 'TLD', 'MEDIANFLOW', 'MOSSE', 'CSRT']\ntracker_type = tracker_types[4]\n\nif tracker_type == 'BOOSTING':\n    tracker = cv2.legacy.TrackerBoosting_create()\nelif tracker_type == 'MIL':\n    tracker = cv2.legacy.TrackerMIL_create()\nelif tracker_type == 'KCF':\n    tracker = cv2.legacy.TrackerKCF_create()\nelif tracker_type == 'TLD':\n    tracker = cv2.legacy.TrackerTLD_create()\nelif tracker_type == 'MEDIANFLOW':\n    tracker = cv2.legacy.TrackerMedianFlow_create()\nelif tracker_type == 'MOSSE':\n    tracker = cv2.legacy.TrackerMOSSE_create()\nelif tracker_type == 'CSRT':\n    tracker = cv2.legacy.TrackerCSRT_create()\n\n# Change tracker_type index to check if objects are created:\nprint(tracker)\n")),(0,r.kt)("h3",{id:"load-video-file"},"Load Video File"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"video = cv2.VideoCapture('resources/car_race_02.mp4')\n# load video\nif not video.isOpened():\n    print('[ERROR] video file not loaded')\n    sys.exit()\n# capture first frame\nok, frame = video.read()\nif not ok:\n    print('[ERROR] no frame captured')\n    sys.exit()\nprint('[INFO] video loaded and frame capture started')\n")),(0,r.kt)("h3",{id:"select-object-to-track"},"Select Object to Track"),(0,r.kt)("p",null,"Load the first frame from your video file and use the OpenCV Region of Interest selector to mark your object:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"bbox = cv2.selectROI(frame)\nprint('[INFO] select ROI and press ENTER or SPACE')\nprint('[INFO] cancel selection by pressing C')\nprint(bbox)\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"OpenCV Object Tracking",src:n(65551).Z,width:"1024",height:"480"})),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"bbox")," variable returns the corner point of the ",(0,r.kt)("strong",{parentName:"p"},"Bounding Box")," selected with the ROI Selector:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"(1028, 190, 84, 76)\n")),(0,r.kt)("h3",{id:"track-the-object"},"Track the Object"),(0,r.kt)("p",null,"Now we can start the object tracking based on our selected region of interest."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"ok = tracker.init(frame, bbox)\nif not ok:\n    print('[ERROR] tracker not initialized')\n    sys.exit()\nprint('[INFO] tracker was initialized on ROI')\n# random generate a colour for bounding box\ncolours = (randint(0, 255), randint(0, 255), randint(0, 255))\n# loop through all frames of video file\nwhile True:\n    ok, frame = video.read()\n    if not ok:\n        print('[INFO] end of video file reached')\n        break\n    # update position of ROI based on tracker prediction\n    ok, bbox = tracker.update(frame)\n    # test print coordinates of predicted bounding box for all frames\n    print(ok, bbox)\n")),(0,r.kt)("p",null,"This will loop through every frame of our video file and update the position of our bounding box based on the tracker prediction until the end of file is reached:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"[INFO] select ROI and press ENTER or SPACE\n[INFO] cancel selection by pressing C\n[INFO] tracker was initialized on ROI\nTrue (1013.0, 196.0, 89.0, 72.0)\nTrue (1000.0, 201.0, 91.0, 74.0)\nTrue (986.0, 205.0, 92.0, 75.0)\n\n...\n\nTrue (76.0, 1034.0, 67.0, 55.0)\n[INFO] end of video file reached\n")),(0,r.kt)("p",null,"Now we can use the predicted position of our bounding box to draw a rectangle around our tracked object:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"    if ok == True:\n        (x, y, w, h) = [int(v) for v in bbox]\n        # use predicted bounding box coordinates to draw a rectangle\n        cv2.rectangle(frame, (x, y), (x+w, y+h), colours, 3)\n        cv2.putText(frame, str(tracker_type), (10, 30), cv2.QT_FONT_NORMAL, 1, (255, 255, 255))\n\n    else:\n        # if prediction failed and no bounding box coordinates are available\n        cv2.putText(frame, 'No Track', (10, 30), cv2.QT_FONT_NORMAL, 1, (0, 0, 255))\n\n    # display object track\n    cv2.imshow('Single Track', frame)\n    # press 'q' to break loop and close window\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n")),(0,r.kt)("h3",{id:"record-the-output-video"},"Record the Output Video"),(0,r.kt)("p",null,"Set recording parameter:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(video.get(cv2.CAP_PROP_FPS))\nvideo_codec = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\nprefix = 'recording/'+datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\nbasename = \"object_track.mp4\"\nvideo_output = cv2.VideoWriter(\"_\".join([prefix, basename]), video_codec, fps, (frame_width, frame_height))\n")),(0,r.kt)("p",null,"And trigger the recording inside the ",(0,r.kt)("strong",{parentName:"p"},"While Loop"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"video_output.write(frame)\n")),(0,r.kt)("h3",{id:"user-input-by-arguments"},"User Input by Arguments"),(0,r.kt)("p",null,"Parse arguments to select the tracking algorithm and video file:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import argparse\n\n...\n\nap = argparse.ArgumentParser()\nap.add_argument("-v", "--video", type=str, default=\'resources/group_of_people_01.mp4\', help="path to input video file")\nap.add_argument("-t", "--tracker", type=int, default=6, help="Select tracker [0-6]: boosting, mil, kcf, "\n                                                                 "tld, mediaflow, mosse, csrt")\nargs = vars(ap.parse_args())\n\ntracker_types = [\'BOOSTING\', \'MIL\', \'KCF\', \'TLD\', \'MEDIANFLOW\', \'MOSSE\', \'CSRT\']\ntracker_type = tracker_types[args["tracker"]]\n\n\n...\n\n\nvideo = cv2.VideoCapture(args["video"])\n')),(0,r.kt)("h2",{id:"multitrack-and-goturn"},"Multitrack and GOTURN"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/mpolinowski/opencv-object-tracking/blob/master/scripts/multi_tracking.py"},"scripts/multi_tracking.py")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://github.com/mpolinowski/opencv-object-tracking/blob/master/scripts/goturn_tracking.py"},"goturn_tracking.py"))),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"OpenCV Object Tracking",src:n(32215).Z,width:"844",height:"235"})))}d.isMDXComponent=!0},11555:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/BOOSTING_vs_KCF-9abbde7c0ac8e3a5e1022aa0b64ec60d.gif"},32215:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/CSRT_Multi_vs_GOTURN-a9e0b70229395861916b7bd65162ae65.gif"},22052:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/MOSSE_vs_CSRT-66fa93080e7c4805c94fbc7dcc1b5dcf.gif"},33347:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/MOSSE_vs_CSRT2-7ec9d136c5e2febdf8b4bc142a43f6f8.gif"},65551:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/OpenCV_Object_Tracking_01-2135bb6f4650f288d2d27958d3c5a8d7.png"},26016:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-5a0b68587d9242bbb46a1f1aaab44216.jpg"}}]);