<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-IoT-and-Machine-Learning/ML/2018-01-02--machine-learning-with-python/index">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">Machine Learning with SciKit Learn | Mike Polinowski</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2018-01-02--machine-learning-with-python/2018-01-02"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Machine Learning with SciKit Learn | Mike Polinowski"><meta data-rh="true" name="description" content="Shenzhen, China"><meta data-rh="true" property="og:description" content="Shenzhen, China"><link data-rh="true" rel="icon" href="/img/icons/favicon-32x32.png"><link data-rh="true" rel="canonical" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2018-01-02--machine-learning-with-python/2018-01-02"><link data-rh="true" rel="alternate" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2018-01-02--machine-learning-with-python/2018-01-02" hreflang="en"><link data-rh="true" rel="alternate" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2018-01-02--machine-learning-with-python/2018-01-02" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Mike Polinowski RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Mike Polinowski Atom Feed">




<link rel="icon" href="/img/angular_momentum.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="rgb(37,194,160)">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#000">
<link rel="apple-touch-icon" href="/img/angular_momentum.png">
<link rel="mask-icon" href="/img/angular_momentum.png" color="rgb(33,33,33)">
<meta name="msapplication-TileImage" content="/img/angular_momentum.png">
<meta name="msapplication-TileColor" content="#000">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-P74BDWF0C6"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-P74BDWF0C6",{})</script><link rel="stylesheet" href="/assets/css/styles.714c4925.css">
<link rel="preload" href="/assets/js/runtime~main.23698315.js" as="script">
<link rel="preload" href="/assets/js/main.2d20e69f.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/angular_momentum.png" alt="Mike Polinowski :: Dev Notebook" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/angular_momentum.png" alt="Mike Polinowski :: Dev Notebook" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Mike Polinowski</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/docs/tags">Tags</a><a class="navbar__item navbar__link" href="/Search">Search</a><a href="https://mpolinowski.github.io/Personal" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">About<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/mpolinowski" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/development">Development</a><button aria-label="Toggle the collapsible sidebar category &#x27;Development&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/devops">DevOps</a><button aria-label="Toggle the collapsible sidebar category &#x27;DevOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/internet-of-things--machine-learning">Internet-of-Things &amp; Machine Learning</a><button aria-label="Toggle the collapsible sidebar category &#x27;Internet-of-Things &amp; Machine Learning&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/docs/category/machine-learning">Machine Learning</a><button aria-label="Toggle the collapsible sidebar category &#x27;Machine Learning&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-14-yolov7_to_tensorflow/2023-01-14">YOLOv7 to Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-13-yolov7_data_conversion/2023-01-13">YOLOv7 Label Conversion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-10-yolov7_custom_data/2023-01-10">YOLOv7 Training with Custom Data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-08-depth-vision-midas/2023-01-08">MiDaS Depth Vision</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-05-yolov7/2023-01-05">YOLOv7 Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-31-tf-rnn-text-generation/2022-12-31">Recurrent Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator/2022-12-28">Deep Convolutional Generative Adversarial Network</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/2022-12-21">Tensorflow Downsampling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-deepdream/2022-12-21">Tensorflow Deep Dream</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-20-tf-representation/2022-12-19">Tensorflow Representation Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-19-tf-hub/2022-12-19">Tensorflow Hub</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-18-tf-transfer-learning/2022-12-18">Tensorflow Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-16-tf-cifar/2022-12-16">Tensorflow Image Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-12-tf-breast-cancer-classification-part6/2022-12-12">Breast Histopathology Image Segmentation Part 6</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-12-tf-breast-cancer-classification-part5/2022-12-12">Breast Histopathology Image Segmentation Part 5</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part4/2022-12-11">Breast Histopathology Image Segmentation Part 4</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part3/2022-12-11">Breast Histopathology Image Segmentation Part 3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part2/2022-12-11">Breast Histopathology Image Segmentation Part 2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1/2022-12-10">Breast Histopathology Image Segmentation Part 1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning/2022-11-27">Deep Docker on Arch</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-04-pytorch-face-restoration/2022-04-04">Face Restoration with GFPGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-03-pytorch-real-super-resolution/2022-04-03">Super Resolution with Real-ESRGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-02-pytorch-super-resolution/2022-04-02">Super Resolution with ESRGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/2022-04-01">Deep Audio</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20">Yolo App - YOLOv5 Data Preparation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/2022-02-19">Yolo App - Flask Web Application</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-18--yolo-app-ocr/2022-02-18">Yolo App - Tesseract Optical Character Recognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-17--yolo-app-prediction-pipeline/2022-02-17">Yolo App - Pipeline Predictions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-16--yolo-app-tensorflow-model/2022-02-16">Yolo App - Train a Model with Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/2022-02-15">Yolo App - Data Collection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-10--opencv-optical-flow-tracking/2021-12-10">OpenCV Optical Flow Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-09--opencv-camshift-tracking/2021-12-09">OpenCV CAMshift Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-08--opencv-meanshift-tracking/2021-12-08">OpenCV Meanshift Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-07--opencv-detection-and-tracking/2021-12-07">OpenCV Object Detection and Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking/2021-12-06">OpenCV Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-05--opencv-face-detection/2021-12-05">OpenCV Face Detection and Privacy</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/2021-12-04">OpenCV Image Objects</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-03--opencv-image-operations/2021-12-03">OpenCV Image Operations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-02--opencv-with-videos/2021-12-02">OpenCV, Streams and Video Files</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-01--opencv-with-images/2021-12-01">OpenCV and Images</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-15--facebook-prophet-introduction/2021-11-15">Introduction into FB Prophet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-14--tensorflow-model-for-tfjs/2021-11-14">Tensorflow.js React App</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-13--tensorflow-model-zoo/2021-11-13">Tensorflow2 Model Zoo</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-12--tensorflow-crash-course-part-v/2021-11-12">Tensorflow2 Crash Course - Part V</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-11--tensorflow-crash-course-part-iv/2021-11-11">Tensorflow2 Crash Course - Part IV</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-10--tensorflow-crash-course-part-iii/2021-11-10">Tensorflow2 Crash Course - Part III</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-09--tensorflow-crash-course-part-ii/2021-11-09">Tensorflow2 Crash Course - Part II</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-08--tensorflow-crash-course-part-i/2021-11-08">Tensorflow Crash Course - Part I</a><button aria-label="Toggle the collapsible sidebar category &#x27;Tensorflow Crash Course - Part I&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-07--opencv-crash-course-part-ii/2021-11-07">OpenCV Crash Course Part II</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-06--opencv-crash-course-part-i/2021-11-06">OpenCV Crash Course Part I</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-05--license-plates-yolov4-opencv-tesseract/2021-11-05">License Plate Recognition with YOLOv4, OpenCV and Tesseract</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-04--installing-yolov4/2021-11-04">Installing YOLOv4 with Anaconda</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-03--streamlit-opencv-mediapipe/2021-11-03">Streamlit user interface for openCV/Mediapipe face mesh app</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-02--spacy_ner_predictions/2021-11-02">spaCy NER Predictions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-01--spacy_natural_language_processing/2021-11-01">spaCy NER on Arch Linux</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2019-04-01--introduction-to-keras/2019-04-01">Introduction to Keras</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-10-31--tesseract_ocr_arch_linux/2021-10-31">Tesseract OCR on Arch Linux</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2019-03-31--introduction-to-tensorflow-2-beta/2019-03-31">Introduction to TensorFlow 2 Beta</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2018-01-02--machine-learning-with-python/2018-01-02">Machine Learning with SciKit Learn</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/aiops">AIOps</a><button aria-label="Toggle the collapsible sidebar category &#x27;AIOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/home-automation">Home Automation</a><button aria-label="Toggle the collapsible sidebar category &#x27;Home Automation&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/mqtt">MQTT</a><button aria-label="Toggle the collapsible sidebar category &#x27;MQTT&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_OVgt"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/internet-of-things--machine-learning"><span itemprop="name">Internet-of-Things &amp; Machine Learning</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/machine-learning"><span itemprop="name">Machine Learning</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Machine Learning with SciKit Learn</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Machine Learning with SciKit Learn</h1></header><p><img loading="lazy" alt="Shenzhen, China" src="/assets/images/photo-33796028333_a7fa30ab08_o-c59d7b60abca3582796fbd0c7132d682.jpg" width="1500" height="480" class="img_ev3q"></p><ul><li><a href="#prerequisite">Prerequisite</a></li><li><a href="#scikit-introduction">SciKit Introduction</a><ul><li><a href="#data-representation">Data Representation</a></li><li><a href="#data-preprocessing">Data Preprocessing</a></li><li><a href="#scikit-learn-api">SciKit-Learn API</a></li><li><a href="#estimation">Estimation</a></li><li><a href="#predictor">Predictor</a></li><li><a href="#transformer">Transformer</a></li></ul></li><li><a href="#unsupervised-learning-introduction">Unsupervised Learning Introduction</a><ul><li><a href="#clustering-tasks">Clustering Tasks</a></li></ul></li><li><a href="#unsupervised-learning-irl">Unsupervised Learning IRL</a><ul><li><a href="#clustering">Clustering</a></li><li><a href="#visualization">Visualization</a></li><li><a href="#k-means-algorithm">k-Means Algorithm</a><ul><li><a href="#initialization-methods">Initialization Methods</a></li></ul></li><li><a href="#mean-shift-algorithm">Mean-Shift Algorithm</a></li><li><a href="#dbscan-algorithm">DBSCAN Algorithm</a></li><li><a href="#evaluating-performance">Evaluating Performance</a></li></ul></li><li><a href="#supervised-learning-introduction">Supervised Learning Introduction</a><ul><li><a href="#classification-tasks">Classification Tasks</a></li><li><a href="#regression-tasks">Regression Tasks</a></li></ul></li><li><a href="#supervised-learning-irl">Supervised Learning IRL</a><ul><li><a href="#data-split">Data Split</a></li><li><a href="#cross-validation">Cross Validation</a></li><li><a href="#metric-evaluation">Metric Evaluation</a></li><li><a href="#table-of-confusion">Table of Confusion</a><ul><li><a href="#evaluation-of-tasks-with-binary-output-labels">Evaluation of Tasks with binary output labels</a></li><li><a href="#evaluation-of-regression-tasks">Evaluation of Regression Tasks</a></li></ul></li></ul></li></ul><p>An Introduction in building machine learning applications with the SciKit Python library. Learn data preprocessing and implement supervised and unsupervised algorithms as well as performing error analysis to evaluate their performance.</p><h1>Prerequisite</h1><p>First we need to install the <a href="https://www.anaconda.com/download/" target="_blank" rel="noopener noreferrer">Anaconda Environment</a> for Windows, macOS or LINUX. This package combines everything we need to get started with Python. From libraries like <a href="https://scikit-learn.org/stable/" target="_blank" rel="noopener noreferrer">SciKit-Learn</a>, Pandas and Matplotlib to Jupyter Notebook, that will help us to execute our Python scripts.</p><p>We will begin working with the <a href="https://anaconda.org/anaconda/seaborn" target="_blank" rel="noopener noreferrer">Seaborn Package</a> dataset that is included in the Anaconda package to become familiar with Python based data analysis.</p><p>In the later steps, we are going to use publicly available data from the <a href="https://archive.ics.uci.edu" target="_blank" rel="noopener noreferrer">UCI Archive</a>:</p><ul><li><p><a href="http://archive.ics.uci.edu/ml/datasets/Wholesale+customers" target="_blank" rel="noopener noreferrer">Wholesale Customer Dataset</a></p></li><li><p><a href="https://archive.ics.uci.edu/ml/datasets/Fertility" target="_blank" rel="noopener noreferrer">Adult Fertility Study</a></p><ul><li><a href="https://archive.ics.uci.edu/ml/machine-learning-databases/00244/" target="_blank" rel="noopener noreferrer">https://archive.ics.uci.edu/ml/machine-learning-databases/00244/</a></li><li><a href="https://archive.ics.uci.edu/ml/machine-learning-databases/adult/" target="_blank" rel="noopener noreferrer">https://archive.ics.uci.edu/ml/machine-learning-databases/adult/</a></li></ul></li><li><p><a href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing" target="_blank" rel="noopener noreferrer">Bank+Marketing Study</a></p><ul><li><a href="https://archive.ics.uci.edu/ml/machine-learning-databases/00222/" target="_blank" rel="noopener noreferrer">https://archive.ics.uci.edu/ml/machine-learning-databases/00222/</a></li></ul></li></ul><h1>SciKit Introduction</h1><p><a href="https://scikit-learn.org/" target="_blank" rel="noopener noreferrer">SciKit-Learn</a> is a OpenSource library for building models based on built-in machine learning and statistical algorithms. The library offers both supervised and unsupervised models, that we will use to analyze our data with.</p><p>The library is used to:</p><ul><li>Interpret data and train models</li><li>Perform predictions from data sets</li><li>Cross validation and performance metric analysis</li><li>To create sample data sets and test algorithms</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="data-representation">Data Representation<a class="hash-link" href="#data-representation" title="Direct link to heading">​</a></h2><p>To feed data into SciKit it needs to be represented as a table or matrix. Most data used in machine learning is 2-dimensional - that means it can be represented by a classical Excel sheet with rows and columns:</p><ul><li>Rows represent observations (instances)</li><li>Columns represent characteristics (features)</li></ul><p>Datasets often have many features that will be represented in the <strong>Feature Matrix</strong>. In most cases it will only be one or two features that will separated for the later analysis of the data set - this skimmed down dataset is called the <strong>Target Matrix</strong>:</p><p><strong>Feature Matrix</strong></p><ul><li>Contains data from each instance for all features</li><li>The dimensions of the matrix are <code>[n_i, n_f]</code> denoting the number of instances and features.</li></ul><p><strong>Target Matrix</strong></p><ul><li>Is usually 1-dimensional as it only contains 1 feature for all instances. If more than 1 feature is necessary to describe the model the dimension increases accordingly.</li></ul><p>The Feature Matrix is usually stored in the variable <strong>X</strong>, while the variable <strong>Y</strong> is used to store the <strong>Target Matrix</strong>. Both matrices can be created by using a <strong>NumPy Array</strong> or a <strong>Panda DataFrame</strong>. </p><p>In the following example we are going to look at plant statistic from the <a href="https://anaconda.org/anaconda/seaborn" target="_blank" rel="noopener noreferrer">Seaborn Package</a> included in the <a href="https://www.anaconda.com/download/" target="_blank" rel="noopener noreferrer">Anaconda Environment</a>. Each row in the set will represent a species of the Setosa family and columns represent the plant characteristics of the sepal as well as petal length and width:</p><p><img loading="lazy" alt="Python SciKit-Learn" src="/assets/images/python-ml_01-b32c58e4ab112551197dafed7766a2bb.png" width="800" height="622" class="img_ev3q"></p><ol><li>We import the <strong>Seaborn</strong> package into the variable <strong>sns</strong>.</li><li>We can now extract the <strong>Iris Dataset</strong> from it and store the data inside the variable <strong>iris</strong>.</li><li>We then drop the <strong>Species Feature</strong> from the dataset and store it inside the variable <strong>X</strong>. Thus the <strong>Feature Matrix</strong> consists of all the features <strong>BUT</strong> the target for all instances. Making it a 2 dimensional dataset.</li><li>Now we can have a look at the top 10 rows of our data to get an idea what it looks like.</li><li>The <strong>Shape</strong> command shows us that we have a <strong>Feature Matrix</strong> that consists of <em>150 rows</em> (instances) and <em>4 columns</em> (features).</li><li>We will now build the <strong>Target Matrix</strong> based on the <strong>Species Feature</strong> and store it in the variable <strong>Y</strong>.</li><li>And we see that the first 10 species all belong to the Setosa family. The <strong>Target Matrix</strong> is now reduced from the earlier 2 to 1 dimension - only consisting of the target feature for all instances.</li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="data-preprocessing">Data Preprocessing<a class="hash-link" href="#data-preprocessing" title="Direct link to heading">​</a></h2><p>IRL datasets are usually not analysis-friendly (<strong>messy data</strong>), as they are containing <em>noisy data</em>, <em>missing entries</em> and <em>outliers</em> that need to be dealt with before feeding them to our algorithm.</p><p><strong>Dealing with Missing Values</strong>:</p><ul><li>Eliminate Data</li><li>Or Replace it<ul><li><strong>Mean Imputation</strong> - filling out missing fields using the mean or median value (<em>may introduce bias to our model</em>)</li><li><strong>Regression Imputation</strong> - Use prediction to fill out the values (<em>may end up overfitting the model</em>)</li></ul></li><li>String-based values should be replaced with a class (<em>like  &#x27;uncategorized&#x27;</em>) </li></ul><p><strong>Dealing with Outliers</strong>:</p><p>Outliers represent values that are far from the mean (often set to <strong>3-6 standard deviations</strong> when the data set follows a Gaussian distribution). If the values follow a Gaussian distribution, <em>global outliers</em> are located at the tails of the bell curve. While <em>local outliers</em> are inside the distribution but far off the group of data points they are associated with. E.g. a vehicle that can drive 500 MPH is a global outlier in a car statistic. While a truck that only has 40 hp is a local outlier in the group labeled as trucks, but is still well inside the curve of the vehicle dataset.</p><ul><li>Delete Outliers.</li><li>If all instances above a certain value of a feature behave the same way, you can <strong>define a top</strong> for that feature and apply it to outliers.</li><li>Replace the value (<strong>Mean</strong> or <strong>Regression</strong>).</li><li>String values (e.g. misspelled features) can be eliminated or corrected (when possible).</li></ul><p>In the following example we will again use the <a href="https://anaconda.org/anaconda/seaborn" target="_blank" rel="noopener noreferrer">Seaborn Package</a> included in the <a href="https://www.anaconda.com/download/" target="_blank" rel="noopener noreferrer">Anaconda Environment</a> and take a look at the age of the passengers of the <strong>Titantic</strong>:</p><p><img loading="lazy" alt="Python SciKit-Learn" src="/assets/images/python-ml_02-4a8ed7c5a0b12a21cb92dafe5082075c.png" width="800" height="1284" class="img_ev3q"></p><ol><li>We import the <strong>Seaborn</strong> package and store the <strong>Titanic Dataset</strong> inside the variable <em>titanic</em>.</li><li>We then load the <strong>Age Feature</strong> from the dataset and store it in the variable <em>age</em>.</li><li>Displaying the first 10 rows shows us that we already have a missing entry (<strong>NaN</strong>, <em>not a number</em>). The <em>shape</em> command shows us that there are 891 rows in total. </li><li>We can check how many of those 891 have a value of NaN with the <em>isnull</em> function. Summing them up shows us that we have 177 passengers of the Titanic where we do not know there age.</li><li>We can now use the <strong>Mean Method</strong> to replace all of those with the mean age. For this we call the mean method on the values in <em>age</em>, round them up and store them inside the variable <em>mean</em>. Printing out the value, we can see that the mean age was <em>30</em>.</li><li>We can now use the <strong>fillna Method</strong> to fill out every value that is NaN with the mean value. Taking a look at the first 10 rows again shows that the missing value has now been filled with the mean value 30.</li><li>To display our distribution - to be able to spot <strong>Outliers</strong> - we import <em>PyPlot</em> from the <em>MatPlotLib</em> library as <em>plt</em>. We use the plt method to build a histogram of the values stored inside the <em>age</em> variable and display the output with the show function.</li><li>To spot outliers we will set the <strong>Minimum Value</strong> that we will accept for our model as the mean value for age MINUS <em>3-times the standard deviation</em> of the age dataset. This turns out to be a negative value - given that this does not make any sense in our particular dataset, we can ignore outliers on minimum side of the distribution.</li><li>To spot outliers we will set the <strong>Maximum Value</strong> that we will accept for our model as the mean value for age PLUS <em>3-times the standard deviation</em> of the age dataset. Everyone who is listed as ~ 69 or above can be treated as an outlier.</li><li>We can thus define our <em>outlier</em> variable as every value inside <em>age</em> that is greater than <em>max<!-- -->_<!-- -->val</em>. Counting the outliers shows us that we have <em>7</em> inside our dataset.</li><li>We decide to remove all outliers from our dataset by only accepting values into our <em>age</em> variable that are smaller or equal to <em>max<!-- -->_<!-- -->val</em>. The shape command shows us that out of the initial 891 passengers we now eliminated 7 from our analysis - <em>884</em>.</li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="scikit-learn-api">SciKit-Learn API<a class="hash-link" href="#scikit-learn-api" title="Direct link to heading">​</a></h2><p>SciKit-Learn offers us a unified syntax to make machine learning more accessible. The SciKit-Learn API is divided into 3 interfaces:</p><ul><li><strong>Estimator Interface</strong>: Used to create models and integrate your data.</li><li><strong>Predictor Interface</strong>: Used to make predictions based on the models created.</li><li><strong>Transformer Interface</strong>: Used to transform data files.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="estimation">Estimation<a class="hash-link" href="#estimation" title="Direct link to heading">​</a></h2><p>This is the interface that you use to initialize a model and apply a fit() method to your data. Your data is received as two variables - <strong>X_train</strong> is the feature matrix and <strong>Y_train</strong> the target matrix for your model. <em>Unsupervised Models</em> only use the first of those two arguments. A <em>Supervised Model</em> takes both.</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">naive_bayes </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> GaussianNB</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model </span><span class="token operator">=</span><span class="token plain"> GaussianNB</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">fit</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">X_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> Y_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>In the example of a supervised model, we imported the model we want to use, store it in the variable <code>model</code> and then apply it to our two arguments using the fit() method.</p><p>The Estimator can perform 3 more tasks for us:</p><ul><li><strong>Feature Extraction</strong>: A transformation of the input data into numerical features.</li><li><strong>Feature Selection</strong>: Selecting a feature from your data that most contributes to the prediction output.</li><li><strong>Dimensionality</strong>: Converting your data into a lower dimension.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="predictor">Predictor<a class="hash-link" href="#predictor" title="Direct link to heading">​</a></h2><p>The Predictor interface performs prediction based on the model you trained. In supervised models it creates a new dataset called <strong>X_test</strong> and re-feeds it to your model. The implementation looks as follows:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">Y_pred </span><span class="token operator">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">predict</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">X_test</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This allows us to quantify the <strong>Confidence</strong> or <strong>Performance</strong> of a model by comparing how far <em>X<!-- -->_<!-- -->test</em> differs from <em>Y<!-- -->_<!-- -->test</em>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="transformer">Transformer<a class="hash-link" href="#transformer" title="Direct link to heading">​</a></h2><p>The Transform interface gives us a transform() method to preprocess our input data. Using the same transformation for the data that we use to train our model as well as the for the data we later use the model on to perform predictions ensures that both datasets are comparable in their distribution. An example is the <strong>Normalization</strong> of a dataset:</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> sklearn</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">preprocessing </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> StandardScaler</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scaler </span><span class="token operator">=</span><span class="token plain"> StandardScaler</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">scaler</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">fit</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">X_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">X_train </span><span class="token operator">=</span><span class="token plain"> scaler</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">transform</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">X_train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Here we imported the transformer and store it inside the variable <code>scaler</code>. Our dataset is then fit to the imported method and the transformation performed.</p><h1>Unsupervised Learning Introduction</h1><p>In unsupervised learning the model is modelled to the data, without any relationship to an output label. It can be used to show up clusters of similarities inside unlabeled data.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="clustering-tasks">Clustering Tasks<a class="hash-link" href="#clustering-tasks" title="Direct link to heading">​</a></h2><p>Finding clusters in unlabeled data involves grouping instances that are similar to each other, while differing visibly from instances in other groups. The most popular Clustering Algorithms are:</p><ol><li><strong>k-means</strong>: Separating instances in <em>n</em> clusters of equal variance by minimizing the sum of the squared distances between 2 points - <em>Centroid-based Model</em>.</li><li><strong>Mean-shift clustering</strong>: Using centroids to create a cluster, where every instances is a candidate to become a centroid (mean of the points in that cluster) - <em>Centroid-based Model</em>.</li><li><strong>DBSCAN</strong>: <em>Density-based spatial clustering of applications with noise</em> separates areas with high densities of points as clusters from areas with a low density - <em>Density-based Model</em>.</li><li><strong>Gaussian</strong>: The belonging to a cluster is shown as a deviation from a distribution as used in an expectation maximization model - <em>Distribution-based Models</em>.</li><li><strong>Hierarchial</strong>: Similarity as proximity inside the data space - <em>Connectivity-based Model</em></li></ol><h1>Unsupervised Learning IRL</h1><p>We want to use unsupervised models  to analyze data sets from real-world applications. The Objectives are:</p><ul><li>Understanding different clustering techniques</li><li>Using Panda Dataframes</li><li>Data visualizations with MatPlotLib</li><li>Working with algorithms like k-means, mean-shift and DBSCAN</li><li>Using performance metrics to decide which one to use</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="clustering">Clustering<a class="hash-link" href="#clustering" title="Direct link to heading">​</a></h2><p>Clustering is a type of unsupervised machine-learning technique to find pattern in unlabeled input data and divide data points into <em>n</em> clusters based on similarity (and difference to data points in other cluster). The assignment to a cluster can either be <strong>hard</strong> (absolute designation) or <strong>soft</strong> (probability of belonging to a cluster). Real-world applications are:</p><ul><li>Search Engine Results</li><li>Recommendation Programs</li><li>Image Recognition</li><li>Market Segmentation for targeted Marketing</li></ul><p>We are going to use the <a href="#prerequisite">Wholesale Customer Dataset</a> from the UC Irvine Machine Learning Repository to explore those techniques.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="visualization">Visualization<a class="hash-link" href="#visualization" title="Direct link to heading">​</a></h2><p>Visual representations of datasets help us to understand relationships in datasets, results and performance of a model. To work with Visualizations we can load our data into a <strong>Dataframe</strong> using <strong>Pandas</strong>. Panda dataframes manage stored data in a 2-dimensional, size-mutable matrix with labelled axes and are often stored in <em>*.csv</em> files - like the example of the <a href="#prerequisite">Wholesale Customer Dataset</a>. Data presented this way can be easily loaded into a frame using the Panda function <strong>read.csv()</strong> (there are alternatives for data based in Excel sheets or SQL databases - <em>read.xlx()</em> and <em>read.sql()</em>):</p><div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> pandas </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> pd</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">file_path </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;./wholesale-customers-data.csv&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">data </span><span class="token operator">=</span><span class="token plain"> pd</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">read_csv</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">file_path</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>To create a visual representation of such a dataframe we can use the Python library <strong>Matplotlib</strong> and create:</p><ul><li>Histograms (<em>plt.hist()</em>) </li><li>Scatter Plots (<em>plt.scatter()</em>)</li><li>Bar Charts (<em>plt.bar()</em>)</li><li>Pie Charts (<em>plt.pie()</em>)</li></ul><p><img loading="lazy" alt="Python SciKit-Learn" src="/assets/images/python-ml_03-55716561bd24d727414489bec67ab005.png" width="800" height="694" class="img_ev3q"></p><p>In this example we used the <strong>Numpy</strong> random number generator and <em>make<!-- -->_<!-- -->circles()</em> method to generate a dataset and created a scatter plot and a histogram from it using Matplotlib.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="k-means-algorithm">k-Means Algorithm<a class="hash-link" href="#k-means-algorithm" title="Direct link to heading">​</a></h2><p>The k-means algorithm is used on unlabelled data to divide it into <em>K</em> number of clustered subgroups based on similarity. The <strong>Centroid</strong> of each cluster represents a collection of features that can be used to define the members of the cluster.</p><ul><li><strong>Initialization</strong>: Based on the number of clusters set by you, centroids are generated by initial estimates or at random.</li><li><strong>Assignment</strong>: All data points are assigned to the nearest cluster.</li><li><strong>Update</strong>: Centroids are recalculated by computing the mean of all data points inside the cluster.</li></ul><p>The algorithm runs until:</p><ul><li>It reaches the number of preset iterations.</li><li>Data points no longer change from one cluster to another.</li><li>The Euclidean distance between all data points and their assigned centroid is minimized.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="initialization-methods">Initialization Methods<a class="hash-link" href="#initialization-methods" title="Direct link to heading">​</a></h3><p>The <strong>k-means++</strong> (default) method chooses the initial centroids randomly with a maximized distance from other centroids.</p><p>The number of centroids has to be chosen by you to minimize the average cluster distance in relation to it&#x27;s centroids. At a small number of centroids, the distance between forming clusters is high. The distance reduces the more initial centroids are added to the calculation - until a point where it stagnates. Adding more centroids after that point will falsify the results by over-representation of features by data points inside the cluster.</p><p>By plotting the distances between clusters against the number of clusters, the ideal number of centroids is given by the breaking point, where the rate decreases suddenly. In the example below we can see that the distances between points inside a cluster is very high, when we start with 1 centroid. It is very low with 15 centroids. k can be set to 5 as it is the point where the similarity between data points inside the cluster no longer increase significantly when we keep sub-dividing clusters:</p><p><img loading="lazy" alt="Python SciKit-Learn" src="/assets/images/python-ml_04-0b0de1549b0c18119e77a656287529e2.png" width="800" height="647" class="img_ev3q"></p><p>Here we imported the <em>sklearn.cluster</em> packages as KMeans and initialize <em>ideal<!-- -->_<!-- -->k</em>, which is then filled with a for-loop calculating the inertia (the average distance between data points within a cluster) as a function of the number of clusters inside our dataset. With every loop the number of clusters <em>i</em> is increased by 1 until we reach 15.</p><p>We can then convert the array to a Numpy array and plot the data. We can see a sharp decrease in rate around 4-6, telling us that <em>k=5</em> would be a good place to initialize our analysis with.</p><p>We can now initialize our analysis by setting the number of centroids to 5, fit the dataset with k-means and predict what cluster a data point belongs to. To visualize the result we want to set the colour for each data point inside a cluster to <code>c=pred_kmeans</code>.</p><p>The results below show the plot for a number of 5, 4 and 6 clusters inside the dataset:</p><p><img loading="lazy" alt="Python SciKit-Learn" src="/assets/images/python-ml_05-1047b7d4f8989a44599e6864f3cd010d.png" width="800" height="1096" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="mean-shift-algorithm">Mean-Shift Algorithm<a class="hash-link" href="#mean-shift-algorithm" title="Direct link to heading">​</a></h2><p>While the <strong>k-mean</strong> algorithm assigns a data point to a cluster as a function of the distance to a centroid, the <strong>mean-shift</strong> algorithm evaluates the density of data points in the data space to define clusters.</p><p>The mean-shift algorithm represents the data points as a <strong>density distribution</strong> (KDE - <em>Kernel Density Estimation</em>).</p><p><img loading="lazy" alt="Python SciKit-Learn" src="/assets/images/python-ml_06-dd7e0d9df21912cb0167df840e984d14.png" width="801" height="1149" class="img_ev3q"></p><p>As we can see we are getting the same result here as with the k-means algorithm - we just did not have to define the number of centroids.</p><p><strong>Note</strong> that you can influence the amount of clusters found by assigning different <strong>bandwidths</strong> - the example above varies the bandwidth between 0.4-0.6 as the data set was normalized between 0-1 (when you are working with data with values between 0-2000, you should adjust the bandwidth to ~ 100-500 to get sensible results). The bandwidth represents the size of a window that is drawn around each data point. With every iteration the mean-shift algorithm calculates the mean of each window, based on the data points it contains, and shifts each window towards the mean. This process is repeated until every point is shifted to the nearest peak in the density distribution. The number of shifts a data point has to undergo depends on the distance to the peak and the window size (bandwidth) that is used. Every data point in a peak of the distribution belongs to that cluster.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="dbscan-algorithm">DBSCAN Algorithm<a class="hash-link" href="#dbscan-algorithm" title="Direct link to heading">​</a></h2><p>The <em>density-based spatial clustering of applications with noise</em> (<strong>DBSCAN</strong>) algorithm groups points that are close to each other and marks points that have no close neighbors as <strong>outliers</strong>.</p><p>The algorithm requires two main parameters:</p><ul><li><strong>Epsilon</strong> (<em>eps</em>): as the maximum distances within which the algorithm searches for neighbors. Epsilon, just like the bandwidth in case of the mean-shift algorithm, has to be adapted to the value of your data point.</li><li><strong>Minimum Number of Observations</strong> (<em>min<!-- -->_<!-- -->sample</em>): as the number of data points required to form a high density area. Note that SciKit learn this value is set to 5 by default and it is optional for you to change this value if necessary.</li></ul><p>Given these requirements each data point can be classified as:</p><ol><li><strong>Core Point</strong>: when it has at least the minimum number of data points within it&#x27;s eps radius.</li><li><strong>Border Point</strong>: when it is within the eps radius of a core point but does not have the required minimum number of data points within it&#x27;s own radius.</li><li><strong>Noise Point</strong>: when none of the above is true.</li></ol><p><img loading="lazy" alt="Python SciKit-Learn" src="/assets/images/python-ml_07-a3836daef336dd3df85bb237a44461e3.png" width="800" height="1093" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="evaluating-performance">Evaluating Performance<a class="hash-link" href="#evaluating-performance" title="Direct link to heading">​</a></h2><p>Once we applied an algorithm to form clusters inside our data set we now have to have a way to evaluate the performance of those clusters - was the algorithm and parameters we choose the best option for the given task?</p><p>In case of a <strong>Supervised Algorithm</strong> this can be done by comparing the predictions we get with the true value we know. In case of an <strong>Unsupervised Model</strong> this is not possible. For clustering algorithm we have the option to measure the similarity of data points within a cluster to estimate the performance of the chosen algorithm.</p><p>SciKit Learn offers two method to evaluate the performance of unsupervised clustering algorithms by measuring how well-defined the clusters edges are (instead of measuring the dispersion within the cluster). We have to keep in mind that those methods don&#x27;t take the size of each cluster into account.</p><ol><li><strong>Silhouette Coefficient Score</strong>: Calculates the mean distance between each point inside their cluster (a) and the mean distance to it&#x27;s nearest other clusters (b). The coefficient is calculated by <code>s = (b-a)/max(a,b)</code> and results in a score between -1 and 1 - the lower the value, the worse the performance of the cluster. A special case is a value of 0 where clusters start to overlap. This scoring system <strong>does not work</strong> with density based algorithms like DBSCAN.</li><li><strong>Calinski-Harabasz Index</strong>: Calculates the variance of each cluster by the mean square error of each point to the centroid of that cluster. This is then compared to the overall inter-cluster variance. A higher value describes a better definition/separation of each cluster. This scoring system <strong>does not work</strong> with density based algorithms like DBSCAN.</li></ol><p>SciKit Learn does not offer a scoring system that works reliable for density-based algorithms.</p><p><img loading="lazy" alt="Python SciKit-Learn" src="/assets/images/python-ml_08-32fbcc8977c6082b1597ce7362a56fc5.png" width="800" height="385" class="img_ev3q"></p><p>As we see above, we are getting comparable scores for the k-mean and mean-shift algorithm with the <strong>silhouette<!-- -->_<!-- -->score</strong> - k-mean (<em>0.360</em>) is works slightly better than mean-shift (<em>0.344</em>). The DBSCAN algorithm performs poorly in comparison (<em>0.089</em>). But the scoring system might fail us here.</p><p>The sores we get from the <strong>calinski<!-- -->_<!-- -->harabaz<!-- -->_<!-- -->score</strong> are in line with this observation (k-means_score=1377.88, meanshift=1304.07, dbscan_sore=0.16).</p><h1>Supervised Learning Introduction</h1><p>A supervised model explores the relation between a set of features and a target value (label / class). E.g. a person&#x27;s demographic and their ability to re-pay loans.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="classification-tasks">Classification Tasks<a class="hash-link" href="#classification-tasks" title="Direct link to heading">​</a></h2><p>Classifications are used to build models with discrete categories as labels. Such tasks output a prediction as a probability of an instance belonging to a label. Common Classification Algorithms are:</p><ol><li><strong>Decision Trees</strong>: A tree-like structure that simulates the decision process based on previous decisions.</li><li><strong>Naive Bayes Classifier</strong>: Relies on probabilistic equations which assume independence among features with the ability to consider several attributes.</li><li><strong>Artificial Neutral Networks</strong>: Replicate the structure of a biological neural network to perform pattern recognition tasks.</li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="regression-tasks">Regression Tasks<a class="hash-link" href="#regression-tasks" title="Direct link to heading">​</a></h2><p>Used for data with continuous quantities as labels, where the value is represented by a quantity and not a set of possible outcomes - e.g. a linear regression.</p><h1>Supervised Learning IRL</h1><p>Finding an algorithm for a task is usually a process of trial &amp; error using testing to validate the resulting model and comparing the result with results from other algorithms.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="data-split">Data Split<a class="hash-link" href="#data-split" title="Direct link to heading">​</a></h2><p>To avoid introducing bias into a supervised model, the data set is partitioned into 3 sets:</p><ol><li><strong>Training Set</strong>: This set is used to train the models with different algorithms. It consists of input data paired with an outcome / label. It is <em>not used</em> for performance evaluation of each model later on.</li><li><strong>Validation Set</strong>: This set is used to perform unbiased evaluations of each model and fine-tune parameters to achieve the best performance. The validation set therefore influences the training indirectly. In the end the model that performs the best is chosen to be used on the next set of data.</li><li><strong>Testing Set</strong>: This set consists of data that had no influence over the trained model and is used for a final, unbiased performance evaluation for future predictions by the model.</li></ol><p>The <strong>Split Ratio</strong> for those three sets depends on the size of our data set. For sets that contain <em>100 - 100,000 instances</em> a split ration for training, validating, testing of <em>60/20/20%</em> is used. For large data sets with <em>more than a million instances</em> a split ration of <em>98/1/1%</em> can be sufficient to determining the performance of a model.</p><p>The <strong>Algorithm</strong> also has an effect on the split ratio you have to use. E.g. if you are working with a model that has a lot of parameters, you might want to work with a larger validation set, while the testing set can remain small.</p><p>In the following we are using the Iris dataset from sklearn and load it into a Panda data frame. Printing the shape of the data frame, we can see that it consists of 150 rows and 4 columns of data and 1 column for the target value with 150 rows.</p><p><img loading="lazy" alt="Python SciKit-Learn" src="/assets/images/python-ml_09-4ef7bb5476df94ab25d36d23051a8413.png" width="1182" height="862" class="img_ev3q"></p><p>To split up our data in a training (<em>_<!-- -->train</em>), validating (<em>_<!-- -->dev</em>) testing (<em>_<!-- -->test</em>) set, we can use the <strong>train<!-- -->_<!-- -->test<!-- -->_<!-- -->split</strong> method from sklearn. We are going to use a <code>test_size</code> of <code>0.2</code> - meaning that we are training our model with 80% of the data - which corresponds to 120 rows, while 30 rows are allocated for testing our model later on.</p><p>In a second step we need to subtract another portion of the data to from our validation group - which removes another 30 rows from our training data.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="cross-validation">Cross Validation<a class="hash-link" href="#cross-validation" title="Direct link to heading">​</a></h2><p>To further reduce bias in our models we can further partition our data into <strong>K</strong> number of groups and re-sample data from those groups as we train and validate our model - this is called <strong>K-fold Cross Validation</strong>, where K is usually replaced by the number of samples used in the training process.</p><p>This process can replace the testing step discussed above or can be done in addition:</p><ul><li><strong>three-split approach</strong>: A testing set is subtracted from the data. The rest of the data is used in the cross-validation process.</li><li><strong>two-split approach</strong>: The complete data set is used for cross-validation.</li></ul><p>In practice this process contains 4 steps that are repeated <strong>K-times</strong>:</p><ol><li>First the data is shuffled.</li><li>The data is split according to the process described above.</li><li>The model is trained and the selected validation group is used to fine-tune parameters.</li><li>The results from the training are stored and the process begins again with step 1 and is repeated K times.</li></ol><p>You end up with K data sets and a model that is trained K-times - the results refined with every iteration.</p><p>In the following we are going to use the same data set as before and use the <strong>three-split-approach</strong> by first removing 20% of our data to form a testing set. We then import the <strong>KFold Method</strong> from Sklearn to split our data in 10 subgroups:</p><p><img loading="lazy" alt="Python SciKit-Learn" src="/assets/images/python-ml_10-e761a252eb62c598eb0f72999b1ba369.png" width="1181" height="600" class="img_ev3q"></p><p>We now have a data set with 10 subgroups that can be referenced by an index number. We can use a <em>for-loop</em> to iterate over the data.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="metric-evaluation">Metric Evaluation<a class="hash-link" href="#metric-evaluation" title="Direct link to heading">​</a></h2><p>The accuracy of a model can be calculated as a percentage by comparing it&#x27;s predicted values with real (unseen as not used in the training of the model) measurements. </p><p>This can visualized in the so called <strong>Confusion Matrix</strong> - a 2-dimensional matrix that contains the predictions as columns and the occurrence or non-occurrence of events as rows.</p><p>In the field of machine learning and specifically the problem of statistical classification, a confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one. Each row of the matrix represents the instances in a predicted class while each column represents the instances in an actual class (or vice versa).</p><p>If a classification system has been trained to distinguish between apples, oranges and pineapples, a confusion matrix will summarize the results of testing the algorithm for further inspection. Assuming a sample of 27 animals — 8 apples, 6 oranges, and 13 pineapples, the resulting confusion matrix could look like the table below:</p><table><thead><tr><th>Prediction / Actual</th><th align="center">Apple (A)</th><th align="center">Orange (A)</th><th align="center">Pineapple (A)</th></tr></thead><tbody><tr><td>Apple (P)</td><td align="center"><strong>5</strong></td><td align="center">2</td><td align="center">0</td></tr><tr><td>Orange (P)</td><td align="center">3</td><td align="center"><strong>3</strong></td><td align="center">2</td></tr><tr><td>Pineapple (P)</td><td align="center">0</td><td align="center">1</td><td align="center"><strong>11</strong></td></tr></tbody></table><p>In this confusion matrix, of the 8 actual apples, the system predicted that three were oranges, and of the six oranges, it predicted that one was a pineapple and two were apples. We can see from the matrix that the system in question has trouble distinguishing between apples and oranges, but can make the distinction between pineapples and other types of animals pretty well. All correct predictions are loaded in the diagonal of the table (highlighted in bold), so it is easy to visually inspect the table for prediction errors, as they will be represented by values outside the diagonal.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="table-of-confusion">Table of Confusion<a class="hash-link" href="#table-of-confusion" title="Direct link to heading">​</a></h2><p>In predictive analytics, a table of confusion (sometimes also called a confusion matrix), is a table with two rows and two columns that reports the number of false positives, false negatives, true positives, and true negatives. This allows more detailed analysis than mere proportion of correct classifications (accuracy). Accuracy is not a reliable metric for the real performance of a classifier, because it will yield misleading results if the data set is unbalanced (that is, when the numbers of observations in different classes vary greatly). For example, if there were 95 apples and only 5 oranges in the data, a particular classifier might classify all the observations as apples. The overall accuracy would be 95%, but in more detail the classifier would have a 100% recognition rate (sensitivity) for the apple class but a 0% recognition rate for the orange class.</p><p>Assuming the confusion matrix above, its corresponding table of confusion, for the apple class, would be:</p><table><thead><tr><th>Prediction / Actual</th><th>Apple (A)</th><th>Not-Apple (A)</th></tr></thead><tbody><tr><td>Apple (P)</td><td>5 True Positives</td><td>2 False Positives</td></tr><tr><td>Not-Apple (P)</td><td>3 False Negatives</td><td>17 True Negatives</td></tr></tbody></table><h3 class="anchor anchorWithStickyNavbar_LWe7" id="evaluation-of-tasks-with-binary-output-labels">Evaluation of Tasks with binary output labels<a class="hash-link" href="#evaluation-of-tasks-with-binary-output-labels" title="Direct link to heading">​</a></h3><p>The performance of the model can be calculated based on the number of predictions that turned out to be true. The performance is given per feature (e.g. our model has a high accuracy to predict pineapples, but is a bit confused when it comes to distinguishing between apples and oranges). The performance table for a pineapple gives us the accuracy for the models prediction capabilities to recognize pineapples as follows:</p><table><thead><tr><th>Actual / Prediction</th><th>Pineapple (P)</th><th>Any other fruit (P)</th><th>Sum</th><th>Accuracy</th></tr></thead><tbody><tr><td>Pineapple (A)</td><td>976</td><td>34</td><td>1000</td><td>97.6 %</td></tr><tr><td>Any other fruit (A)</td><td>157</td><td>843</td><td>1000</td><td>84.3 %</td></tr></tbody></table><p>When the model saw a pineapple, out of 1000 instances it correctly predicted the type of fruit 976 times - giving us an accuracy of 97.6 %. But when seeing the image of an orange or apple it still concluded that it was a pineapple 157 times out of 1000 - resulting in an accuracy of 84.3 %.</p><ul><li><strong>Accuracy Metric</strong> : To calculate the Accuracy of the model over all instances the sum of all <strong>True Positives</strong> and <strong>True Negatives</strong> is divided by the total number of instances: <em>Accuracy = (TP + TN)/m</em></li></ul><ul><li><strong>Precision Metric</strong> : To calculate the precision of model over all instances to classify positive binary labels we need to calculate: <em>Precision = TP / (TP + FP)</em> e.g. (976) / (976 + 157) = 86.1%</li></ul><ul><li><strong>Recall Metric</strong> : The recall metric is the number of correctly predicted positive labels against all correctly predicted labels, positive and negative: <em>Recall = TP / (TP + FN)</em> e.g. (976) / (976 + 34) = 97.6%</li></ul><p><img loading="lazy" alt="Python SciKit-Learn" src="/assets/images/python-ml_11-47cbc3354547787ab12b49d157aeab59.png" width="1139" height="1085" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="evaluation-of-regression-tasks">Evaluation of Regression Tasks<a class="hash-link" href="#evaluation-of-regression-tasks" title="Direct link to heading">​</a></h3><p>Regression tasks have continuous outputs without a fixed number of output labels - here we cannot use any of the metrics above to evaluate the accuracy or precision of the predictions of our model.</p><ul><li><strong>Mean Absolute Error</strong> : The MAE is the average distance between the predicted result and the actual value, without taking into account the direction of the error: <em>MAE = 1/m * ∑ (over all m instances) (y(actual) - y(predicted)</em></li><li><strong>Root Mean Square Error</strong> : RMSE = √ (1/m * ∑ (over all m instances) (y(actual) - y(predicted))²</li></ul><p>In both cases the ideal model (prediction = actual value) would result in an error of <code>0</code>. In real applications you would try different models on your data and compare their prediction error - the one with the lowest error value wins. </p><p><img loading="lazy" alt="Python SciKit-Learn" src="/assets/images/python-ml_12-744f7e670042cd19a1f016b7bc796fd2.png" width="1149" height="1013" class="img_ev3q"></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/machine-learning">Machine Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/python">Python</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2018-01-02--machine-learning-with-python/index.mdx" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/IoT-and-Machine-Learning/ML/2019-03-31--introduction-to-tensorflow-2-beta/2019-03-31"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Introduction to TensorFlow 2 Beta</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/category/aiops"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">AIOps</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#data-representation" class="table-of-contents__link toc-highlight">Data Representation</a></li><li><a href="#data-preprocessing" class="table-of-contents__link toc-highlight">Data Preprocessing</a></li><li><a href="#scikit-learn-api" class="table-of-contents__link toc-highlight">SciKit-Learn API</a></li><li><a href="#estimation" class="table-of-contents__link toc-highlight">Estimation</a></li><li><a href="#predictor" class="table-of-contents__link toc-highlight">Predictor</a></li><li><a href="#transformer" class="table-of-contents__link toc-highlight">Transformer</a></li><li><a href="#clustering-tasks" class="table-of-contents__link toc-highlight">Clustering Tasks</a></li><li><a href="#clustering" class="table-of-contents__link toc-highlight">Clustering</a></li><li><a href="#visualization" class="table-of-contents__link toc-highlight">Visualization</a></li><li><a href="#k-means-algorithm" class="table-of-contents__link toc-highlight">k-Means Algorithm</a><ul><li><a href="#initialization-methods" class="table-of-contents__link toc-highlight">Initialization Methods</a></li></ul></li><li><a href="#mean-shift-algorithm" class="table-of-contents__link toc-highlight">Mean-Shift Algorithm</a></li><li><a href="#dbscan-algorithm" class="table-of-contents__link toc-highlight">DBSCAN Algorithm</a></li><li><a href="#evaluating-performance" class="table-of-contents__link toc-highlight">Evaluating Performance</a></li><li><a href="#classification-tasks" class="table-of-contents__link toc-highlight">Classification Tasks</a></li><li><a href="#regression-tasks" class="table-of-contents__link toc-highlight">Regression Tasks</a></li><li><a href="#data-split" class="table-of-contents__link toc-highlight">Data Split</a></li><li><a href="#cross-validation" class="table-of-contents__link toc-highlight">Cross Validation</a></li><li><a href="#metric-evaluation" class="table-of-contents__link toc-highlight">Metric Evaluation</a></li><li><a href="#table-of-confusion" class="table-of-contents__link toc-highlight">Table of Confusion</a><ul><li><a href="#evaluation-of-tasks-with-binary-output-labels" class="table-of-contents__link toc-highlight">Evaluation of Tasks with binary output labels</a></li><li><a href="#evaluation-of-regression-tasks" class="table-of-contents__link toc-highlight">Evaluation of Regression Tasks</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Research</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Notebook</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/tags">Tags</a></li><li class="footer__item"><a class="footer__link-item" href="/Curriculum-Vitae">CV</a></li></ul></div><div class="col footer__col"><div class="footer__title">Social</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/mike-polinowski-6396ba121/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/MikePolinowski" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.flickr.com/people/149680084@N06/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Flickr<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/mpolinowski" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Mike Polinowski, INSTAR Deutschland GmbH, Shenzhen - China.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.23698315.js"></script>
<script src="/assets/js/main.2d20e69f.js"></script>
</body>
</html>